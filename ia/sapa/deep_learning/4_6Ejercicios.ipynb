{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-16 17:47:18.622140: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-16 17:47:18.629647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-16 17:47:18.639630: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-16 17:47:18.642384: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-16 17:47:18.650150: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.activations import swish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practica cómo entrenar una red neuronal profunda con el conjunto de datos de imágenes CIFAR10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A\n",
    "El conjunto de datos está compuesto por 60.000 imágenes en color de 32 x 32 píxe­les (50.000 para el entrenamiento, 5.000 para la validación y 5.000 para las pruebas) con 10 clases. Puedes cargarlo con tf.keras.datasets.cifar10.load_data(). Muestra una de la imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos las tuplas en x e y\n",
    "(x_train_full, y_train_full), (x_test_full, y_test_full) = datos\n",
    "\n",
    "# 50,000 entrenamiento\n",
    "x_train = x_train_full[:50000]\n",
    "y_train = y_train_full[:50000]\n",
    "\n",
    "# 5,000 validación\n",
    "x_val = x_test_full[:5000]\n",
    "y_val = y_test_full[:5000]\n",
    "\n",
    "# 5,000 prueba\n",
    "x_test = x_test_full[5000:10000]\n",
    "y_test = y_test_full[5000:10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# muestra una imagen\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(x_train[8])\n",
    "plt.axis('off')   # quita los ejes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B\n",
    "Crea una RNP con 20 capas ocultas de 100 neuronas cada una (son demasiadas,\n",
    "pero esa es la gracia del ejercicio). \n",
    "\n",
    "Utiliza la inicialización He y la función de activa­ción Swish. \n",
    "\n",
    "Antes de las 20 capas tendras que añadir una capa Input y una capa Flatten y despúes una capa de de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737046041.289367   91823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1737046041.321243   91823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1737046041.321439   91823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1737046041.322829   91823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1737046041.323038   91823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1737046041.323107   91823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1737046041.382006   91823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1737046041.382130   91823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1737046041.382210   91823 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-16 17:47:21.382283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10268 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">307,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m307,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,210</span> (1.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m500,210\u001b[0m (1.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,210</span> (1.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m500,210\u001b[0m (1.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()      # creacion del modelo\n",
    "model.add(tf.keras.layers.Input(shape=(32,32,3)))    # capa entrada,   shape= imagen de 32x32 a color 3\n",
    "model.add(tf.keras.layers.Flatten())      # capa flatten\n",
    "for i in range(20):        \n",
    "    model.add(tf.keras.layers.Dense(100, activation=swish, kernel_initializer='he_normal'))    # las 20 capas ocultas de 100 neuronas activacion swish\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))     # capa salida \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C\n",
    "Elige una tasa de aprendizaje adecuada para la optimización Nadam.\n",
    "\n",
    "Para probar los diferentes modelos haz un bucle (después de cada entrenamiento evalua X_train y X_valid y guarda en un diccionario para \"Red neuronal normal\")\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "\n",
    "[{\n",
    "\n",
    "    'Red neuronal normal': {\n",
    "\n",
    "        'Tasa de aprendizaje': X,\n",
    "\n",
    "        'Entrenamiento sparse categorical accuracy': X,\n",
    "\n",
    "        'Validación sparse categorical accuracy': X,\n",
    "\n",
    "        'Tiempo total (s)': X\n",
    "\n",
    "    }\n",
    "    \n",
    "}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737046044.914113   91901 service.cc:146] XLA service 0x7d4d08001ad0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1737046044.914147   91901 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4080 Laptop GPU, Compute Capability 8.9\n",
      "2025-01-16 17:47:25.042607: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-01-16 17:47:25.255556: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 107/1563\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0971 - loss: 43.6134"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737046046.006278   91901 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.1119 - loss: 13.6290 - val_accuracy: 0.1416 - val_loss: 2.9038\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1422 - loss: 2.6828 - val_accuracy: 0.1814 - val_loss: 2.3088\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1897 - loss: 2.2549 - val_accuracy: 0.2236 - val_loss: 2.1241\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2364 - loss: 2.0910 - val_accuracy: 0.2640 - val_loss: 2.0143\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2692 - loss: 1.9943 - val_accuracy: 0.2990 - val_loss: 1.9377\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2947 - loss: 1.9251 - val_accuracy: 0.3222 - val_loss: 1.8795\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3140 - loss: 1.8737 - val_accuracy: 0.3396 - val_loss: 1.8412\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3285 - loss: 1.8403 - val_accuracy: 0.3322 - val_loss: 1.8300\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3473 - loss: 1.7953 - val_accuracy: 0.3354 - val_loss: 1.8042\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3565 - loss: 1.7679 - val_accuracy: 0.3724 - val_loss: 1.7590\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1825 - loss: 2.7182 - val_accuracy: 0.2732 - val_loss: 2.0019\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2896 - loss: 1.9316 - val_accuracy: 0.3086 - val_loss: 1.8716\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3216 - loss: 1.8601 - val_accuracy: 0.3488 - val_loss: 1.7823\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3396 - loss: 1.8133 - val_accuracy: 0.3390 - val_loss: 1.8091\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3536 - loss: 1.7789 - val_accuracy: 0.3614 - val_loss: 1.7532\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3612 - loss: 1.7611 - val_accuracy: 0.3760 - val_loss: 1.7128\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3776 - loss: 1.7334 - val_accuracy: 0.3818 - val_loss: 1.7020\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3797 - loss: 1.7138 - val_accuracy: 0.3810 - val_loss: 1.7208\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3921 - loss: 1.6856 - val_accuracy: 0.3890 - val_loss: 1.6946\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3905 - loss: 1.6800 - val_accuracy: 0.4042 - val_loss: 1.6535\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4225 - loss: 1.6025 - val_accuracy: 0.4260 - val_loss: 1.5950\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4281 - loss: 1.5798 - val_accuracy: 0.4340 - val_loss: 1.5806\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4323 - loss: 1.5615 - val_accuracy: 0.4310 - val_loss: 1.5802\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4343 - loss: 1.5627 - val_accuracy: 0.4354 - val_loss: 1.5748\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4352 - loss: 1.5561 - val_accuracy: 0.4348 - val_loss: 1.5670\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4359 - loss: 1.5462 - val_accuracy: 0.4376 - val_loss: 1.5654\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4468 - loss: 1.5287 - val_accuracy: 0.4386 - val_loss: 1.5677\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4492 - loss: 1.5230 - val_accuracy: 0.4436 - val_loss: 1.5578\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4449 - loss: 1.5341 - val_accuracy: 0.4380 - val_loss: 1.5678\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4458 - loss: 1.5254 - val_accuracy: 0.4460 - val_loss: 1.5546\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1184 - loss: 10.5249 - val_accuracy: 0.1008 - val_loss: 2.3063\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 7.4192 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0974 - loss: 2.3033 - val_accuracy: 0.1026 - val_loss: 2.3033\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 2.3033 - val_accuracy: 0.0994 - val_loss: 2.3030\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0998 - loss: 2.3033 - val_accuracy: 0.1026 - val_loss: 2.3034\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0976 - loss: 2.3035 - val_accuracy: 0.1008 - val_loss: 2.3035\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0991 - loss: 2.3033 - val_accuracy: 0.0976 - val_loss: 2.3029\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0998 - loss: 2.3032 - val_accuracy: 0.0976 - val_loss: 2.3032\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0980 - loss: 2.3033 - val_accuracy: 0.0982 - val_loss: 2.3037\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3035 - val_accuracy: 0.1014 - val_loss: 2.3031\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.0983 - loss: 2.3030 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0979 - loss: 2.3027 - val_accuracy: 0.1010 - val_loss: 2.3026\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0975 - loss: 2.3027 - val_accuracy: 0.1010 - val_loss: 2.3026\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0957 - loss: 2.3028 - val_accuracy: 0.1010 - val_loss: 2.3027\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0982 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3027\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0990 - loss: 2.3027 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1003 - loss: 2.3027 - val_accuracy: 0.0994 - val_loss: 2.3027\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3027 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0980 - loss: 2.3028 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0998 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1006 - loss: 2.3088 - val_accuracy: 0.0982 - val_loss: 2.3138\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0972 - loss: 2.3094 - val_accuracy: 0.0976 - val_loss: 2.3114\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0988 - loss: 2.3092 - val_accuracy: 0.0994 - val_loss: 2.3086\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1016 - loss: 2.3088 - val_accuracy: 0.1026 - val_loss: 2.3154\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0977 - loss: 2.3101 - val_accuracy: 0.0994 - val_loss: 2.3096\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1015 - loss: 2.3084 - val_accuracy: 0.1014 - val_loss: 2.3050\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0987 - loss: 2.3092 - val_accuracy: 0.1026 - val_loss: 2.3066\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 2.3086 - val_accuracy: 0.0994 - val_loss: 2.3046\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1005 - loss: 2.3089 - val_accuracy: 0.0982 - val_loss: 2.3053\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0988 - loss: 2.3088 - val_accuracy: 0.0994 - val_loss: 2.3066\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.3044 - val_accuracy: 0.0994 - val_loss: 2.3047\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1024 - loss: 2.3040 - val_accuracy: 0.1008 - val_loss: 2.3044\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0981 - loss: 2.3042 - val_accuracy: 0.1010 - val_loss: 2.3039\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0986 - loss: 2.3040 - val_accuracy: 0.0982 - val_loss: 2.3038\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0994 - loss: 2.3040 - val_accuracy: 0.0990 - val_loss: 2.3033\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0978 - loss: 2.3040 - val_accuracy: 0.0994 - val_loss: 2.3037\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1003 - loss: 2.3038 - val_accuracy: 0.1026 - val_loss: 2.3032\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1007 - loss: 2.3038 - val_accuracy: 0.0994 - val_loss: 2.3046\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3043 - val_accuracy: 0.1024 - val_loss: 2.3041\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1005 - loss: 2.3039 - val_accuracy: 0.1024 - val_loss: 2.3038\n"
     ]
    }
   ],
   "source": [
    "historial = {}\n",
    "rangos = [1e-5, 5e-4 , 1e-4 , 5e-3 , 1e-3 , 5e-2 , 1e-2]\n",
    "\n",
    "for lr in rangos:\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Nadam(learning_rate=lr),  \n",
    "              metrics=['accuracy'])\n",
    "    time_ini = time.time()\n",
    "    hist = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
    "    time_fin = time.time()\n",
    "    \n",
    "    historial[lr] = {'Tasa aprendizaje': lr, 'Entrenamiento accuracy': hist.history['accuracy'][-1], \n",
    "                     'Validacion accuracy': hist.history['val_accuracy'][-1], 'Tiempo': time_fin-time_ini}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.359279990196228    Validacion accuracy: 0.3723999857902527    Tiempo: 26.694779872894287    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.39678001403808594    Validacion accuracy: 0.4041999876499176    Tiempo: 25.946476459503174    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.447160005569458    Validacion accuracy: 0.44600000977516174    Tiempo: 26.679094791412354    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.0980599969625473    Validacion accuracy: 0.10140000283718109    Tiempo: 27.2749662399292    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.0997999981045723    Validacion accuracy: 0.0982000008225441    Tiempo: 27.435654878616333    \n",
      "Tasa aprendizaje: 0.05    Entrenamiento accuracy: 0.09961999952793121    Validacion accuracy: 0.09939999878406525    Tiempo: 28.00967788696289    \n",
      "Tasa aprendizaje: 0.01    Entrenamiento accuracy: 0.09855999797582626    Validacion accuracy: 0.10239999741315842    Tiempo: 26.613236904144287    \n",
      "Mejor lr:  0.0001\n"
     ]
    }
   ],
   "source": [
    "mejor_lr = 0\n",
    "mejor_val_acc = -2\n",
    "for k,value in historial.items(): \n",
    "    txt = ''\n",
    "    for key in value.keys(): txt += str(key)+': '+str(value[key])+'    '\n",
    "    print(txt)\n",
    "    if mejor_val_acc < value['Validacion accuracy']:\n",
    "        mejor_val_acc = value['Validacion accuracy']\n",
    "        mejor_lr = k\n",
    "print('Mejor lr: ',mejor_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D\n",
    " Una vez elegida la tasa de aprendizaje entrena el modelo usando la detención temprana (ahora que tienes detención temprana aumenta el número de epochs).\n",
    "\n",
    " Añade los resultados al diccionario anterior, hay que añadir:\n",
    "\n",
    "[{\n",
    "\n",
    "    'Red neuronal normal con detención temprana': {\n",
    "\n",
    "        'Tasa de aprendizaje': X,\n",
    "\n",
    "        'Entrenamiento sparse categorical accuracy': X,\n",
    "\n",
    "        'Validación sparse categorical accuracy': X,\n",
    "\n",
    "        'Tiempo total (s)': X,\n",
    "\n",
    "        'Mejor época': X\n",
    "\n",
    "    }\n",
    "    \n",
    "}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1014 - loss: 2.3038 - val_accuracy: 0.0994 - val_loss: 2.3038\n",
      "Epoch 2/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3041 - val_accuracy: 0.0976 - val_loss: 2.3038\n",
      "Epoch 3/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0982 - loss: 2.3040 - val_accuracy: 0.0994 - val_loss: 2.3031\n",
      "Epoch 4/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 2.3042 - val_accuracy: 0.0990 - val_loss: 2.3043\n",
      "Epoch 5/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1016 - loss: 2.3039 - val_accuracy: 0.0990 - val_loss: 2.3038\n",
      "Epoch 6/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0982 - loss: 2.3041 - val_accuracy: 0.0982 - val_loss: 2.3039\n",
      "Epoch 7/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0978 - loss: 2.3041 - val_accuracy: 0.1014 - val_loss: 2.3039\n",
      "Epoch 1/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1011 - loss: 2.3030 - val_accuracy: 0.0994 - val_loss: 2.3028\n",
      "Epoch 2/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3031 - val_accuracy: 0.0994 - val_loss: 2.3027\n",
      "Epoch 3/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0969 - loss: 2.3028 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 4/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0994 - loss: 2.3027 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 5/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0987 - loss: 2.3027 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 6/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0994 - loss: 2.3027 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 7/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0977 - loss: 2.3027 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 8/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0986 - loss: 2.3026 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 9/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0989 - loss: 2.3026 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 10/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0953 - loss: 2.3026 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 11/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 2.3026 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 12/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0987 - loss: 2.3026 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 13/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1015 - loss: 2.3026 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 14/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0973 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 15/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1015 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 16/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0987 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 17/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0976 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 18/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0986 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 19/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0984 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 20/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0987 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 21/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0973 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 22/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3026 - val_accuracy: 0.1010 - val_loss: 2.3026\n",
      "Epoch 23/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0979 - loss: 2.3026 - val_accuracy: 0.1010 - val_loss: 2.3026\n",
      "Epoch 24/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0980 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 25/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3026 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 26/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1001 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3026\n",
      "Epoch 27/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0976 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3026\n",
      "Epoch 28/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0956 - loss: 2.3026 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 29/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0991 - loss: 2.3026 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 30/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0990 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 31/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0993 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 32/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0974 - loss: 2.3026 - val_accuracy: 0.1024 - val_loss: 2.3026\n",
      "Epoch 33/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0989 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 34/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0977 - loss: 2.3026 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 35/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0989 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 36/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0981 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 37/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3026 - val_accuracy: 0.1010 - val_loss: 2.3026\n",
      "Epoch 38/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0971 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 39/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0968 - loss: 2.3026 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 40/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 41/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1008 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 42/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0972 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 43/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 44/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1007 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 45/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0974 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3026\n",
      "Epoch 46/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0967 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3026\n",
      "Epoch 47/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0972 - loss: 2.3026 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 48/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1003 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 49/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0970 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 50/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1007 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 51/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0986 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 52/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0971 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 53/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0980 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 54/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1006 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 55/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0997 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3026\n",
      "Epoch 56/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3026 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 57/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3026 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 58/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1027 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 59/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0979 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 60/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Tasa aprendizaje: 0.0001\n",
      "Entrenamiento accuracy: 0.09762000292539597\n",
      "Validacion accuracy: 0.10080000013113022\n",
      "Tiempo: 136.0\n",
      "Mejor epoca: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"./recursos/checkpoint/4_6_D_checkpoints.weights.h5\", save_weights_only=True)\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=70, validation_data=(x_val, y_val), \n",
    "                     callbacks=[checkpoint_cb,early_stopping_cb])\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "            optimizer=tf.keras.optimizers.Nadam(learning_rate=mejor_lr),   # asignar tasa de aprendizaje\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "time_ini = time.time()\n",
    "hist = model.fit(x_train, y_train, epochs=60, validation_data=(x_val, y_val))\n",
    "time_fin = time.time()\n",
    "\n",
    "mejor_ep = 0\n",
    "mejor_ep_acc = 0\n",
    "train_acc_arr = hist.history['accuracy']\n",
    "for i in range(len(train_acc_arr)): \n",
    "    if train_acc_arr[i] > mejor_ep_acc: \n",
    "        mejor_ep = i\n",
    "        mejor_ep_acc = train_acc_arr[i]\n",
    "\n",
    "historial[mejor_lr] = ({'Tasa aprendizaje': mejor_lr, 'Entrenamiento accuracy': train_acc_arr[-1], \n",
    "                    'Validacion accuracy': hist.history['val_accuracy'][-1], 'Tiempo': np.round(time_fin-time_ini), 'Mejor epoca': mejor_ep})\n",
    "\n",
    "txt = ''\n",
    "for key,value in historial[mejor_lr].items():  txt += str(key)+': '+str(value)+'\\n'\n",
    "print(txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E\n",
    "Ahora, prueba a añadir normalización de lotes y repite C y D con esta nueva red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.1407 - loss: 2.2649 - val_accuracy: 0.2302 - val_loss: 2.1201\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2419 - loss: 2.0977 - val_accuracy: 0.2826 - val_loss: 2.0222\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2671 - loss: 2.0162 - val_accuracy: 0.2950 - val_loss: 1.9476\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2829 - loss: 1.9431 - val_accuracy: 0.3072 - val_loss: 1.8614\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3029 - loss: 1.8573 - val_accuracy: 0.3316 - val_loss: 1.7944\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3294 - loss: 1.7935 - val_accuracy: 0.3530 - val_loss: 1.7468\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3488 - loss: 1.7525 - val_accuracy: 0.3674 - val_loss: 1.7126\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3677 - loss: 1.7143 - val_accuracy: 0.3792 - val_loss: 1.6799\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3792 - loss: 1.6809 - val_accuracy: 0.3866 - val_loss: 1.6633\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3898 - loss: 1.6501 - val_accuracy: 0.4006 - val_loss: 1.6417\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.39107999205589294    Validacion accuracy: 0.40059998631477356    Tiempo: 31.338576555252075    \n",
      "Mejor lr:  1e-05 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.3205 - loss: 1.8659 - val_accuracy: 0.3982 - val_loss: 1.6645\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3957 - loss: 1.6708 - val_accuracy: 0.4526 - val_loss: 1.5615\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4357 - loss: 1.5751 - val_accuracy: 0.4770 - val_loss: 1.4944\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4629 - loss: 1.5185 - val_accuracy: 0.4698 - val_loss: 1.4806\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4774 - loss: 1.4793 - val_accuracy: 0.4848 - val_loss: 1.4763\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4954 - loss: 1.4244 - val_accuracy: 0.4888 - val_loss: 1.4517\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5123 - loss: 1.3875 - val_accuracy: 0.4646 - val_loss: 1.4811\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5221 - loss: 1.3557 - val_accuracy: 0.4964 - val_loss: 1.4346\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5313 - loss: 1.3278 - val_accuracy: 0.5066 - val_loss: 1.4121\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5456 - loss: 1.2976 - val_accuracy: 0.5174 - val_loss: 1.3812\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.39107999205589294    Validacion accuracy: 0.40059998631477356    Tiempo: 31.338576555252075    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5414999723434448    Validacion accuracy: 0.5174000263214111    Tiempo: 30.650527715682983    \n",
      "Mejor lr:  0.0005 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.5819 - loss: 1.1934 - val_accuracy: 0.5378 - val_loss: 1.3507\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5935 - loss: 1.1448 - val_accuracy: 0.5288 - val_loss: 1.3498\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6083 - loss: 1.1129 - val_accuracy: 0.5316 - val_loss: 1.3618\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6077 - loss: 1.0973 - val_accuracy: 0.5272 - val_loss: 1.3506\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6137 - loss: 1.0877 - val_accuracy: 0.5294 - val_loss: 1.3530\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6160 - loss: 1.0814 - val_accuracy: 0.5376 - val_loss: 1.3534\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6231 - loss: 1.0640 - val_accuracy: 0.5238 - val_loss: 1.3756\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6253 - loss: 1.0492 - val_accuracy: 0.5354 - val_loss: 1.3758\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6335 - loss: 1.0395 - val_accuracy: 0.5318 - val_loss: 1.3845\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6384 - loss: 1.0243 - val_accuracy: 0.5332 - val_loss: 1.3803\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.39107999205589294    Validacion accuracy: 0.40059998631477356    Tiempo: 31.338576555252075    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5414999723434448    Validacion accuracy: 0.5174000263214111    Tiempo: 30.650527715682983    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.6320800185203552    Validacion accuracy: 0.5332000255584717    Tiempo: 30.22593402862549    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2320 - loss: 2.0174 - val_accuracy: 0.0990 - val_loss: 2.3076\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 2.3268 - val_accuracy: 0.0976 - val_loss: 2.3030\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1027 - loss: 2.3033 - val_accuracy: 0.1010 - val_loss: 2.3029\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0954 - loss: 2.3034 - val_accuracy: 0.1026 - val_loss: 2.3028\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1007 - loss: 2.3032 - val_accuracy: 0.1014 - val_loss: 2.3029\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0993 - loss: 2.3035 - val_accuracy: 0.1024 - val_loss: 2.3028\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0979 - loss: 2.3034 - val_accuracy: 0.0976 - val_loss: 2.3031\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0970 - loss: 2.3035 - val_accuracy: 0.1026 - val_loss: 2.3027\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0987 - loss: 2.3033 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0942 - loss: 2.3035 - val_accuracy: 0.1014 - val_loss: 2.3033\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.39107999205589294    Validacion accuracy: 0.40059998631477356    Tiempo: 31.338576555252075    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5414999723434448    Validacion accuracy: 0.5174000263214111    Tiempo: 30.650527715682983    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.6320800185203552    Validacion accuracy: 0.5332000255584717    Tiempo: 30.22593402862549    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.09718000143766403    Validacion accuracy: 0.10140000283718109    Tiempo: 30.89717435836792    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.0965 - loss: 2.3028 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0992 - loss: 2.3027 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0999 - loss: 2.3027 - val_accuracy: 0.1008 - val_loss: 2.3027\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1006 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3025\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0969 - loss: 2.3027 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0987 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 2.3027 - val_accuracy: 0.0976 - val_loss: 2.3027\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0982 - loss: 2.3028 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0929 - loss: 2.3028 - val_accuracy: 0.1008 - val_loss: 2.3027\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0965 - loss: 2.3028 - val_accuracy: 0.1024 - val_loss: 2.3025\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.39107999205589294    Validacion accuracy: 0.40059998631477356    Tiempo: 31.338576555252075    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5414999723434448    Validacion accuracy: 0.5174000263214111    Tiempo: 30.650527715682983    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.6320800185203552    Validacion accuracy: 0.5332000255584717    Tiempo: 30.22593402862549    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.09718000143766403    Validacion accuracy: 0.10140000283718109    Tiempo: 30.89717435836792    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.09666000306606293    Validacion accuracy: 0.10239999741315842    Tiempo: 31.65806770324707    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.0962 - loss: 2.3092 - val_accuracy: 0.0982 - val_loss: 2.3095\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0964 - loss: 2.3095 - val_accuracy: 0.1008 - val_loss: 2.3078\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0979 - loss: 2.3091 - val_accuracy: 0.1010 - val_loss: 2.3064\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0958 - loss: 2.3082 - val_accuracy: 0.0976 - val_loss: 2.3096\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1004 - loss: 2.3082 - val_accuracy: 0.0976 - val_loss: 2.3094\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1008 - loss: 2.3086 - val_accuracy: 0.1010 - val_loss: 2.3048\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0982 - loss: 2.3091 - val_accuracy: 0.1026 - val_loss: 2.3092\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0993 - loss: 2.3086 - val_accuracy: 0.1014 - val_loss: 2.3056\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1031 - loss: 2.3079 - val_accuracy: 0.0976 - val_loss: 2.3044\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 2.3086 - val_accuracy: 0.1010 - val_loss: 2.3071\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.39107999205589294    Validacion accuracy: 0.40059998631477356    Tiempo: 31.338576555252075    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5414999723434448    Validacion accuracy: 0.5174000263214111    Tiempo: 30.650527715682983    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.6320800185203552    Validacion accuracy: 0.5332000255584717    Tiempo: 30.22593402862549    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.09718000143766403    Validacion accuracy: 0.10140000283718109    Tiempo: 30.89717435836792    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.09666000306606293    Validacion accuracy: 0.10239999741315842    Tiempo: 31.65806770324707    \n",
      "Tasa aprendizaje: 0.05    Entrenamiento accuracy: 0.0995199978351593    Validacion accuracy: 0.10100000351667404    Tiempo: 30.446158170700073    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0983 - loss: 2.3044 - val_accuracy: 0.1010 - val_loss: 2.3033\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1000 - loss: 2.3040 - val_accuracy: 0.1026 - val_loss: 2.3033\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0992 - loss: 2.3040 - val_accuracy: 0.0994 - val_loss: 2.3030\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0980 - loss: 2.3040 - val_accuracy: 0.0976 - val_loss: 2.3035\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0998 - loss: 2.3040 - val_accuracy: 0.0982 - val_loss: 2.3052\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0970 - loss: 2.3043 - val_accuracy: 0.1024 - val_loss: 2.3031\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0991 - loss: 2.3039 - val_accuracy: 0.0982 - val_loss: 2.3035\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0984 - loss: 2.3038 - val_accuracy: 0.1014 - val_loss: 2.3043\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0975 - loss: 2.3040 - val_accuracy: 0.0976 - val_loss: 2.3040\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0979 - loss: 2.3039 - val_accuracy: 0.0976 - val_loss: 2.3042\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.39107999205589294    Validacion accuracy: 0.40059998631477356    Tiempo: 31.338576555252075    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5414999723434448    Validacion accuracy: 0.5174000263214111    Tiempo: 30.650527715682983    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.6320800185203552    Validacion accuracy: 0.5332000255584717    Tiempo: 30.22593402862549    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.09718000143766403    Validacion accuracy: 0.10140000283718109    Tiempo: 30.89717435836792    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.09666000306606293    Validacion accuracy: 0.10239999741315842    Tiempo: 31.65806770324707    \n",
      "Tasa aprendizaje: 0.05    Entrenamiento accuracy: 0.0995199978351593    Validacion accuracy: 0.10100000351667404    Tiempo: 30.446158170700073    \n",
      "Tasa aprendizaje: 0.01    Entrenamiento accuracy: 0.0996600016951561    Validacion accuracy: 0.09759999811649323    Tiempo: 30.061028480529785    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3041 - val_accuracy: 0.0982 - val_loss: 2.3036\n",
      "Epoch 2/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3039 - val_accuracy: 0.1026 - val_loss: 2.3029\n",
      "Epoch 3/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0992 - loss: 2.3041 - val_accuracy: 0.0994 - val_loss: 2.3044\n",
      "Epoch 4/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3041 - val_accuracy: 0.1026 - val_loss: 2.3034\n",
      "Epoch 5/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1004 - loss: 2.3041 - val_accuracy: 0.1010 - val_loss: 2.3046\n",
      "Epoch 6/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3041 - val_accuracy: 0.1024 - val_loss: 2.3031\n",
      "Epoch 1/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.1013 - loss: 2.3033 - val_accuracy: 0.1026 - val_loss: 2.3027\n",
      "Epoch 2/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0995 - loss: 2.3030 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 3/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0988 - loss: 2.3028 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 4/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1016 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3025\n",
      "Epoch 5/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0978 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3025\n",
      "Epoch 6/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0993 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3025\n",
      "Epoch 7/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1015 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 8/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0996 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 9/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1012 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 10/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0980 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 11/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0981 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 12/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0987 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 13/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0984 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 14/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0988 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 15/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0997 - loss: 2.3026 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 16/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0961 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 17/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0943 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 18/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1001 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 19/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0997 - loss: 2.3026 - val_accuracy: 0.1010 - val_loss: 2.3026\n",
      "Epoch 20/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0964 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 21/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0976 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 22/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1022 - loss: 2.3026 - val_accuracy: 0.1010 - val_loss: 2.3026\n",
      "Epoch 23/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0990 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 24/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.3026 - val_accuracy: 0.1010 - val_loss: 2.3026\n",
      "Epoch 25/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1012 - loss: 2.3026 - val_accuracy: 0.1010 - val_loss: 2.3026\n",
      "Epoch 26/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1009 - loss: 2.3026 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 27/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 2.3026 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 28/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1038 - loss: 2.3026 - val_accuracy: 0.1010 - val_loss: 2.3026\n",
      "Epoch 29/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0977 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 30/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0978 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 31/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1012 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 32/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0958 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 33/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 34/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0999 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 35/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0957 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 36/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0992 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 37/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0960 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 38/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0976 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 39/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0977 - loss: 2.3026 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 40/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1014 - loss: 2.3026 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 41/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1006 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 42/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0979 - loss: 2.3026 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 43/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1009 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3026\n",
      "Epoch 44/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0992 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3026\n",
      "Epoch 45/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3026 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 46/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0950 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 47/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3026 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 48/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0997 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 49/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0990 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 50/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0991 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 51/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0992 - loss: 2.3026 - val_accuracy: 0.1008 - val_loss: 2.3026\n",
      "Epoch 52/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1042 - loss: 2.3026 - val_accuracy: 0.1010 - val_loss: 2.3026\n",
      "Epoch 53/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0977 - loss: 2.3026 - val_accuracy: 0.1010 - val_loss: 2.3026\n",
      "Epoch 54/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0973 - loss: 2.3026 - val_accuracy: 0.1010 - val_loss: 2.3026\n",
      "Epoch 55/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3026 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 56/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0991 - loss: 2.3026 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 57/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0964 - loss: 2.3026 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 58/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0990 - loss: 2.3026 - val_accuracy: 0.1010 - val_loss: 2.3026\n",
      "Epoch 59/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0987 - loss: 2.3026 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 60/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0987 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3026\n",
      "\n",
      "Tasa aprendizaje: 0.0001\n",
      "Entrenamiento accuracy: 0.09662000089883804\n",
      "Validacion accuracy: 0.0982000008225441\n",
      "Tiempo: 160.0\n",
      "Mejor epoca: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Limpiamos memoria\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# crear red\n",
    "model = tf.keras.Sequential()      # creacion del modelo\n",
    "model.add(tf.keras.layers.Input(shape=(32,32,3)))    # capa entrada,   shape= imagen de 32x32 a color 3\n",
    "model.add(tf.keras.layers.Flatten())      # capa flatten\n",
    "model.add(tf.keras.layers.BatchNormalization())   # normalizacion\n",
    "for i in range(20):        \n",
    "    model.add(tf.keras.layers.Dense(100, activation=swish, kernel_initializer='he_normal'))    # las 20 capas ocultas de 100 neuronas activacion swish\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))     # capa salida \n",
    "\n",
    "\n",
    "def ej_CyD(model, letra):\n",
    "    # C, hayar mejor lr\n",
    "    historial = {}\n",
    "    rangos = [1e-5, 5e-4 , 1e-4 , 5e-3 , 1e-3 , 5e-2 , 1e-2]\n",
    "    for lr in rangos:\n",
    "\n",
    "        model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                optimizer=tf.keras.optimizers.Nadam(learning_rate=lr),  \n",
    "                metrics=['accuracy'])\n",
    "        time_ini = time.time()\n",
    "        hist = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
    "        time_fin = time.time()\n",
    "        \n",
    "        historial[lr] = {'Tasa aprendizaje': lr, 'Entrenamiento accuracy': hist.history['accuracy'][-1], \n",
    "                        'Validacion accuracy': hist.history['val_accuracy'][-1], 'Tiempo': time_fin-time_ini}\n",
    "        mejor_lr = 0\n",
    "        mejor_val_acc = -2\n",
    "        for k,value in historial.items(): \n",
    "            txt = ''\n",
    "            for key in value.keys(): txt += str(key)+': '+str(value[key])+'    '\n",
    "            print(txt)\n",
    "            if mejor_val_acc < value['Validacion accuracy']:\n",
    "                mejor_val_acc = value['Validacion accuracy']\n",
    "                mejor_lr = k\n",
    "        print('Mejor lr: ',mejor_lr,'\\n\\n')\n",
    "\n",
    "\n",
    "    # D, aplicar detencion temprana con el mejor lr\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True)\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"./recursos/checkpoint/4_6_\"+letra+\"_checkpoints.weights.h5\", save_weights_only=True)\n",
    "\n",
    "    hist = model.fit(x_train, y_train, epochs=70, validation_data=(x_val, y_val), \n",
    "                        callbacks=[checkpoint_cb,early_stopping_cb])\n",
    "\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                optimizer=tf.keras.optimizers.Nadam(learning_rate=mejor_lr),   # asignar tasa de aprendizaje\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    time_ini = time.time()\n",
    "    hist = model.fit(x_train, y_train, epochs=60, validation_data=(x_val, y_val))\n",
    "    time_fin = time.time()\n",
    "\n",
    "    mejor_ep = 0\n",
    "    mejor_ep_acc = 0\n",
    "    train_acc_arr = hist.history['accuracy']\n",
    "    for i in range(len(train_acc_arr)): \n",
    "        if train_acc_arr[i] > mejor_ep_acc: \n",
    "            mejor_ep = i\n",
    "            mejor_ep_acc = train_acc_arr[i]\n",
    "\n",
    "    historial[mejor_lr] = ({'Tasa aprendizaje': mejor_lr, 'Entrenamiento accuracy': train_acc_arr[-1], \n",
    "                        'Validacion accuracy': hist.history['val_accuracy'][-1], 'Tiempo': np.round(time_fin-time_ini), 'Mejor epoca': mejor_ep})\n",
    "\n",
    "    txt = '\\n'\n",
    "    for key,value in historial[mejor_lr].items():  txt += str(key)+': '+str(value)+'\\n'\n",
    "    print(txt)\n",
    "    return mejor_lr, historial\n",
    "\n",
    "\n",
    "mejor_lr_E, historial_E = ej_CyD(model,'E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F\n",
    "Prueba a sustituir la normalización de lotes por la activación SELU y haz los ajustes necesarios para garantizar que la red se autonormaliza (es decir, tienes que estandarizar los datos antes de empezar).\n",
    "\n",
    "En este caso prueba a estandarizar manualmentes, es decir restando la media y dividiendo por la desviación standard.\n",
    "\n",
    "Usa la inicialización LeCun normal.\n",
    "\n",
    "Repite C y D con esta nueva red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.2256 - loss: 2.2520 - val_accuracy: 0.3362 - val_loss: 1.8619\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3513 - loss: 1.8172 - val_accuracy: 0.3750 - val_loss: 1.7478\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3903 - loss: 1.7106 - val_accuracy: 0.4022 - val_loss: 1.6895\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4137 - loss: 1.6425 - val_accuracy: 0.4160 - val_loss: 1.6477\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4392 - loss: 1.5930 - val_accuracy: 0.4270 - val_loss: 1.6140\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4523 - loss: 1.5490 - val_accuracy: 0.4358 - val_loss: 1.5977\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4682 - loss: 1.5119 - val_accuracy: 0.4312 - val_loss: 1.5849\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4741 - loss: 1.4831 - val_accuracy: 0.4416 - val_loss: 1.5603\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4882 - loss: 1.4571 - val_accuracy: 0.4456 - val_loss: 1.5607\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5017 - loss: 1.4154 - val_accuracy: 0.4506 - val_loss: 1.5471\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4940199851989746    Validacion accuracy: 0.4505999982357025    Tiempo: 26.782188653945923    \n",
      "Mejor lr:  1e-05 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.3313 - loss: 1.8899 - val_accuracy: 0.4200 - val_loss: 1.6347\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4222 - loss: 1.6439 - val_accuracy: 0.4426 - val_loss: 1.5732\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4515 - loss: 1.5554 - val_accuracy: 0.4624 - val_loss: 1.5638\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4760 - loss: 1.4870 - val_accuracy: 0.4592 - val_loss: 1.5232\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4992 - loss: 1.4270 - val_accuracy: 0.4916 - val_loss: 1.4621\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5198 - loss: 1.3685 - val_accuracy: 0.4976 - val_loss: 1.4935\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5392 - loss: 1.3290 - val_accuracy: 0.5054 - val_loss: 1.4226\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5571 - loss: 1.2827 - val_accuracy: 0.5062 - val_loss: 1.4314\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5674 - loss: 1.2383 - val_accuracy: 0.5210 - val_loss: 1.4339\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5818 - loss: 1.2023 - val_accuracy: 0.5100 - val_loss: 1.4442\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4940199851989746    Validacion accuracy: 0.4505999982357025    Tiempo: 26.782188653945923    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5768799781799316    Validacion accuracy: 0.5099999904632568    Tiempo: 26.618760585784912    \n",
      "Mejor lr:  0.0005 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6363 - loss: 1.0504 - val_accuracy: 0.5410 - val_loss: 1.3654\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6613 - loss: 0.9701 - val_accuracy: 0.5378 - val_loss: 1.4030\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6754 - loss: 0.9281 - val_accuracy: 0.5356 - val_loss: 1.4398\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6849 - loss: 0.9026 - val_accuracy: 0.5354 - val_loss: 1.4315\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6996 - loss: 0.8660 - val_accuracy: 0.5320 - val_loss: 1.4658\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7083 - loss: 0.8400 - val_accuracy: 0.5332 - val_loss: 1.4836\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7160 - loss: 0.8222 - val_accuracy: 0.5344 - val_loss: 1.5004\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7257 - loss: 0.7979 - val_accuracy: 0.5288 - val_loss: 1.5338\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7372 - loss: 0.7646 - val_accuracy: 0.5304 - val_loss: 1.5861\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7403 - loss: 0.7524 - val_accuracy: 0.5316 - val_loss: 1.5910\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4940199851989746    Validacion accuracy: 0.4505999982357025    Tiempo: 26.782188653945923    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5768799781799316    Validacion accuracy: 0.5099999904632568    Tiempo: 26.618760585784912    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7377399802207947    Validacion accuracy: 0.5315999984741211    Tiempo: 27.045398235321045    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1557 - loss: 2.6473 - val_accuracy: 0.0982 - val_loss: 2.3165\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0948 - loss: 2.3508 - val_accuracy: 0.1024 - val_loss: 2.3618\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1009 - loss: 2.3568 - val_accuracy: 0.1008 - val_loss: 2.3837\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0991 - loss: 2.3598 - val_accuracy: 0.0994 - val_loss: 2.3314\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1007 - loss: 2.3592 - val_accuracy: 0.0982 - val_loss: 2.3761\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1015 - loss: 2.3582 - val_accuracy: 0.0976 - val_loss: 2.3470\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1020 - loss: 2.3617 - val_accuracy: 0.1008 - val_loss: 2.3470\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1018 - loss: 2.3602 - val_accuracy: 0.0982 - val_loss: 2.3191\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1027 - loss: 2.3613 - val_accuracy: 0.0982 - val_loss: 2.3510\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1045 - loss: 2.3590 - val_accuracy: 0.1024 - val_loss: 2.3820\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4940199851989746    Validacion accuracy: 0.4505999982357025    Tiempo: 26.782188653945923    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5768799781799316    Validacion accuracy: 0.5099999904632568    Tiempo: 26.618760585784912    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7377399802207947    Validacion accuracy: 0.5315999984741211    Tiempo: 27.045398235321045    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.10344000160694122    Validacion accuracy: 0.10239999741315842    Tiempo: 26.419175624847412    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.0946 - loss: 2.3218 - val_accuracy: 0.1014 - val_loss: 2.3212\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0979 - loss: 2.3224 - val_accuracy: 0.1008 - val_loss: 2.3177\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1013 - loss: 2.3200 - val_accuracy: 0.1024 - val_loss: 2.3282\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1011 - loss: 2.3202 - val_accuracy: 0.0976 - val_loss: 2.3319\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1003 - loss: 2.3222 - val_accuracy: 0.1026 - val_loss: 2.3270\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3230 - val_accuracy: 0.0990 - val_loss: 2.3293\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1001 - loss: 2.3224 - val_accuracy: 0.1014 - val_loss: 2.3375\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3214 - val_accuracy: 0.1014 - val_loss: 2.3177\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1017 - loss: 2.3214 - val_accuracy: 0.1024 - val_loss: 2.3223\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0982 - loss: 2.3223 - val_accuracy: 0.0994 - val_loss: 2.3311\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4940199851989746    Validacion accuracy: 0.4505999982357025    Tiempo: 26.782188653945923    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5768799781799316    Validacion accuracy: 0.5099999904632568    Tiempo: 26.618760585784912    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7377399802207947    Validacion accuracy: 0.5315999984741211    Tiempo: 27.045398235321045    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.10344000160694122    Validacion accuracy: 0.10239999741315842    Tiempo: 26.419175624847412    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.09935999661684036    Validacion accuracy: 0.09939999878406525    Tiempo: 25.820282697677612    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1040 - loss: 3.1708 - val_accuracy: 0.0990 - val_loss: 3.1332\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0993 - loss: 3.0043 - val_accuracy: 0.1024 - val_loss: 3.3519\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0997 - loss: 2.9749 - val_accuracy: 0.0976 - val_loss: 3.9328\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1020 - loss: 2.9608 - val_accuracy: 0.1014 - val_loss: 3.0890\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0974 - loss: 2.9793 - val_accuracy: 0.0990 - val_loss: 3.1320\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1013 - loss: 3.0000 - val_accuracy: 0.0994 - val_loss: 2.7670\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 3.0254 - val_accuracy: 0.0994 - val_loss: 2.6800\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0994 - loss: 2.9610 - val_accuracy: 0.0976 - val_loss: 4.2185\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1014 - loss: 2.9456 - val_accuracy: 0.1014 - val_loss: 2.6791\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0988 - loss: 2.9732 - val_accuracy: 0.0976 - val_loss: 5.1184\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4940199851989746    Validacion accuracy: 0.4505999982357025    Tiempo: 26.782188653945923    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5768799781799316    Validacion accuracy: 0.5099999904632568    Tiempo: 26.618760585784912    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7377399802207947    Validacion accuracy: 0.5315999984741211    Tiempo: 27.045398235321045    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.10344000160694122    Validacion accuracy: 0.10239999741315842    Tiempo: 26.419175624847412    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.09935999661684036    Validacion accuracy: 0.09939999878406525    Tiempo: 25.820282697677612    \n",
      "Tasa aprendizaje: 0.05    Entrenamiento accuracy: 0.09922000020742416    Validacion accuracy: 0.09759999811649323    Tiempo: 26.915548086166382    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1022 - loss: 2.4247 - val_accuracy: 0.1008 - val_loss: 2.3751\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1023 - loss: 2.3939 - val_accuracy: 0.1010 - val_loss: 2.3707\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0976 - loss: 2.3957 - val_accuracy: 0.1024 - val_loss: 2.4755\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3990 - val_accuracy: 0.0976 - val_loss: 2.4120\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1002 - loss: 2.3957 - val_accuracy: 0.1026 - val_loss: 2.4381\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 2.3959 - val_accuracy: 0.0976 - val_loss: 2.4677\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0963 - loss: 2.3980 - val_accuracy: 0.0976 - val_loss: 2.3820\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0996 - loss: 2.4005 - val_accuracy: 0.1024 - val_loss: 2.4834\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1020 - loss: 2.3950 - val_accuracy: 0.0976 - val_loss: 2.4134\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0936 - loss: 2.3991 - val_accuracy: 0.1014 - val_loss: 2.4928\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4940199851989746    Validacion accuracy: 0.4505999982357025    Tiempo: 26.782188653945923    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5768799781799316    Validacion accuracy: 0.5099999904632568    Tiempo: 26.618760585784912    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7377399802207947    Validacion accuracy: 0.5315999984741211    Tiempo: 27.045398235321045    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.10344000160694122    Validacion accuracy: 0.10239999741315842    Tiempo: 26.419175624847412    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.09935999661684036    Validacion accuracy: 0.09939999878406525    Tiempo: 25.820282697677612    \n",
      "Tasa aprendizaje: 0.05    Entrenamiento accuracy: 0.09922000020742416    Validacion accuracy: 0.09759999811649323    Tiempo: 26.915548086166382    \n",
      "Tasa aprendizaje: 0.01    Entrenamiento accuracy: 0.09662000089883804    Validacion accuracy: 0.10140000283718109    Tiempo: 27.003178119659424    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1007 - loss: 2.3993 - val_accuracy: 0.0982 - val_loss: 2.6624\n",
      "Epoch 2/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1005 - loss: 2.3973 - val_accuracy: 0.1014 - val_loss: 2.4745\n",
      "Epoch 3/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1033 - loss: 2.3948 - val_accuracy: 0.1026 - val_loss: 2.3362\n",
      "Epoch 4/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3945 - val_accuracy: 0.1014 - val_loss: 2.3867\n",
      "Epoch 5/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0996 - loss: 2.3971 - val_accuracy: 0.0982 - val_loss: 2.4568\n",
      "Epoch 6/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1011 - loss: 2.3950 - val_accuracy: 0.0994 - val_loss: 2.3675\n",
      "Epoch 7/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 2.3979 - val_accuracy: 0.1010 - val_loss: 2.3897\n",
      "Epoch 1/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1015 - loss: 2.3072 - val_accuracy: 0.1014 - val_loss: 2.3036\n",
      "Epoch 2/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3047 - val_accuracy: 0.1008 - val_loss: 2.3048\n",
      "Epoch 3/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0952 - loss: 2.3055 - val_accuracy: 0.1010 - val_loss: 2.3038\n",
      "Epoch 4/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0990 - loss: 2.3049 - val_accuracy: 0.1008 - val_loss: 2.3049\n",
      "Epoch 5/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0973 - loss: 2.3054 - val_accuracy: 0.1014 - val_loss: 2.3048\n",
      "Epoch 6/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1009 - loss: 2.3051 - val_accuracy: 0.1024 - val_loss: 2.3048\n",
      "Epoch 7/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3050 - val_accuracy: 0.0982 - val_loss: 2.3050\n",
      "Epoch 8/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0992 - loss: 2.3048 - val_accuracy: 0.0990 - val_loss: 2.3054\n",
      "Epoch 9/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0993 - loss: 2.3049 - val_accuracy: 0.1014 - val_loss: 2.3057\n",
      "Epoch 10/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0972 - loss: 2.3051 - val_accuracy: 0.1008 - val_loss: 2.3052\n",
      "Epoch 11/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0982 - loss: 2.3048 - val_accuracy: 0.1026 - val_loss: 2.3048\n",
      "Epoch 12/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0972 - loss: 2.3052 - val_accuracy: 0.1026 - val_loss: 2.3042\n",
      "Epoch 13/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0933 - loss: 2.3053 - val_accuracy: 0.1014 - val_loss: 2.3034\n",
      "Epoch 14/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1001 - loss: 2.3049 - val_accuracy: 0.1010 - val_loss: 2.3047\n",
      "Epoch 15/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0930 - loss: 2.3055 - val_accuracy: 0.0994 - val_loss: 2.3038\n",
      "Epoch 16/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0979 - loss: 2.3051 - val_accuracy: 0.1008 - val_loss: 2.3037\n",
      "Epoch 17/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0978 - loss: 2.3046 - val_accuracy: 0.1024 - val_loss: 2.3030\n",
      "Epoch 18/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1001 - loss: 2.3046 - val_accuracy: 0.0990 - val_loss: 2.3053\n",
      "Epoch 19/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 2.3050 - val_accuracy: 0.1008 - val_loss: 2.3045\n",
      "Epoch 20/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1002 - loss: 2.3049 - val_accuracy: 0.1024 - val_loss: 2.3038\n",
      "Epoch 21/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1006 - loss: 2.3047 - val_accuracy: 0.1010 - val_loss: 2.3036\n",
      "Epoch 22/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0990 - loss: 2.3047 - val_accuracy: 0.0982 - val_loss: 2.3055\n",
      "Epoch 23/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0997 - loss: 2.3051 - val_accuracy: 0.0976 - val_loss: 2.3033\n",
      "Epoch 24/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1035 - loss: 2.3047 - val_accuracy: 0.1024 - val_loss: 2.3042\n",
      "Epoch 25/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0982 - loss: 2.3053 - val_accuracy: 0.0990 - val_loss: 2.3048\n",
      "Epoch 26/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0998 - loss: 2.3054 - val_accuracy: 0.0982 - val_loss: 2.3040\n",
      "Epoch 27/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1025 - loss: 2.3046 - val_accuracy: 0.0976 - val_loss: 2.3052\n",
      "Epoch 28/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0987 - loss: 2.3048 - val_accuracy: 0.1014 - val_loss: 2.3054\n",
      "Epoch 29/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0981 - loss: 2.3050 - val_accuracy: 0.0994 - val_loss: 2.3051\n",
      "Epoch 30/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3052 - val_accuracy: 0.1008 - val_loss: 2.3034\n",
      "Epoch 31/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0991 - loss: 2.3050 - val_accuracy: 0.1024 - val_loss: 2.3040\n",
      "Epoch 32/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3052 - val_accuracy: 0.1024 - val_loss: 2.3041\n",
      "Epoch 33/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0988 - loss: 2.3044 - val_accuracy: 0.1010 - val_loss: 2.3051\n",
      "Epoch 34/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0998 - loss: 2.3048 - val_accuracy: 0.0994 - val_loss: 2.3034\n",
      "Epoch 35/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0972 - loss: 2.3048 - val_accuracy: 0.0990 - val_loss: 2.3044\n",
      "Epoch 36/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 2.3047 - val_accuracy: 0.1024 - val_loss: 2.3037\n",
      "Epoch 37/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1001 - loss: 2.3052 - val_accuracy: 0.0976 - val_loss: 2.3052\n",
      "Epoch 38/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3053 - val_accuracy: 0.1026 - val_loss: 2.3028\n",
      "Epoch 39/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3048 - val_accuracy: 0.1008 - val_loss: 2.3049\n",
      "Epoch 40/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3050 - val_accuracy: 0.0982 - val_loss: 2.3048\n",
      "Epoch 41/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1003 - loss: 2.3053 - val_accuracy: 0.0976 - val_loss: 2.3046\n",
      "Epoch 42/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0997 - loss: 2.3046 - val_accuracy: 0.0994 - val_loss: 2.3047\n",
      "Epoch 43/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0998 - loss: 2.3050 - val_accuracy: 0.1014 - val_loss: 2.3063\n",
      "Epoch 44/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1018 - loss: 2.3053 - val_accuracy: 0.0994 - val_loss: 2.3065\n",
      "Epoch 45/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 2.3050 - val_accuracy: 0.1008 - val_loss: 2.3042\n",
      "Epoch 46/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1037 - loss: 2.3047 - val_accuracy: 0.1008 - val_loss: 2.3040\n",
      "Epoch 47/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3048 - val_accuracy: 0.1024 - val_loss: 2.3035\n",
      "Epoch 48/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0986 - loss: 2.3049 - val_accuracy: 0.1008 - val_loss: 2.3047\n",
      "Epoch 49/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1002 - loss: 2.3051 - val_accuracy: 0.1010 - val_loss: 2.3043\n",
      "Epoch 50/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1024 - loss: 2.3048 - val_accuracy: 0.1008 - val_loss: 2.3047\n",
      "Epoch 51/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0979 - loss: 2.3049 - val_accuracy: 0.1026 - val_loss: 2.3041\n",
      "Epoch 52/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0963 - loss: 2.3049 - val_accuracy: 0.0976 - val_loss: 2.3045\n",
      "Epoch 53/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1044 - loss: 2.3052 - val_accuracy: 0.0976 - val_loss: 2.3036\n",
      "Epoch 54/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1018 - loss: 2.3046 - val_accuracy: 0.1010 - val_loss: 2.3045\n",
      "Epoch 55/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1004 - loss: 2.3051 - val_accuracy: 0.1026 - val_loss: 2.3040\n",
      "Epoch 56/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0997 - loss: 2.3048 - val_accuracy: 0.0976 - val_loss: 2.3050\n",
      "Epoch 57/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1011 - loss: 2.3051 - val_accuracy: 0.1008 - val_loss: 2.3064\n",
      "Epoch 58/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3049 - val_accuracy: 0.0976 - val_loss: 2.3053\n",
      "Epoch 59/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3049 - val_accuracy: 0.1026 - val_loss: 2.3045\n",
      "Epoch 60/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1051 - loss: 2.3046 - val_accuracy: 0.1008 - val_loss: 2.3037\n",
      "\n",
      "Tasa aprendizaje: 0.0001\n",
      "Entrenamiento accuracy: 0.10335999727249146\n",
      "Validacion accuracy: 0.10080000013113022\n",
      "Tiempo: 140.0\n",
      "Mejor epoca: 59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Limpiamos memoria\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# estandarizar\n",
    "media = np.mean(x_train, axis=(0, 1, 2))\n",
    "desviacion = np.std(x_train, axis=(0, 1, 2))\n",
    "x_train = (x_train - media) / desviacion\n",
    "x_val = (x_val - media) / desviacion\n",
    "x_test = (x_test - media) / desviacion\n",
    "\n",
    "\n",
    "# crear red\n",
    "model = tf.keras.Sequential()      # creacion del modelo\n",
    "model.add(tf.keras.layers.Input(shape=(32,32,3)))    # capa entrada,   shape= imagen de 32x32 a color 3\n",
    "model.add(tf.keras.layers.Flatten())      # capa flatten\n",
    "for i in range(20):        \n",
    "    model.add(tf.keras.layers.Dense(100, activation='selu', kernel_initializer=tf.keras.initializers.LecunNormal))    # las 20 capas ocultas de 100 neuronas activacion swish\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))     # capa salida \n",
    "\n",
    "mejor_lr_F, historial_F = ej_CyD(model,'F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G\n",
    "Prueba ahora a regularizar el modelo anterior añadiendo una capa dropout antes de la última capa (estandariza manualmente como en el punto anterior).\n",
    "\n",
    "Repite C y D con esta nueva red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1920 - loss: 2.4504 - val_accuracy: 0.3278 - val_loss: 1.9106\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3014 - loss: 1.9857 - val_accuracy: 0.3676 - val_loss: 1.7882\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3414 - loss: 1.8611 - val_accuracy: 0.3948 - val_loss: 1.7192\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3699 - loss: 1.7832 - val_accuracy: 0.4162 - val_loss: 1.6785\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3948 - loss: 1.7076 - val_accuracy: 0.4288 - val_loss: 1.6381\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4129 - loss: 1.6575 - val_accuracy: 0.4336 - val_loss: 1.6074\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4310 - loss: 1.6042 - val_accuracy: 0.4418 - val_loss: 1.6007\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4411 - loss: 1.5720 - val_accuracy: 0.4502 - val_loss: 1.5833\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4527 - loss: 1.5487 - val_accuracy: 0.4536 - val_loss: 1.5694\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4638 - loss: 1.5146 - val_accuracy: 0.4608 - val_loss: 1.5526\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4607999920845032    Validacion accuracy: 0.4607999920845032    Tiempo: 27.522173643112183    \n",
      "Mejor lr:  1e-05 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.3072 - loss: 1.9801 - val_accuracy: 0.4210 - val_loss: 1.6603\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4046 - loss: 1.6893 - val_accuracy: 0.4386 - val_loss: 1.6070\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4462 - loss: 1.5693 - val_accuracy: 0.4634 - val_loss: 1.5525\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4782 - loss: 1.4922 - val_accuracy: 0.4770 - val_loss: 1.5376\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4976 - loss: 1.4392 - val_accuracy: 0.4938 - val_loss: 1.4622\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5170 - loss: 1.3852 - val_accuracy: 0.4872 - val_loss: 1.4779\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5362 - loss: 1.3404 - val_accuracy: 0.5052 - val_loss: 1.4460\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5543 - loss: 1.3007 - val_accuracy: 0.4950 - val_loss: 1.4486\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5620 - loss: 1.2697 - val_accuracy: 0.5314 - val_loss: 1.3883\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5811 - loss: 1.2301 - val_accuracy: 0.5024 - val_loss: 1.4401\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4607999920845032    Validacion accuracy: 0.4607999920845032    Tiempo: 27.522173643112183    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5764200091362    Validacion accuracy: 0.5023999810218811    Tiempo: 27.608420848846436    \n",
      "Mejor lr:  0.0005 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6295 - loss: 1.0744 - val_accuracy: 0.5432 - val_loss: 1.3795\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6605 - loss: 0.9821 - val_accuracy: 0.5426 - val_loss: 1.3829\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6774 - loss: 0.9433 - val_accuracy: 0.5360 - val_loss: 1.4061\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6857 - loss: 0.9171 - val_accuracy: 0.5370 - val_loss: 1.4154\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6967 - loss: 0.8934 - val_accuracy: 0.5322 - val_loss: 1.4483\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7060 - loss: 0.8599 - val_accuracy: 0.5348 - val_loss: 1.4600\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7134 - loss: 0.8392 - val_accuracy: 0.5302 - val_loss: 1.4890\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7241 - loss: 0.8177 - val_accuracy: 0.5344 - val_loss: 1.4962\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7383 - loss: 0.7852 - val_accuracy: 0.5252 - val_loss: 1.5298\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7422 - loss: 0.7632 - val_accuracy: 0.5276 - val_loss: 1.5441\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4607999920845032    Validacion accuracy: 0.4607999920845032    Tiempo: 27.522173643112183    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5764200091362    Validacion accuracy: 0.5023999810218811    Tiempo: 27.608420848846436    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7378000020980835    Validacion accuracy: 0.5275999903678894    Tiempo: 26.994523763656616    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1652 - loss: 2.5058 - val_accuracy: 0.1014 - val_loss: 2.3206\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1003 - loss: 2.4378 - val_accuracy: 0.0990 - val_loss: 2.3431\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1002 - loss: 2.3891 - val_accuracy: 0.1028 - val_loss: 2.3792\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3798 - val_accuracy: 0.1024 - val_loss: 2.3334\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0974 - loss: 2.3774 - val_accuracy: 0.1014 - val_loss: 2.4248\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1012 - loss: 2.3786 - val_accuracy: 0.1008 - val_loss: 2.3227\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3789 - val_accuracy: 0.1010 - val_loss: 2.3602\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3827 - val_accuracy: 0.0990 - val_loss: 2.3783\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1011 - loss: 2.3798 - val_accuracy: 0.0982 - val_loss: 2.3682\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0984 - loss: 2.3813 - val_accuracy: 0.0976 - val_loss: 2.3634\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4607999920845032    Validacion accuracy: 0.4607999920845032    Tiempo: 27.522173643112183    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5764200091362    Validacion accuracy: 0.5023999810218811    Tiempo: 27.608420848846436    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7378000020980835    Validacion accuracy: 0.5275999903678894    Tiempo: 26.994523763656616    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.09796000272035599    Validacion accuracy: 0.09759999811649323    Tiempo: 27.22620153427124    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1007 - loss: 2.3386 - val_accuracy: 0.1008 - val_loss: 2.3112\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1022 - loss: 2.3248 - val_accuracy: 0.0976 - val_loss: 2.3243\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1004 - loss: 2.3259 - val_accuracy: 0.1008 - val_loss: 2.3195\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1015 - loss: 2.3234 - val_accuracy: 0.1014 - val_loss: 2.3147\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3247 - val_accuracy: 0.1008 - val_loss: 2.3243\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1000 - loss: 2.3260 - val_accuracy: 0.1008 - val_loss: 2.3219\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1013 - loss: 2.3241 - val_accuracy: 0.1024 - val_loss: 2.3415\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1026 - loss: 2.3231 - val_accuracy: 0.1026 - val_loss: 2.3114\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0996 - loss: 2.3247 - val_accuracy: 0.0982 - val_loss: 2.3130\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1007 - loss: 2.3249 - val_accuracy: 0.0976 - val_loss: 2.3127\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4607999920845032    Validacion accuracy: 0.4607999920845032    Tiempo: 27.522173643112183    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5764200091362    Validacion accuracy: 0.5023999810218811    Tiempo: 27.608420848846436    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7378000020980835    Validacion accuracy: 0.5275999903678894    Tiempo: 26.994523763656616    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.09796000272035599    Validacion accuracy: 0.09759999811649323    Tiempo: 27.22620153427124    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.0993800014257431    Validacion accuracy: 0.09759999811649323    Tiempo: 27.51779866218567    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 3.2308 - val_accuracy: 0.1010 - val_loss: 3.2676\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0967 - loss: 3.0717 - val_accuracy: 0.1024 - val_loss: 3.6810\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0960 - loss: 3.1015 - val_accuracy: 0.1010 - val_loss: 3.1578\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 3.0452 - val_accuracy: 0.1008 - val_loss: 2.9680\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1001 - loss: 3.0630 - val_accuracy: 0.0976 - val_loss: 3.1445\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0987 - loss: 3.0480 - val_accuracy: 0.0990 - val_loss: 2.8231\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0998 - loss: 3.0634 - val_accuracy: 0.0994 - val_loss: 4.0752\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1036 - loss: 3.0653 - val_accuracy: 0.0990 - val_loss: 3.0843\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 3.0966 - val_accuracy: 0.1026 - val_loss: 4.1017\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1004 - loss: 3.1060 - val_accuracy: 0.1024 - val_loss: 2.8778\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4607999920845032    Validacion accuracy: 0.4607999920845032    Tiempo: 27.522173643112183    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5764200091362    Validacion accuracy: 0.5023999810218811    Tiempo: 27.608420848846436    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7378000020980835    Validacion accuracy: 0.5275999903678894    Tiempo: 26.994523763656616    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.09796000272035599    Validacion accuracy: 0.09759999811649323    Tiempo: 27.22620153427124    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.0993800014257431    Validacion accuracy: 0.09759999811649323    Tiempo: 27.51779866218567    \n",
      "Tasa aprendizaje: 0.05    Entrenamiento accuracy: 0.10044000297784805    Validacion accuracy: 0.10239999741315842    Tiempo: 27.561628341674805    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 2.4716 - val_accuracy: 0.0990 - val_loss: 2.4133\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1016 - loss: 2.4363 - val_accuracy: 0.1008 - val_loss: 2.4572\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1036 - loss: 2.4363 - val_accuracy: 0.0990 - val_loss: 2.5158\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0984 - loss: 2.4410 - val_accuracy: 0.1014 - val_loss: 2.4502\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0993 - loss: 2.4404 - val_accuracy: 0.1008 - val_loss: 2.4832\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0970 - loss: 2.4424 - val_accuracy: 0.0976 - val_loss: 2.3430\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1020 - loss: 2.4318 - val_accuracy: 0.1014 - val_loss: 2.3196\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1029 - loss: 2.4370 - val_accuracy: 0.1010 - val_loss: 2.3926\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0991 - loss: 2.4431 - val_accuracy: 0.0976 - val_loss: 2.4381\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0999 - loss: 2.4347 - val_accuracy: 0.0990 - val_loss: 2.4941\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4607999920845032    Validacion accuracy: 0.4607999920845032    Tiempo: 27.522173643112183    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5764200091362    Validacion accuracy: 0.5023999810218811    Tiempo: 27.608420848846436    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7378000020980835    Validacion accuracy: 0.5275999903678894    Tiempo: 26.994523763656616    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.09796000272035599    Validacion accuracy: 0.09759999811649323    Tiempo: 27.22620153427124    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.0993800014257431    Validacion accuracy: 0.09759999811649323    Tiempo: 27.51779866218567    \n",
      "Tasa aprendizaje: 0.05    Entrenamiento accuracy: 0.10044000297784805    Validacion accuracy: 0.10239999741315842    Tiempo: 27.561628341674805    \n",
      "Tasa aprendizaje: 0.01    Entrenamiento accuracy: 0.10000000149011612    Validacion accuracy: 0.0989999994635582    Tiempo: 27.657562017440796    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0974 - loss: 2.4378 - val_accuracy: 0.0976 - val_loss: 2.4094\n",
      "Epoch 2/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 2.4381 - val_accuracy: 0.0982 - val_loss: 2.3996\n",
      "Epoch 3/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0981 - loss: 2.4377 - val_accuracy: 0.0976 - val_loss: 2.3642\n",
      "Epoch 4/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0984 - loss: 2.4374 - val_accuracy: 0.0994 - val_loss: 2.5186\n",
      "Epoch 5/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1001 - loss: 2.4370 - val_accuracy: 0.1010 - val_loss: 2.3856\n",
      "Epoch 6/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1001 - loss: 2.4438 - val_accuracy: 0.1014 - val_loss: 2.4490\n",
      "Epoch 7/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.4372 - val_accuracy: 0.0982 - val_loss: 2.4386\n",
      "Epoch 1/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1021 - loss: 2.3495 - val_accuracy: 0.1024 - val_loss: 2.3038\n",
      "Epoch 2/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0997 - loss: 2.3403 - val_accuracy: 0.1026 - val_loss: 2.3050\n",
      "Epoch 3/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1004 - loss: 2.3308 - val_accuracy: 0.1010 - val_loss: 2.3046\n",
      "Epoch 4/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1013 - loss: 2.3261 - val_accuracy: 0.0990 - val_loss: 2.3037\n",
      "Epoch 5/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3223 - val_accuracy: 0.0976 - val_loss: 2.3044\n",
      "Epoch 6/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3177 - val_accuracy: 0.1008 - val_loss: 2.3053\n",
      "Epoch 7/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1011 - loss: 2.3162 - val_accuracy: 0.1008 - val_loss: 2.3033\n",
      "Epoch 8/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0979 - loss: 2.3144 - val_accuracy: 0.0994 - val_loss: 2.3054\n",
      "Epoch 9/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0971 - loss: 2.3133 - val_accuracy: 0.0990 - val_loss: 2.3046\n",
      "Epoch 10/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1009 - loss: 2.3113 - val_accuracy: 0.1024 - val_loss: 2.3046\n",
      "Epoch 11/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 2.3093 - val_accuracy: 0.0976 - val_loss: 2.3044\n",
      "Epoch 12/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 2.3082 - val_accuracy: 0.0990 - val_loss: 2.3058\n",
      "Epoch 13/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3084 - val_accuracy: 0.1026 - val_loss: 2.3035\n",
      "Epoch 14/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3076 - val_accuracy: 0.0990 - val_loss: 2.3045\n",
      "Epoch 15/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1018 - loss: 2.3061 - val_accuracy: 0.1008 - val_loss: 2.3046\n",
      "Epoch 16/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1015 - loss: 2.3069 - val_accuracy: 0.1010 - val_loss: 2.3032\n",
      "Epoch 17/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1001 - loss: 2.3067 - val_accuracy: 0.0976 - val_loss: 2.3048\n",
      "Epoch 18/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3063 - val_accuracy: 0.0990 - val_loss: 2.3053\n",
      "Epoch 19/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0975 - loss: 2.3060 - val_accuracy: 0.1008 - val_loss: 2.3035\n",
      "Epoch 20/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1024 - loss: 2.3053 - val_accuracy: 0.1010 - val_loss: 2.3043\n",
      "Epoch 21/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1009 - loss: 2.3057 - val_accuracy: 0.1008 - val_loss: 2.3068\n",
      "Epoch 22/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1003 - loss: 2.3058 - val_accuracy: 0.0976 - val_loss: 2.3050\n",
      "Epoch 23/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0961 - loss: 2.3056 - val_accuracy: 0.0976 - val_loss: 2.3039\n",
      "Epoch 24/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3060 - val_accuracy: 0.0976 - val_loss: 2.3046\n",
      "Epoch 25/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1005 - loss: 2.3053 - val_accuracy: 0.1008 - val_loss: 2.3043\n",
      "Epoch 26/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1004 - loss: 2.3056 - val_accuracy: 0.1014 - val_loss: 2.3032\n",
      "Epoch 27/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0993 - loss: 2.3052 - val_accuracy: 0.1014 - val_loss: 2.3042\n",
      "Epoch 28/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1019 - loss: 2.3052 - val_accuracy: 0.0990 - val_loss: 2.3038\n",
      "Epoch 29/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1025 - loss: 2.3051 - val_accuracy: 0.0990 - val_loss: 2.3044\n",
      "Epoch 30/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0981 - loss: 2.3053 - val_accuracy: 0.0994 - val_loss: 2.3036\n",
      "Epoch 31/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1001 - loss: 2.3055 - val_accuracy: 0.1010 - val_loss: 2.3042\n",
      "Epoch 32/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3055 - val_accuracy: 0.1010 - val_loss: 2.3058\n",
      "Epoch 33/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 2.3052 - val_accuracy: 0.1014 - val_loss: 2.3034\n",
      "Epoch 34/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 2.3052 - val_accuracy: 0.0994 - val_loss: 2.3039\n",
      "Epoch 35/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0976 - loss: 2.3053 - val_accuracy: 0.0976 - val_loss: 2.3035\n",
      "Epoch 36/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 2.3050 - val_accuracy: 0.0994 - val_loss: 2.3059\n",
      "Epoch 37/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0987 - loss: 2.3056 - val_accuracy: 0.1014 - val_loss: 2.3051\n",
      "Epoch 38/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1018 - loss: 2.3054 - val_accuracy: 0.0994 - val_loss: 2.3036\n",
      "Epoch 39/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3052 - val_accuracy: 0.1024 - val_loss: 2.3058\n",
      "Epoch 40/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0976 - loss: 2.3059 - val_accuracy: 0.1014 - val_loss: 2.3041\n",
      "Epoch 41/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0977 - loss: 2.3052 - val_accuracy: 0.1024 - val_loss: 2.3038\n",
      "Epoch 42/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1003 - loss: 2.3048 - val_accuracy: 0.0976 - val_loss: 2.3061\n",
      "Epoch 43/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3053 - val_accuracy: 0.0990 - val_loss: 2.3041\n",
      "Epoch 44/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3053 - val_accuracy: 0.1010 - val_loss: 2.3028\n",
      "Epoch 45/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0998 - loss: 2.3052 - val_accuracy: 0.0976 - val_loss: 2.3057\n",
      "Epoch 46/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3056 - val_accuracy: 0.1010 - val_loss: 2.3035\n",
      "Epoch 47/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0996 - loss: 2.3051 - val_accuracy: 0.0990 - val_loss: 2.3038\n",
      "Epoch 48/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0976 - loss: 2.3056 - val_accuracy: 0.0990 - val_loss: 2.3062\n",
      "Epoch 49/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1016 - loss: 2.3055 - val_accuracy: 0.1024 - val_loss: 2.3039\n",
      "Epoch 50/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0959 - loss: 2.3053 - val_accuracy: 0.1008 - val_loss: 2.3043\n",
      "Epoch 51/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0986 - loss: 2.3053 - val_accuracy: 0.0982 - val_loss: 2.3040\n",
      "Epoch 52/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1017 - loss: 2.3047 - val_accuracy: 0.1014 - val_loss: 2.3050\n",
      "Epoch 53/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0962 - loss: 2.3054 - val_accuracy: 0.0994 - val_loss: 2.3049\n",
      "Epoch 54/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 2.3052 - val_accuracy: 0.1010 - val_loss: 2.3050\n",
      "Epoch 55/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1002 - loss: 2.3051 - val_accuracy: 0.0990 - val_loss: 2.3044\n",
      "Epoch 56/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1028 - loss: 2.3050 - val_accuracy: 0.0990 - val_loss: 2.3058\n",
      "Epoch 57/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0996 - loss: 2.3056 - val_accuracy: 0.1008 - val_loss: 2.3048\n",
      "Epoch 58/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3053 - val_accuracy: 0.1014 - val_loss: 2.3057\n",
      "Epoch 59/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0947 - loss: 2.3051 - val_accuracy: 0.0976 - val_loss: 2.3040\n",
      "Epoch 60/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1029 - loss: 2.3051 - val_accuracy: 0.0994 - val_loss: 2.3043\n",
      "\n",
      "Tasa aprendizaje: 0.0001\n",
      "Entrenamiento accuracy: 0.10057999938726425\n",
      "Validacion accuracy: 0.09939999878406525\n",
      "Tiempo: 140.0\n",
      "Mejor epoca: 28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# con la estandarizacion de F es suficiente, no es necesario estandarizar de nuevo\n",
    "\n",
    "# Limpiamos memoria\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "# crear red\n",
    "model = tf.keras.Sequential()      # creacion del modelo\n",
    "model.add(tf.keras.layers.Input(shape=(32,32,3)))    # capa entrada,   shape= imagen de 32x32 a color 3\n",
    "model.add(tf.keras.layers.Flatten())      # capa flatten\n",
    "for i in range(20):        \n",
    "    model.add(tf.keras.layers.Dense(100, activation='selu', kernel_initializer=tf.keras.initializers.LecunNormal))    # las 20 capas ocultas de 100 neuronas activacion swish\n",
    "model.add(tf.keras.layers.Dropout(0.2))     # capa dropout ('apaga' un porcentaje de neuronas al azar)\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))     # capa salida \n",
    "\n",
    "mejor_lr_G, historial_G = ej_CyD(model,'G')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iabd_3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
