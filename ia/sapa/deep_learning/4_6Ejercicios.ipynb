{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 04:31:55.736074: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-15 04:31:55.743442: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-15 04:31:55.752176: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-15 04:31:55.754833: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-15 04:31:55.762836: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "from keras.activations import swish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practica cómo entrenar una red neuronal profunda con el conjunto de datos de imágenes CIFAR10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A\n",
    "El conjunto de datos está compuesto por 60.000 imágenes en color de 32 x 32 píxe­les (50.000 para el entrenamiento, 5.000 para la validación y 5.000 para las pruebas) con 10 clases. Puedes cargarlo con tf.keras.datasets.cifar10.load_data(). Muestra una de la imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos las tuplas en x e y\n",
    "(x_train_full, y_train_full), (x_test_full, y_test_full) = datos\n",
    "\n",
    "# 50,000 entrenamiento\n",
    "x_train = x_train_full[:50000]\n",
    "y_train = y_train_full[:50000]\n",
    "\n",
    "# 5,000 validación\n",
    "x_val = x_test_full[:5000]\n",
    "y_val = y_test_full[:5000]\n",
    "\n",
    "# 5,000 prueba\n",
    "x_test = x_test_full[5000:10000]\n",
    "y_test = y_test_full[5000:10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# muestra una imagen\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(x_train[8])\n",
    "plt.axis('off')   # quita los ejes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B\n",
    "Crea una RNP con 20 capas ocultas de 100 neuronas cada una (son demasiadas,\n",
    "pero esa es la gracia del ejercicio). \n",
    "\n",
    "Utiliza la inicialización He y la función de activa­ción Swish. \n",
    "\n",
    "Antes de las 20 capas tendras que añadir una capa Input y una capa Flatten y despúes una capa de de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1736911927.235747    9086 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1736911927.265645    9086 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1736911927.265829    9086 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1736911927.268390    9086 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1736911927.268617    9086 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1736911927.268777    9086 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1736911927.307962    9086 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1736911927.308106    9086 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1736911927.308190    9086 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-15 04:32:07.308266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10268 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">307,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m307,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,210</span> (1.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m500,210\u001b[0m (1.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,210</span> (1.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m500,210\u001b[0m (1.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()      # creacion del modelo\n",
    "model.add(tf.keras.layers.Input(shape=(32,32,3)))    # capa entrada,   shape= imagen de 32x32 a color 3\n",
    "model.add(tf.keras.layers.Flatten())      # capa flatten\n",
    "for i in range(20):        \n",
    "    model.add(tf.keras.layers.Dense(100, activation=swish, kernel_initializer='he_normal'))    # las 20 capas ocultas de 100 neuronas activacion swish\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))     # capa salida \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C\n",
    "Elige una tasa de aprendizaje adecuada para la optimización Nadam.\n",
    "\n",
    "Para probar los diferentes modelos haz un bucle (después de cada entrenamiento evalua X_train y X_valid y guarda en un diccionario para \"Red neuronal normal\")\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "\n",
    "[{\n",
    "\n",
    "    'Red neuronal normal': {\n",
    "\n",
    "        'Tasa de aprendizaje': X,\n",
    "\n",
    "        'Entrenamiento sparse categorical accuracy': X,\n",
    "\n",
    "        'Validación sparse categorical accuracy': X,\n",
    "\n",
    "        'Tiempo total (s)': X\n",
    "\n",
    "    }\n",
    "    \n",
    "}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736911936.875276    9187 service.cc:146] XLA service 0x7fe6f4026800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1736911936.875337    9187 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4080 Laptop GPU, Compute Capability 8.9\n",
      "2025-01-15 04:32:17.016147: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-01-15 04:32:17.239593: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 104/1563\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1016 - loss: 80.5041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736911938.012938    9187 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.1142 - loss: 20.0085 - val_accuracy: 0.1666 - val_loss: 2.7409\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1650 - loss: 2.5454 - val_accuracy: 0.2082 - val_loss: 2.2498\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2117 - loss: 2.2013 - val_accuracy: 0.2612 - val_loss: 2.0718\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2479 - loss: 2.0805 - val_accuracy: 0.2662 - val_loss: 2.0142\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2661 - loss: 2.0030 - val_accuracy: 0.2806 - val_loss: 1.9541\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2920 - loss: 1.9366 - val_accuracy: 0.3134 - val_loss: 1.8942\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3051 - loss: 1.8982 - val_accuracy: 0.3226 - val_loss: 1.8552\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3229 - loss: 1.8558 - val_accuracy: 0.3396 - val_loss: 1.8117\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3362 - loss: 1.8262 - val_accuracy: 0.3440 - val_loss: 1.8048\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3489 - loss: 1.7979 - val_accuracy: 0.3584 - val_loss: 1.7748\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1825 - loss: 2.9613 - val_accuracy: 0.2736 - val_loss: 1.9197\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2890 - loss: 1.9235 - val_accuracy: 0.2850 - val_loss: 1.9269\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3346 - loss: 1.8239 - val_accuracy: 0.3510 - val_loss: 1.7642\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3485 - loss: 1.7906 - val_accuracy: 0.3622 - val_loss: 1.7587\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3635 - loss: 1.7556 - val_accuracy: 0.3968 - val_loss: 1.6785\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3794 - loss: 1.7241 - val_accuracy: 0.3998 - val_loss: 1.6666\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4002 - loss: 1.6788 - val_accuracy: 0.4080 - val_loss: 1.6634\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4097 - loss: 1.6506 - val_accuracy: 0.4296 - val_loss: 1.5935\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4087 - loss: 1.6296 - val_accuracy: 0.4242 - val_loss: 1.6026\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4173 - loss: 1.6138 - val_accuracy: 0.4374 - val_loss: 1.5839\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4565 - loss: 1.5110 - val_accuracy: 0.4538 - val_loss: 1.5180\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4665 - loss: 1.4762 - val_accuracy: 0.4590 - val_loss: 1.5072\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4672 - loss: 1.4784 - val_accuracy: 0.4620 - val_loss: 1.5015\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4681 - loss: 1.4699 - val_accuracy: 0.4602 - val_loss: 1.5091\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4815 - loss: 1.4476 - val_accuracy: 0.4612 - val_loss: 1.5112\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4803 - loss: 1.4403 - val_accuracy: 0.4608 - val_loss: 1.4995\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4886 - loss: 1.4262 - val_accuracy: 0.4644 - val_loss: 1.4980\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4852 - loss: 1.4239 - val_accuracy: 0.4590 - val_loss: 1.5139\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4912 - loss: 1.4094 - val_accuracy: 0.4660 - val_loss: 1.5008\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4970 - loss: 1.3997 - val_accuracy: 0.4594 - val_loss: 1.5085\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1108 - loss: 2.3976 - val_accuracy: 0.0976 - val_loss: 2.3045\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0973 - loss: 2.3637 - val_accuracy: 0.1026 - val_loss: 2.3030\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0997 - loss: 2.3036 - val_accuracy: 0.0994 - val_loss: 2.3033\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0974 - loss: 2.3032 - val_accuracy: 0.1010 - val_loss: 2.3033\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0976 - loss: 2.3033 - val_accuracy: 0.1010 - val_loss: 2.3035\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1004 - loss: 2.3034 - val_accuracy: 0.1008 - val_loss: 2.3028\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0969 - loss: 2.3033 - val_accuracy: 0.0990 - val_loss: 2.3038\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3034 - val_accuracy: 0.0976 - val_loss: 2.3029\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1013 - loss: 2.3032 - val_accuracy: 0.1014 - val_loss: 2.3029\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1008 - loss: 2.3034 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.0982 - loss: 2.3028 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1001 - loss: 2.3027 - val_accuracy: 0.1024 - val_loss: 2.3026\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64782s\u001b[0m 41s/step - accuracy: 0.1003 - loss: 2.3028 - val_accuracy: 0.1024 - val_loss: 2.3026\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-7198s\u001b[0m -4608042us/step - accuracy: 0.1001 - loss: 2.3027 - val_accuracy: 0.0990 - val_loss: 2.3027\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1010 - loss: 2.3028 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3027 - val_accuracy: 0.0976 - val_loss: 2.3027\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0992 - loss: 2.3027 - val_accuracy: 0.0990 - val_loss: 2.3027\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0977 - loss: 2.3028 - val_accuracy: 0.0976 - val_loss: 2.3027\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0976 - loss: 2.3028 - val_accuracy: 0.0990 - val_loss: 2.3027\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0978 - loss: 2.3028 - val_accuracy: 0.0976 - val_loss: 2.3027\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.3088 - val_accuracy: 0.1026 - val_loss: 2.3069\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0947 - loss: 2.3091 - val_accuracy: 0.1014 - val_loss: 2.3065\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.3081 - val_accuracy: 0.1008 - val_loss: 2.3062\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0998 - loss: 2.3089 - val_accuracy: 0.1026 - val_loss: 2.3090\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1008 - loss: 2.3086 - val_accuracy: 0.1010 - val_loss: 2.3108\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0995 - loss: 2.3090 - val_accuracy: 0.1014 - val_loss: 2.3067\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1005 - loss: 2.3088 - val_accuracy: 0.1008 - val_loss: 2.3074\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0996 - loss: 2.3090 - val_accuracy: 0.0994 - val_loss: 2.3108\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1004 - loss: 2.3091 - val_accuracy: 0.0994 - val_loss: 2.3051\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1006 - loss: 2.3080 - val_accuracy: 0.1008 - val_loss: 2.3054\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.0968 - loss: 2.3041 - val_accuracy: 0.0976 - val_loss: 2.3048\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1005 - loss: 2.3040 - val_accuracy: 0.0990 - val_loss: 2.3034\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0978 - loss: 2.3041 - val_accuracy: 0.0982 - val_loss: 2.3032\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0969 - loss: 2.3043 - val_accuracy: 0.0976 - val_loss: 2.3046\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1032 - loss: 2.3037 - val_accuracy: 0.0990 - val_loss: 2.3037\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.3041 - val_accuracy: 0.0976 - val_loss: 2.3044\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0990 - loss: 166623.2344 - val_accuracy: 0.0976 - val_loss: 2.3035\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1017 - loss: 2.3037 - val_accuracy: 0.1014 - val_loss: 2.3047\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0979 - loss: 2.3044 - val_accuracy: 0.0976 - val_loss: 2.3047\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1017 - loss: 2.3039 - val_accuracy: 0.0990 - val_loss: 2.3042\n"
     ]
    }
   ],
   "source": [
    "historial = {}\n",
    "rangos = [1e-5, 5e-4 , 1e-4 , 5e-3 , 1e-3 , 5e-2 , 1e-2]\n",
    "\n",
    "for lr in rangos:\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Nadam(learning_rate=lr),  \n",
    "              metrics=['accuracy'])\n",
    "    time_ini = time.time()\n",
    "    hist = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
    "    time_fin = time.time()\n",
    "    \n",
    "    historial[lr] = {'Tasa aprendizaje': lr, 'Entrenamiento accuracy': hist.history['accuracy'][-1], \n",
    "                     'Validacion accuracy': hist.history['val_accuracy'][-1], 'Tiempo': time_fin-time_ini}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.34845998883247375    Validacion accuracy: 0.35839998722076416    Tiempo: 27.992127895355225    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.4192200005054474    Validacion accuracy: 0.4374000132083893    Tiempo: 29.62821388244629    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.4935399889945984    Validacion accuracy: 0.4593999981880188    Tiempo: 28.677001953125    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.09907999634742737    Validacion accuracy: 0.10140000283718109    Tiempo: 27.947672367095947    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.0983399972319603    Validacion accuracy: 0.09759999811649323    Tiempo: 57608.54164338112    \n",
      "Tasa aprendizaje: 0.05    Entrenamiento accuracy: 0.09976000338792801    Validacion accuracy: 0.10080000013113022    Tiempo: 30.36816120147705    \n",
      "Tasa aprendizaje: 0.01    Entrenamiento accuracy: 0.09989999979734421    Validacion accuracy: 0.0989999994635582    Tiempo: 30.798951148986816    \n",
      "Mejor lr:  0.0001\n"
     ]
    }
   ],
   "source": [
    "mejor_lr = 0\n",
    "mejor_val_acc = -2\n",
    "for k,value in historial.items(): \n",
    "    txt = ''\n",
    "    for key in value.keys(): txt += str(key)+': '+str(value[key])+'    '\n",
    "    print(txt)\n",
    "    if mejor_val_acc < value['Validacion accuracy']:\n",
    "        mejor_val_acc = value['Validacion accuracy']\n",
    "        mejor_lr = k\n",
    "print('Mejor lr: ',mejor_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D\n",
    " Una vez elegida la tasa de aprendizaje entrena el modelo usando la detención temprana (ahora que tienes detención temprana aumenta el número de epochs).\n",
    "\n",
    " Añade los resultados al diccionario anterior, hay que añadir:\n",
    "\n",
    "[{\n",
    "\n",
    "    'Red neuronal normal con detención temprana': {\n",
    "\n",
    "        'Tasa de aprendizaje': X,\n",
    "\n",
    "        'Entrenamiento sparse categorical accuracy': X,\n",
    "\n",
    "        'Validación sparse categorical accuracy': X,\n",
    "\n",
    "        'Tiempo total (s)': X,\n",
    "\n",
    "        'Mejor época': X\n",
    "\n",
    "    }\n",
    "    \n",
    "}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"./recursos/checkpoint/4_6_D_checkpoints.weights.h5\", save_weights_only=True)\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=70, validation_data=(x_val, y_val), \n",
    "                     callbacks=[checkpoint_cb,early_stopping_cb])\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "            optimizer=tf.keras.optimizers.Nadam(learning_rate=mejor_lr),   # asignar tasa de aprendizaje\n",
    "            metrics=['accuracy'])\n",
    "time_ini = time.time()\n",
    "hist = model.fit(x_train, y_train, epochs=60, validation_data=(x_val, y_val))\n",
    "time_fin = time.time()\n",
    "\n",
    "historial[mejor_lr] = ({'Tasa aprendizaje': mejor_lr, 'Entrenamiento accuracy': hist.history['accuracy'][-1], \n",
    "                    'Validacion accuracy': hist.history['val_accuracy'][-1], 'Tiempo': time_fin-time_ini})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E\n",
    "Ahora, prueba a añadir normalización de lotes y repite C y D con esta nueva red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iabd/anaconda3/envs/iabd_3_9/lib/python3.9/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# crear red\n",
    "model = tf.keras.Sequential()      # creacion del modelo\n",
    "model.add(tf.keras.layers.Input(shape=(32,32,3)))    # capa entrada,   shape= imagen de 32x32 a color 3\n",
    "model.add(tf.keras.layers.Flatten())      # capa flatten\n",
    "model.add(tf.keras.layers.Normalization(input_shape=(32,32,3)))\n",
    "for i in range(20):        \n",
    "    model.add(tf.keras.layers.Dense(100, activation=swish, kernel_initializer='he_normal'))    # las 20 capas ocultas de 100 neuronas activacion swish\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))     # capa salida \n",
    "\n",
    "# entrenar\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "            optimizer=tf.keras.optimizers.Nadam(learning_rate=lr),  \n",
    "            metrics=['accuracy'])\n",
    "time_ini = time.time()\n",
    "hist = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
    "time_fin = time.time()\n",
    "\n",
    "historial[lr] = {'Tasa aprendizaje': lr, 'Entrenamiento accuracy': hist.history['accuracy'][-1], \n",
    "                    'Validacion accuracy': hist.history['val_accuracy'][-1], 'Tiempo': time_fin-time_ini,\n",
    "                    'Mejor epoca':0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F\n",
    "Prueba a sustituir la normalización de lotes por la activación SELU y haz los ajustes necesarios para garantizar que la red se autonormaliza (es decir, tienes que estandarizar los datos antes de empezar).\n",
    "\n",
    "En este caso prueba a estandarizar manualmentes, es decir restando la media y dividiendo por la desviación standard.\n",
    "\n",
    "Usa la inicialización LeCun normal.\n",
    "\n",
    "Repite C y D con esta nueva red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G\n",
    "Prueba ahora a regularizar el modelo anterior añadiendo una capa dropout antes de la última capa (estandariza manualmente como en el punto anterior).\n",
    "\n",
    "Repite C y D con esta nueva red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iabd_3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
