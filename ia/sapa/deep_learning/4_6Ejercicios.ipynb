{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.activations import swish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practica cómo entrenar una red neuronal profunda con el conjunto de datos de imágenes CIFAR10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A\n",
    "El conjunto de datos está compuesto por 60.000 imágenes en color de 32 x 32 píxe­les (50.000 para el entrenamiento, 5.000 para la validación y 5.000 para las pruebas) con 10 clases. Puedes cargarlo con tf.keras.datasets.cifar10.load_data(). Muestra una de la imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos las tuplas en x e y\n",
    "(x_train_full, y_train_full), (x_test_full, y_test_full) = datos\n",
    "\n",
    "# 50,000 entrenamiento\n",
    "x_train = x_train_full[:50000]\n",
    "y_train = y_train_full[:50000]\n",
    "\n",
    "# 5,000 validación\n",
    "x_val = x_test_full[:5000]\n",
    "y_val = y_test_full[:5000]\n",
    "\n",
    "# 5,000 prueba\n",
    "x_test = x_test_full[5000:10000]\n",
    "y_test = y_test_full[5000:10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# muestra una imagen\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(x_train[8])\n",
    "plt.axis('off')   # quita los ejes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B\n",
    "Crea una RNP con 20 capas ocultas de 100 neuronas cada una (son demasiadas,\n",
    "pero esa es la gracia del ejercicio). \n",
    "\n",
    "Utiliza la inicialización He y la función de activa­ción Swish. \n",
    "\n",
    "Antes de las 20 capas tendras que añadir una capa Input y una capa Flatten y despúes una capa de de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">307,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m307,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,210</span> (1.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m500,210\u001b[0m (1.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,210</span> (1.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m500,210\u001b[0m (1.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()      # creacion del modelo\n",
    "model.add(tf.keras.layers.Input(shape=(32,32,3)))    # capa entrada,   shape= imagen de 32x32 a color 3\n",
    "model.add(tf.keras.layers.Flatten())      # capa flatten\n",
    "for i in range(20):        \n",
    "    model.add(tf.keras.layers.Dense(100, activation=swish, kernel_initializer='he_normal'))    # las 20 capas ocultas de 100 neuronas activacion swish\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))     # capa salida \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C\n",
    "Elige una tasa de aprendizaje adecuada para la optimización Nadam.\n",
    "\n",
    "Para probar los diferentes modelos haz un bucle (después de cada entrenamiento evalua X_train y X_valid y guarda en un diccionario para \"Red neuronal normal\")\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "\n",
    "[{\n",
    "\n",
    "    'Red neuronal normal': {\n",
    "\n",
    "        'Tasa de aprendizaje': X,\n",
    "\n",
    "        'Entrenamiento sparse categorical accuracy': X,\n",
    "\n",
    "        'Validación sparse categorical accuracy': X,\n",
    "\n",
    "        'Tiempo total (s)': X\n",
    "\n",
    "    }\n",
    "    \n",
    "}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5ms/step - accuracy: 0.1068 - loss: 31.5792 - val_accuracy: 0.1376 - val_loss: 3.3590\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1419 - loss: 3.0356 - val_accuracy: 0.1690 - val_loss: 2.5138\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1690 - loss: 2.4364 - val_accuracy: 0.1858 - val_loss: 2.3010\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1951 - loss: 2.2561 - val_accuracy: 0.2186 - val_loss: 2.1628\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2222 - loss: 2.1423 - val_accuracy: 0.2328 - val_loss: 2.0871\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2411 - loss: 2.0545 - val_accuracy: 0.2572 - val_loss: 2.0313\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.2564 - loss: 2.0093 - val_accuracy: 0.2858 - val_loss: 1.9756\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2813 - loss: 1.9586 - val_accuracy: 0.2846 - val_loss: 1.9521\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3001 - loss: 1.9149 - val_accuracy: 0.3094 - val_loss: 1.9036\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3109 - loss: 1.8866 - val_accuracy: 0.3202 - val_loss: 1.8760\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.3292 - loss: 1.8480 - val_accuracy: 0.3270 - val_loss: 1.8606\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3308 - loss: 1.8374 - val_accuracy: 0.3352 - val_loss: 1.8573\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3349 - loss: 1.8336 - val_accuracy: 0.3330 - val_loss: 1.8511\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3382 - loss: 1.8318 - val_accuracy: 0.3350 - val_loss: 1.8441\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3372 - loss: 1.8267 - val_accuracy: 0.3386 - val_loss: 1.8401\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3457 - loss: 1.8104 - val_accuracy: 0.3370 - val_loss: 1.8392\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3491 - loss: 1.8070 - val_accuracy: 0.3404 - val_loss: 1.8370\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3461 - loss: 1.8063 - val_accuracy: 0.3406 - val_loss: 1.8296\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3471 - loss: 1.8008 - val_accuracy: 0.3450 - val_loss: 1.8269\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3489 - loss: 1.7950 - val_accuracy: 0.3446 - val_loss: 1.8274\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.2850 - loss: 1.9674 - val_accuracy: 0.3458 - val_loss: 1.8258\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3331 - loss: 1.8384 - val_accuracy: 0.3560 - val_loss: 1.7893\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3564 - loss: 1.7735 - val_accuracy: 0.3604 - val_loss: 1.8057\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3818 - loss: 1.7175 - val_accuracy: 0.3780 - val_loss: 1.7250\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3967 - loss: 1.6739 - val_accuracy: 0.3940 - val_loss: 1.6845\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4070 - loss: 1.6484 - val_accuracy: 0.4148 - val_loss: 1.6492\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4154 - loss: 1.6240 - val_accuracy: 0.4148 - val_loss: 1.6231\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4285 - loss: 1.5806 - val_accuracy: 0.4250 - val_loss: 1.6016\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4382 - loss: 1.5583 - val_accuracy: 0.4380 - val_loss: 1.5665\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4433 - loss: 1.5477 - val_accuracy: 0.4446 - val_loss: 1.5738\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.4741 - loss: 1.4713 - val_accuracy: 0.4690 - val_loss: 1.5058\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4820 - loss: 1.4416 - val_accuracy: 0.4634 - val_loss: 1.5047\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4849 - loss: 1.4395 - val_accuracy: 0.4658 - val_loss: 1.5090\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4834 - loss: 1.4328 - val_accuracy: 0.4682 - val_loss: 1.4968\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4862 - loss: 1.4247 - val_accuracy: 0.4742 - val_loss: 1.4937\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4945 - loss: 1.4127 - val_accuracy: 0.4668 - val_loss: 1.4984\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4995 - loss: 1.4018 - val_accuracy: 0.4742 - val_loss: 1.4870\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4969 - loss: 1.4037 - val_accuracy: 0.4740 - val_loss: 1.4990\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4994 - loss: 1.3927 - val_accuracy: 0.4748 - val_loss: 1.4831\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5044 - loss: 1.3837 - val_accuracy: 0.4770 - val_loss: 1.4876\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.2149 - loss: 2.1814 - val_accuracy: 0.2952 - val_loss: 1.9479\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3139 - loss: 1.8620 - val_accuracy: 0.3592 - val_loss: 1.7612\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3454 - loss: 1.7966 - val_accuracy: 0.3724 - val_loss: 1.7172\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3741 - loss: 1.7236 - val_accuracy: 0.3940 - val_loss: 1.6835\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.3849 - loss: 1.7010 - val_accuracy: 0.4014 - val_loss: 1.6758\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3974 - loss: 1.6748 - val_accuracy: 0.4162 - val_loss: 1.6354\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4076 - loss: 1.6470 - val_accuracy: 0.4314 - val_loss: 1.5805\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4190 - loss: 1.6169 - val_accuracy: 0.4170 - val_loss: 1.6001\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4293 - loss: 1.6047 - val_accuracy: 0.4324 - val_loss: 1.5784\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4346 - loss: 1.5839 - val_accuracy: 0.4246 - val_loss: 1.5950\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.4644 - loss: 1.4922 - val_accuracy: 0.4652 - val_loss: 1.5016\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4753 - loss: 1.4671 - val_accuracy: 0.4690 - val_loss: 1.4947\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4811 - loss: 1.4489 - val_accuracy: 0.4668 - val_loss: 1.4884\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4818 - loss: 1.4457 - val_accuracy: 0.4754 - val_loss: 1.4892\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4888 - loss: 1.4335 - val_accuracy: 0.4652 - val_loss: 1.4929\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4886 - loss: 1.4273 - val_accuracy: 0.4706 - val_loss: 1.4859\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4913 - loss: 1.4212 - val_accuracy: 0.4716 - val_loss: 1.4909\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.4964 - loss: 1.4086 - val_accuracy: 0.4694 - val_loss: 1.4931\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 1.4030 - val_accuracy: 0.4688 - val_loss: 1.4966\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.5010 - loss: 1.3966 - val_accuracy: 0.4752 - val_loss: 1.4775\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.1104 - loss: 2.8755 - val_accuracy: 0.1008 - val_loss: 2.3028\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0991 - loss: 2.3033 - val_accuracy: 0.0982 - val_loss: 2.3034\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0978 - loss: 2.3034 - val_accuracy: 0.1010 - val_loss: 2.3033\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0979 - loss: 2.3035 - val_accuracy: 0.0976 - val_loss: 2.3033\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0996 - loss: 2.3033 - val_accuracy: 0.0994 - val_loss: 2.3035\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0987 - loss: 2.3034 - val_accuracy: 0.0994 - val_loss: 2.3028\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0986 - loss: 2.3031 - val_accuracy: 0.0976 - val_loss: 2.3031\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0992 - loss: 2.3034 - val_accuracy: 0.0994 - val_loss: 2.3032\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1003 - loss: 2.3033 - val_accuracy: 0.1024 - val_loss: 2.3029\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0996 - loss: 2.3033 - val_accuracy: 0.0994 - val_loss: 2.3029\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.0976 - loss: 2.3029 - val_accuracy: 0.1014 - val_loss: 2.3027\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1004 - loss: 2.3027 - val_accuracy: 0.1026 - val_loss: 2.3026\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1012 - loss: 2.3027 - val_accuracy: 0.1024 - val_loss: 2.3027\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0989 - loss: 2.3028 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0942 - loss: 2.3028 - val_accuracy: 0.0976 - val_loss: 2.3027\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1005 - loss: 2.3027 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0989 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3026\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1011 - loss: 2.3027 - val_accuracy: 0.0976 - val_loss: 2.3027\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0992 - loss: 2.3028 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0975 - loss: 2.3027 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.0998 - loss: 2.3036 - val_accuracy: 0.1024 - val_loss: 2.3035\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1003 - loss: 2.3037 - val_accuracy: 0.0990 - val_loss: 2.3060\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1023 - loss: 2.3038 - val_accuracy: 0.1008 - val_loss: 2.3044\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0991 - loss: 2.3042 - val_accuracy: 0.1008 - val_loss: 2.3045\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0999 - loss: 2.3041 - val_accuracy: 0.0994 - val_loss: 2.3040\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0983 - loss: 2.3041 - val_accuracy: 0.1008 - val_loss: 2.3036\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0993 - loss: 2.3040 - val_accuracy: 0.1026 - val_loss: 2.3033\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.0959 - loss: 2.3042 - val_accuracy: 0.0982 - val_loss: 2.3034\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1005 - loss: 2.3036 - val_accuracy: 0.1024 - val_loss: 2.3039\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0984 - loss: 2.3042 - val_accuracy: 0.1010 - val_loss: 2.3052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': {'Tasa aprendizaje': 1e-05,\n",
       "  'Entrenamiento accuracy': np.float64(0.5007799863815308),\n",
       "  'Validacion accuracy': np.float64(0.47699999809265137),\n",
       "  'Tiempo': 92.61396408081055}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historial = {'C':{'Tasa aprendizaje': None, 'Entrenamiento accuracy': 0, \n",
    "                     'Validacion accuracy': 0, 'Tiempo': None}}\n",
    "rangos = [5e-6, 1e-6, 5e-5, 1e-5, 5e-4, 1e-4, 5e-3, 1e-3, 1e-2]\n",
    "\n",
    "for lr in rangos:\n",
    "    # compilar\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Nadam(learning_rate=lr),  \n",
    "              metrics=['accuracy'])\n",
    "    # entrenar\n",
    "    time_ini = time.time()\n",
    "    hist = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
    "    time_fin = time.time()\n",
    "    \n",
    "    # guardar datos si son mejores\n",
    "    val_acc = np.sort( hist.history['val_accuracy'])[-1]     # oredenado de menor a mayor cojo el ultimo\n",
    "    if val_acc > historial['C']['Validacion accuracy']:\n",
    "        t_acc = np.sort(hist.history['accuracy'])[-1]  \n",
    "        historial['C'] = {'Tasa aprendizaje': lr, 'Entrenamiento accuracy': t_acc, \n",
    "                     'Validacion accuracy': val_acc, 'Tiempo': time_fin-time_ini}\n",
    "historial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_lr = historial['C']['Tasa aprendizaje']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D\n",
    " Una vez elegida la tasa de aprendizaje entrena el modelo usando la detención temprana (ahora que tienes detención temprana aumenta el número de epochs).\n",
    "\n",
    " Añade los resultados al diccionario anterior, hay que añadir:\n",
    "\n",
    "[{\n",
    "\n",
    "    'Red neuronal normal con detención temprana': {\n",
    "\n",
    "        'Tasa de aprendizaje': X,\n",
    "\n",
    "        'Entrenamiento sparse categorical accuracy': X,\n",
    "\n",
    "        'Validación sparse categorical accuracy': X,\n",
    "\n",
    "        'Tiempo total (s)': X,\n",
    "\n",
    "        'Mejor época': X\n",
    "\n",
    "    }\n",
    "    \n",
    "}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0970 - loss: 2.3040 - val_accuracy: 0.0976 - val_loss: 2.3037\n",
      "Epoch 2/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1004 - loss: 2.3039 - val_accuracy: 0.0982 - val_loss: 2.3035\n",
      "Epoch 3/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0965 - loss: 2.3038 - val_accuracy: 0.0976 - val_loss: 2.3040\n",
      "Epoch 4/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1019 - loss: 2.3037 - val_accuracy: 0.0982 - val_loss: 2.3043\n",
      "Epoch 5/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0973 - loss: 2.3043 - val_accuracy: 0.0976 - val_loss: 2.3045\n",
      "Epoch 6/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0995 - loss: 2.3040 - val_accuracy: 0.0990 - val_loss: 2.3040\n",
      "Epoch 1/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5ms/step - accuracy: 0.0994 - loss: 2.3032 - val_accuracy: 0.0982 - val_loss: 2.3034\n",
      "Epoch 2/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1006 - loss: 2.3031 - val_accuracy: 0.0982 - val_loss: 2.3034\n",
      "Epoch 3/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1018 - loss: 2.3029 - val_accuracy: 0.0982 - val_loss: 2.3034\n",
      "Epoch 4/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0987 - loss: 2.3030 - val_accuracy: 0.0982 - val_loss: 2.3033\n",
      "Epoch 5/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1008 - loss: 2.3030 - val_accuracy: 0.0982 - val_loss: 2.3033\n",
      "Epoch 6/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0999 - loss: 2.3028 - val_accuracy: 0.0982 - val_loss: 2.3033\n",
      "Epoch 7/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1003 - loss: 2.3028 - val_accuracy: 0.0982 - val_loss: 2.3032\n",
      "Epoch 8/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1003 - loss: 2.3029 - val_accuracy: 0.0982 - val_loss: 2.3032\n",
      "Epoch 9/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0990 - loss: 2.3030 - val_accuracy: 0.0982 - val_loss: 2.3032\n",
      "Epoch 10/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0990 - loss: 2.3030 - val_accuracy: 0.0982 - val_loss: 2.3031\n",
      "Epoch 11/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0981 - loss: 2.3031 - val_accuracy: 0.0982 - val_loss: 2.3031\n",
      "Epoch 12/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1002 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3031\n",
      "Epoch 13/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0981 - loss: 2.3028 - val_accuracy: 0.0982 - val_loss: 2.3031\n",
      "Epoch 14/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0999 - loss: 2.3029 - val_accuracy: 0.0982 - val_loss: 2.3031\n",
      "Epoch 15/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0983 - loss: 2.3028 - val_accuracy: 0.0982 - val_loss: 2.3030\n",
      "Epoch 16/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0986 - loss: 2.3028 - val_accuracy: 0.0982 - val_loss: 2.3030\n",
      "Epoch 17/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1011 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3030\n",
      "Epoch 18/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1002 - loss: 2.3028 - val_accuracy: 0.0982 - val_loss: 2.3030\n",
      "Epoch 19/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0984 - loss: 2.3028 - val_accuracy: 0.0982 - val_loss: 2.3030\n",
      "Epoch 20/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1023 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3030\n",
      "Epoch 21/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0980 - loss: 2.3028 - val_accuracy: 0.0982 - val_loss: 2.3029\n",
      "Epoch 22/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1006 - loss: 2.3028 - val_accuracy: 0.0982 - val_loss: 2.3029\n",
      "Epoch 23/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1004 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3029\n",
      "Epoch 24/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1027 - loss: 2.3025 - val_accuracy: 0.0982 - val_loss: 2.3029\n",
      "Epoch 25/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1023 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3029\n",
      "Epoch 26/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1003 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3029\n",
      "Epoch 27/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1002 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3029\n",
      "Epoch 28/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0995 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3028\n",
      "Epoch 29/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1019 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3028\n",
      "Epoch 30/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1009 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3028\n",
      "Epoch 31/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1002 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3028\n",
      "Epoch 32/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0976 - loss: 2.3028 - val_accuracy: 0.0982 - val_loss: 2.3028\n",
      "Epoch 33/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0976 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3028\n",
      "Epoch 34/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0989 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3028\n",
      "Epoch 35/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1035 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3028\n",
      "Epoch 36/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0982 - loss: 2.3028 - val_accuracy: 0.0982 - val_loss: 2.3028\n",
      "Epoch 37/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1007 - loss: 2.3025 - val_accuracy: 0.0982 - val_loss: 2.3028\n",
      "Epoch 38/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0974 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3028\n",
      "Epoch 39/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0998 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3028\n",
      "Epoch 40/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0985 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3028\n",
      "Epoch 41/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0989 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 42/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1000 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 43/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1014 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 44/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1001 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 45/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1000 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 46/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1018 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 47/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0980 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 48/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0998 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 49/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1017 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 50/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1012 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 51/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1001 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 52/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1020 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 53/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0982 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 54/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1010 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 55/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0989 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 56/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0990 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 57/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0998 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 58/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1016 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 59/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1033 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 60/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0992 - loss: 2.3026 - val_accuracy: 0.0982 - val_loss: 2.3027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Tasa aprendizaje': 1e-05,\n",
       " 'Entrenamiento accuracy': 0.10000000149011612,\n",
       " 'Validacion accuracy': 0.0982000008225441,\n",
       " 'Tiempo': np.float64(491.0),\n",
       " 'Mejor epoca': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"./recursos/checkpoint/4_6_D_checkpoints.weights.h5\", save_weights_only=True)\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=70, validation_data=(x_val, y_val), \n",
    "                     callbacks=[checkpoint_cb,early_stopping_cb])\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "            optimizer=tf.keras.optimizers.Nadam(learning_rate=mejor_lr),   # asignar tasa de aprendizaje\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "time_ini = time.time()\n",
    "hist = model.fit(x_train, y_train, epochs=60, validation_data=(x_val, y_val))\n",
    "time_fin = time.time()\n",
    "\n",
    "mejor_ep = 0\n",
    "mejor_ep_acc = 0\n",
    "val_acc_arr = hist.history['val_accuracy']\n",
    "for i in range(len(val_acc_arr)): \n",
    "    if val_acc_arr[i] > mejor_ep_acc: \n",
    "        mejor_ep = i\n",
    "        mejor_ep_acc = val_acc_arr[i]\n",
    "\n",
    "historial['D'] = {'Tasa aprendizaje': mejor_lr, 'Entrenamiento accuracy': hist.history['accuracy'][mejor_ep], \n",
    "                    'Validacion accuracy': mejor_ep_acc, 'Tiempo': np.round(time_fin-time_ini), 'Mejor epoca': mejor_ep}\n",
    "\n",
    "historial['D']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E\n",
    "Ahora, prueba a añadir normalización de lotes y repite C y D con esta nueva red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python311\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - accuracy: 0.0987 - loss: 2.9724 - val_accuracy: 0.1028 - val_loss: 3.9361\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.0991 - loss: 2.8614 - val_accuracy: 0.1066 - val_loss: 3.5365\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1037 - loss: 2.7728 - val_accuracy: 0.1038 - val_loss: 3.5919\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1087 - loss: 2.6976 - val_accuracy: 0.1068 - val_loss: 3.5424\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1076 - loss: 2.6563 - val_accuracy: 0.1206 - val_loss: 3.6167\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1065 - loss: 2.6332 - val_accuracy: 0.1128 - val_loss: 3.7936\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1085 - loss: 2.5967 - val_accuracy: 0.1194 - val_loss: 3.4003\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1119 - loss: 2.5658 - val_accuracy: 0.1212 - val_loss: 3.5302\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1080 - loss: 2.5564 - val_accuracy: 0.1258 - val_loss: 3.4855\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1130 - loss: 2.5309 - val_accuracy: 0.1252 - val_loss: 3.6238\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - accuracy: 0.1160 - loss: 2.5123 - val_accuracy: 0.1250 - val_loss: 3.2175\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1150 - loss: 2.5081 - val_accuracy: 0.1190 - val_loss: 3.2992\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1148 - loss: 2.5093 - val_accuracy: 0.1382 - val_loss: 3.3518\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1149 - loss: 2.5001 - val_accuracy: 0.1316 - val_loss: 3.4216\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1162 - loss: 2.5010 - val_accuracy: 0.1338 - val_loss: 3.4279\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1168 - loss: 2.4929 - val_accuracy: 0.1244 - val_loss: 3.1644\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1166 - loss: 2.4970 - val_accuracy: 0.1368 - val_loss: 3.2320\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1156 - loss: 2.4939 - val_accuracy: 0.1292 - val_loss: 3.4916\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1154 - loss: 2.4865 - val_accuracy: 0.1286 - val_loss: 3.2838\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1157 - loss: 2.4839 - val_accuracy: 0.1352 - val_loss: 3.3402\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - accuracy: 0.1129 - loss: 2.4762 - val_accuracy: 0.1300 - val_loss: 2.6686\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1263 - loss: 2.3769 - val_accuracy: 0.1376 - val_loss: 2.6556\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1493 - loss: 2.2851 - val_accuracy: 0.1784 - val_loss: 2.3815\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1745 - loss: 2.1933 - val_accuracy: 0.1954 - val_loss: 2.2783\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.2181 - loss: 2.0998 - val_accuracy: 0.2400 - val_loss: 2.1551\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.2513 - loss: 2.0206 - val_accuracy: 0.2768 - val_loss: 2.0149\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.2855 - loss: 1.9352 - val_accuracy: 0.3066 - val_loss: 1.9336\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.3078 - loss: 1.8881 - val_accuracy: 0.3290 - val_loss: 1.8792\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.3311 - loss: 1.8429 - val_accuracy: 0.3352 - val_loss: 1.8843\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.3515 - loss: 1.8018 - val_accuracy: 0.3724 - val_loss: 1.7409\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - accuracy: 0.3628 - loss: 1.7706 - val_accuracy: 0.3942 - val_loss: 1.6796\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.3647 - loss: 1.7536 - val_accuracy: 0.4042 - val_loss: 1.6908\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.3689 - loss: 1.7446 - val_accuracy: 0.4108 - val_loss: 1.6728\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.3792 - loss: 1.7311 - val_accuracy: 0.4106 - val_loss: 1.6553\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.3868 - loss: 1.7183 - val_accuracy: 0.4150 - val_loss: 1.6438\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.3808 - loss: 1.7191 - val_accuracy: 0.4170 - val_loss: 1.6341\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.3879 - loss: 1.7019 - val_accuracy: 0.4188 - val_loss: 1.6286\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.3865 - loss: 1.7032 - val_accuracy: 0.4226 - val_loss: 1.6254\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.3909 - loss: 1.6945 - val_accuracy: 0.4324 - val_loss: 1.6118\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.3957 - loss: 1.6905 - val_accuracy: 0.4334 - val_loss: 1.6001\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - accuracy: 0.3412 - loss: 1.8332 - val_accuracy: 0.1770 - val_loss: 2.2817\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.3741 - loss: 1.7497 - val_accuracy: 0.3616 - val_loss: 1.7828\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.4066 - loss: 1.6754 - val_accuracy: 0.4112 - val_loss: 1.6657\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.4221 - loss: 1.6315 - val_accuracy: 0.4408 - val_loss: 1.5774\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.4330 - loss: 1.5941 - val_accuracy: 0.4090 - val_loss: 1.6721\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.4437 - loss: 1.5704 - val_accuracy: 0.4524 - val_loss: 1.6008\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.4551 - loss: 1.5392 - val_accuracy: 0.4356 - val_loss: 1.6623\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.4609 - loss: 1.5111 - val_accuracy: 0.4696 - val_loss: 1.5740\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.4767 - loss: 1.4885 - val_accuracy: 0.4766 - val_loss: 1.5224\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.4842 - loss: 1.4684 - val_accuracy: 0.4764 - val_loss: 1.5316\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 9ms/step - accuracy: 0.5052 - loss: 1.4100 - val_accuracy: 0.5176 - val_loss: 1.4388\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.5168 - loss: 1.3705 - val_accuracy: 0.5220 - val_loss: 1.4456\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.5181 - loss: 1.3665 - val_accuracy: 0.5266 - val_loss: 1.4202\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.5233 - loss: 1.3443 - val_accuracy: 0.5272 - val_loss: 1.4419\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.5252 - loss: 1.3365 - val_accuracy: 0.5252 - val_loss: 1.4415\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.5297 - loss: 1.3328 - val_accuracy: 0.5264 - val_loss: 1.4321\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.5308 - loss: 1.3291 - val_accuracy: 0.5292 - val_loss: 1.4182\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.5320 - loss: 1.3179 - val_accuracy: 0.5320 - val_loss: 1.4399\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.5415 - loss: 1.3001 - val_accuracy: 0.5302 - val_loss: 1.4368\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.5404 - loss: 1.2977 - val_accuracy: 0.5274 - val_loss: 1.4517\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 9ms/step - accuracy: 0.2761 - loss: 1.9722 - val_accuracy: 0.2700 - val_loss: 2.3433\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.3280 - loss: 1.8548 - val_accuracy: 0.2328 - val_loss: 2.2210\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.3348 - loss: 1.8356 - val_accuracy: 0.3464 - val_loss: 1.8127\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.3648 - loss: 1.7718 - val_accuracy: 0.3594 - val_loss: 1.8042\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.3834 - loss: 1.7322 - val_accuracy: 0.3690 - val_loss: 1.8457\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.4006 - loss: 1.6941 - val_accuracy: 0.3670 - val_loss: 1.9699\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.3952 - loss: 1.6858 - val_accuracy: 0.3772 - val_loss: 1.7384\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.4041 - loss: 1.6623 - val_accuracy: 0.3588 - val_loss: 1.9215\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.3932 - loss: 1.6811 - val_accuracy: 0.3558 - val_loss: 3.0130\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.3750 - loss: 1.7369 - val_accuracy: 0.3536 - val_loss: 17160.6328\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 9ms/step - accuracy: 0.3980 - loss: 1.6800 - val_accuracy: 0.4202 - val_loss: 402662.9062\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4184 - loss: 1.6259 - val_accuracy: 0.4276 - val_loss: 1701828.2500\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4202 - loss: 1.6175 - val_accuracy: 0.4290 - val_loss: 156761.1719\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4160 - loss: 1.6257 - val_accuracy: 0.4236 - val_loss: 6170537.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4223 - loss: 1.6065 - val_accuracy: 0.4234 - val_loss: 592152.2500\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4136 - loss: 1.6301 - val_accuracy: 0.4246 - val_loss: 59602680.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4193 - loss: 1.6114 - val_accuracy: 0.4258 - val_loss: 1087006.2500\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4188 - loss: 1.6178 - val_accuracy: 0.4080 - val_loss: 1244565.7500\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4099 - loss: 1.6473 - val_accuracy: 0.4308 - val_loss: 269986.5312\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4135 - loss: 1.6339 - val_accuracy: 0.4278 - val_loss: 1239525.7500\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 9ms/step - accuracy: 0.3658 - loss: 1.7579 - val_accuracy: 0.2268 - val_loss: 5446378771709952.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.3022 - loss: 1.9084 - val_accuracy: 0.2396 - val_loss: 210206415909987545218537226240.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.3337 - loss: 1.8131 - val_accuracy: 0.3550 - val_loss: nan\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.3589 - loss: 1.7561 - val_accuracy: 0.3240 - val_loss: nan\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.3754 - loss: 1.7173 - val_accuracy: 0.3776 - val_loss: nan\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.3884 - loss: 1.6945 - val_accuracy: 0.3822 - val_loss: nan\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.3972 - loss: 1.6763 - val_accuracy: 0.3828 - val_loss: nan\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4037 - loss: 1.6499 - val_accuracy: 0.3686 - val_loss: nan\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4034 - loss: 1.6470 - val_accuracy: 0.3588 - val_loss: nan\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4075 - loss: 1.6424 - val_accuracy: 0.3752 - val_loss: nan\n",
      "Epoch 1/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4093 - loss: 1.6351 - val_accuracy: 0.3910 - val_loss: nan\n",
      "Epoch 2/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4083 - loss: 1.6325 - val_accuracy: 0.3704 - val_loss: nan\n",
      "Epoch 3/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4200 - loss: 1.6139 - val_accuracy: 0.3932 - val_loss: 1280893618540989667659970949152768.0000\n",
      "Epoch 4/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4227 - loss: 1.6012 - val_accuracy: 0.3884 - val_loss: 829725520139655817774046132568064.0000\n",
      "Epoch 5/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4202 - loss: 1.6102 - val_accuracy: 0.3984 - val_loss: 441230609991602730739838222336.0000\n",
      "Epoch 1/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 9ms/step - accuracy: 0.4131 - loss: 1.6218 - val_accuracy: 0.3164 - val_loss: nan\n",
      "Epoch 2/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4164 - loss: 1.6177 - val_accuracy: 0.2998 - val_loss: 340035319652718187498211140173824.0000\n",
      "Epoch 3/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4211 - loss: 1.6134 - val_accuracy: 0.3898 - val_loss: 3365263553999880405081294182023168.0000\n",
      "Epoch 4/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4220 - loss: 1.5956 - val_accuracy: 0.4112 - val_loss: 10348661269489357809201770678714368.0000\n",
      "Epoch 5/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4277 - loss: 1.5934 - val_accuracy: 0.4040 - val_loss: nan\n",
      "Epoch 6/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4253 - loss: 1.5969 - val_accuracy: 0.3618 - val_loss: 6549284020668106140255432283783168.0000\n",
      "Epoch 7/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4235 - loss: 1.5948 - val_accuracy: 0.3870 - val_loss: 2866852181993055953773195631263744.0000\n",
      "Epoch 8/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4300 - loss: 1.5838 - val_accuracy: 0.4090 - val_loss: nan\n",
      "Epoch 9/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4296 - loss: 1.5771 - val_accuracy: 0.3948 - val_loss: nan\n",
      "Epoch 10/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4321 - loss: 1.5721 - val_accuracy: 0.3904 - val_loss: nan\n",
      "Epoch 11/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4370 - loss: 1.5747 - val_accuracy: 0.4146 - val_loss: nan\n",
      "Epoch 12/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4343 - loss: 1.5616 - val_accuracy: 0.4058 - val_loss: nan\n",
      "Epoch 13/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4331 - loss: 1.5692 - val_accuracy: 0.4062 - val_loss: nan\n",
      "Epoch 14/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4397 - loss: 1.5555 - val_accuracy: 0.4238 - val_loss: nan\n",
      "Epoch 15/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4383 - loss: 1.5642 - val_accuracy: 0.3986 - val_loss: nan\n",
      "Epoch 16/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4343 - loss: 1.5598 - val_accuracy: 0.3900 - val_loss: nan\n",
      "Epoch 17/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4382 - loss: 1.5550 - val_accuracy: 0.4092 - val_loss: nan\n",
      "Epoch 18/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4387 - loss: 1.5540 - val_accuracy: 0.4198 - val_loss: nan\n",
      "Epoch 19/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4440 - loss: 1.5428 - val_accuracy: 0.4112 - val_loss: nan\n",
      "Epoch 20/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4400 - loss: 1.5394 - val_accuracy: 0.4104 - val_loss: nan\n",
      "Epoch 21/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4460 - loss: 1.5452 - val_accuracy: 0.3798 - val_loss: nan\n",
      "Epoch 22/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4389 - loss: 1.5453 - val_accuracy: 0.4048 - val_loss: nan\n",
      "Epoch 23/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4419 - loss: 1.5429 - val_accuracy: 0.4146 - val_loss: nan\n",
      "Epoch 24/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4438 - loss: 1.5384 - val_accuracy: 0.4160 - val_loss: 1288924599803348661520844655165440.0000\n",
      "Epoch 25/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4402 - loss: 1.5381 - val_accuracy: 0.4322 - val_loss: nan\n",
      "Epoch 26/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4445 - loss: 1.5390 - val_accuracy: 0.4072 - val_loss: nan\n",
      "Epoch 27/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4480 - loss: 1.5377 - val_accuracy: 0.3452 - val_loss: nan\n",
      "Epoch 28/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4514 - loss: 1.5225 - val_accuracy: 0.4328 - val_loss: nan\n",
      "Epoch 29/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4521 - loss: 1.5307 - val_accuracy: 0.4108 - val_loss: 23709673837094109993371524480892928.0000\n",
      "Epoch 30/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4501 - loss: 1.5244 - val_accuracy: 0.4012 - val_loss: nan\n",
      "Epoch 31/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4439 - loss: 1.5351 - val_accuracy: 0.4266 - val_loss: nan\n",
      "Epoch 32/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4458 - loss: 1.5356 - val_accuracy: 0.4268 - val_loss: nan\n",
      "Epoch 33/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4506 - loss: 1.5223 - val_accuracy: 0.4250 - val_loss: nan\n",
      "Epoch 34/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4519 - loss: 1.5235 - val_accuracy: 0.4130 - val_loss: nan\n",
      "Epoch 35/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4496 - loss: 1.5198 - val_accuracy: 0.4086 - val_loss: 3701503233435270933652263835533312.0000\n",
      "Epoch 36/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4524 - loss: 1.5212 - val_accuracy: 0.3902 - val_loss: nan\n",
      "Epoch 37/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4580 - loss: 1.5159 - val_accuracy: 0.4222 - val_loss: nan\n",
      "Epoch 38/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4529 - loss: 1.5193 - val_accuracy: 0.4132 - val_loss: nan\n",
      "Epoch 39/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4522 - loss: 1.5098 - val_accuracy: 0.4314 - val_loss: 300432631312510066966781596008448.0000\n",
      "Epoch 40/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4549 - loss: 1.5127 - val_accuracy: 0.4126 - val_loss: nan\n",
      "Epoch 41/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4576 - loss: 1.5077 - val_accuracy: 0.4386 - val_loss: nan\n",
      "Epoch 42/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4542 - loss: 1.5152 - val_accuracy: 0.4254 - val_loss: 158711978989454220047921365123072.0000\n",
      "Epoch 43/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4545 - loss: 1.5094 - val_accuracy: 0.4060 - val_loss: 1668870061810719362042196614184960.0000\n",
      "Epoch 44/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4566 - loss: 1.5093 - val_accuracy: 0.4094 - val_loss: 69480603302118139474921450897408.0000\n",
      "Epoch 45/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4601 - loss: 1.5011 - val_accuracy: 0.4174 - val_loss: 7872199978070152773364457091891200.0000\n",
      "Epoch 46/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.4641 - loss: 1.4987 - val_accuracy: 0.4112 - val_loss: 72437239329226688837883453767680.0000\n",
      "Epoch 47/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4525 - loss: 1.5066 - val_accuracy: 0.4114 - val_loss: 8542079043888414889238970788478976.0000\n",
      "Epoch 48/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4604 - loss: 1.5033 - val_accuracy: 0.4330 - val_loss: nan\n",
      "Epoch 49/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4599 - loss: 1.5072 - val_accuracy: 0.4282 - val_loss: 835039068273278491258981898518528.0000\n",
      "Epoch 50/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4561 - loss: 1.5095 - val_accuracy: 0.4272 - val_loss: 2738492655199633443829455238725632.0000\n",
      "Epoch 51/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4605 - loss: 1.4994 - val_accuracy: 0.4274 - val_loss: 902506490929321894895915443945472.0000\n",
      "Epoch 52/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4646 - loss: 1.4947 - val_accuracy: 0.4374 - val_loss: nan\n",
      "Epoch 53/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4562 - loss: 1.5065 - val_accuracy: 0.3808 - val_loss: 301694479068804146148239709569024.0000\n",
      "Epoch 54/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4620 - loss: 1.5049 - val_accuracy: 0.4018 - val_loss: nan\n",
      "Epoch 55/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4638 - loss: 1.4940 - val_accuracy: 0.4276 - val_loss: nan\n",
      "Epoch 56/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4652 - loss: 1.4873 - val_accuracy: 0.4392 - val_loss: nan\n",
      "Epoch 57/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4585 - loss: 1.5032 - val_accuracy: 0.4286 - val_loss: nan\n",
      "Epoch 58/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4620 - loss: 1.4966 - val_accuracy: 0.4238 - val_loss: nan\n",
      "Epoch 59/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4670 - loss: 1.4841 - val_accuracy: 0.3950 - val_loss: nan\n",
      "Epoch 60/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4639 - loss: 1.4896 - val_accuracy: 0.4362 - val_loss: 1256598116814984615729869461913600.0000\n"
     ]
    }
   ],
   "source": [
    "# Limpiamos memoria\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# crear red\n",
    "model = tf.keras.Sequential()      # creacion del modelo\n",
    "model.add(tf.keras.layers.Input(shape=(32,32,3)))    # capa entrada,   shape= imagen de 32x32 a color 3\n",
    "model.add(tf.keras.layers.Flatten())      # capa flatten\n",
    "for i in range(20):        \n",
    "    model.add(tf.keras.layers.Dense(100, activation=swish, kernel_initializer='he_normal'))    # las 20 capas ocultas de 100 neuronas activacion swish\n",
    "    model.add(tf.keras.layers.BatchNormalization())      # normalizacion\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))     # capa salida \n",
    "\n",
    "\n",
    "def ej_CyD(model, letra):\n",
    "    mejor_acc = 0\n",
    "    mejor_lr = None\n",
    "    # C, hayar mejor lr\n",
    "    rangos = [5e-6, 1e-6, 5e-5, 1e-5, 5e-4, 1e-4, 5e-3, 1e-3, 1e-2]\n",
    "    for lr in rangos:\n",
    "        # compilar\n",
    "        model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                optimizer=tf.keras.optimizers.Nadam(learning_rate=lr),  \n",
    "                metrics=['accuracy'])\n",
    "        # entrenar\n",
    "        time_ini = time.time()\n",
    "        hist = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
    "        time_fin = time.time()\n",
    "        \n",
    "        # guardar mejor lr\n",
    "        val_acc = np.sort( hist.history['val_accuracy'])[-1]     # oredenado de menor a mayor cojo el ultimo\n",
    "        if val_acc > mejor_acc:\n",
    "            mejor_lr = lr\n",
    "\n",
    "\n",
    "    # D, aplicar detencion temprana con el mejor lr\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True)\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"./recursos/checkpoint/4_6_\"+letra+\"_checkpoints.weights.h5\", save_weights_only=True)\n",
    "\n",
    "    hist = model.fit(x_train, y_train, epochs=70, validation_data=(x_val, y_val), \n",
    "                        callbacks=[checkpoint_cb,early_stopping_cb])\n",
    "\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                optimizer=tf.keras.optimizers.Nadam(learning_rate=mejor_lr),   # asignar tasa de aprendizaje\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    time_ini = time.time()\n",
    "    hist = model.fit(x_train, y_train, epochs=60, validation_data=(x_val, y_val))\n",
    "    time_fin = time.time()\n",
    "\n",
    "    mejor_ep = 0\n",
    "    mejor_ep_acc = 0\n",
    "    val_acc_arr = hist.history['val_accuracy']\n",
    "    for i in range(len(val_acc_arr)): \n",
    "        if val_acc_arr[i] > mejor_ep_acc: \n",
    "            mejor_ep = i\n",
    "            mejor_ep_acc = val_acc_arr[i]\n",
    "\n",
    "    return {'Tasa aprendizaje': mejor_lr, 'Entrenamiento accuracy': hist.history['accuracy'][mejor_ep], \n",
    "        'Validacion accuracy': mejor_ep_acc, 'Tiempo': np.round(time_fin-time_ini), 'Mejor epoca': mejor_ep}\n",
    "\n",
    "historial['E'] = ej_CyD(model,'E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F\n",
    "Prueba a sustituir la normalización de lotes por la activación SELU y haz los ajustes necesarios para garantizar que la red se autonormaliza (es decir, tienes que estandarizar los datos antes de empezar).\n",
    "\n",
    "En este caso prueba a estandarizar manualmentes, es decir restando la media y dividiendo por la desviación standard.\n",
    "\n",
    "Usa la inicialización LeCun normal.\n",
    "\n",
    "Repite C y D con esta nueva red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.1929 - loss: 2.4129 - val_accuracy: 0.2944 - val_loss: 1.9720\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3015 - loss: 1.9407 - val_accuracy: 0.3390 - val_loss: 1.8633\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3432 - loss: 1.8334 - val_accuracy: 0.3646 - val_loss: 1.7959\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3704 - loss: 1.7709 - val_accuracy: 0.3810 - val_loss: 1.7452\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3881 - loss: 1.7209 - val_accuracy: 0.3912 - val_loss: 1.7113\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4067 - loss: 1.6638 - val_accuracy: 0.4040 - val_loss: 1.6831\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4215 - loss: 1.6355 - val_accuracy: 0.4044 - val_loss: 1.6674\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4321 - loss: 1.6040 - val_accuracy: 0.4128 - val_loss: 1.6480\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4359 - loss: 1.5852 - val_accuracy: 0.4206 - val_loss: 1.6341\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4486 - loss: 1.5575 - val_accuracy: 0.4202 - val_loss: 1.6200\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.4566 - loss: 1.5365 - val_accuracy: 0.4294 - val_loss: 1.6121\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4665 - loss: 1.5153 - val_accuracy: 0.4274 - val_loss: 1.6104\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4652 - loss: 1.5162 - val_accuracy: 0.4296 - val_loss: 1.6087\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4693 - loss: 1.5089 - val_accuracy: 0.4270 - val_loss: 1.6073\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4712 - loss: 1.5005 - val_accuracy: 0.4312 - val_loss: 1.6044\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4686 - loss: 1.5073 - val_accuracy: 0.4298 - val_loss: 1.6032\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4700 - loss: 1.5046 - val_accuracy: 0.4286 - val_loss: 1.6015\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4718 - loss: 1.4956 - val_accuracy: 0.4316 - val_loss: 1.6005\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4719 - loss: 1.4982 - val_accuracy: 0.4304 - val_loss: 1.5990\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4744 - loss: 1.4842 - val_accuracy: 0.4300 - val_loss: 1.5968\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.4362 - loss: 1.5864 - val_accuracy: 0.4384 - val_loss: 1.5788\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4643 - loss: 1.5006 - val_accuracy: 0.4626 - val_loss: 1.5191\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4870 - loss: 1.4386 - val_accuracy: 0.4758 - val_loss: 1.4988\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5074 - loss: 1.3770 - val_accuracy: 0.4784 - val_loss: 1.4798\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5269 - loss: 1.3213 - val_accuracy: 0.4894 - val_loss: 1.4602\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5497 - loss: 1.2808 - val_accuracy: 0.4950 - val_loss: 1.4348\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5607 - loss: 1.2444 - val_accuracy: 0.5004 - val_loss: 1.4283\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5728 - loss: 1.2063 - val_accuracy: 0.5046 - val_loss: 1.4412\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5834 - loss: 1.1751 - val_accuracy: 0.4990 - val_loss: 1.4407\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5987 - loss: 1.1356 - val_accuracy: 0.4984 - val_loss: 1.4412\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.6400 - loss: 1.0296 - val_accuracy: 0.5104 - val_loss: 1.4271\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6562 - loss: 0.9950 - val_accuracy: 0.5120 - val_loss: 1.4339\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6593 - loss: 0.9848 - val_accuracy: 0.5112 - val_loss: 1.4422\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6691 - loss: 0.9510 - val_accuracy: 0.5118 - val_loss: 1.4477\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6762 - loss: 0.9386 - val_accuracy: 0.5066 - val_loss: 1.4589\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.6783 - loss: 0.9336 - val_accuracy: 0.5034 - val_loss: 1.4664\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6796 - loss: 0.9228 - val_accuracy: 0.5044 - val_loss: 1.4811\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6879 - loss: 0.9049 - val_accuracy: 0.5068 - val_loss: 1.4825\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6861 - loss: 0.9021 - val_accuracy: 0.5068 - val_loss: 1.4898\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6902 - loss: 0.8898 - val_accuracy: 0.5088 - val_loss: 1.5028\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.3863 - loss: 1.7524 - val_accuracy: 0.4316 - val_loss: 1.6452\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4446 - loss: 1.5926 - val_accuracy: 0.4284 - val_loss: 1.6017\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4719 - loss: 1.5156 - val_accuracy: 0.4482 - val_loss: 1.5606\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4947 - loss: 1.4524 - val_accuracy: 0.4520 - val_loss: 1.5515\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5092 - loss: 1.4126 - val_accuracy: 0.4778 - val_loss: 1.5029\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5251 - loss: 1.3680 - val_accuracy: 0.5048 - val_loss: 1.4583\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5485 - loss: 1.3075 - val_accuracy: 0.4946 - val_loss: 1.4778\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5597 - loss: 1.2722 - val_accuracy: 0.5100 - val_loss: 1.4237\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5686 - loss: 1.2415 - val_accuracy: 0.5082 - val_loss: 1.4197\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5828 - loss: 1.2066 - val_accuracy: 0.5142 - val_loss: 1.4377\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.6391 - loss: 1.0466 - val_accuracy: 0.5422 - val_loss: 1.3700\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6723 - loss: 0.9493 - val_accuracy: 0.5362 - val_loss: 1.4054\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6807 - loss: 0.9205 - val_accuracy: 0.5424 - val_loss: 1.4059\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6987 - loss: 0.8737 - val_accuracy: 0.5342 - val_loss: 1.4383\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7054 - loss: 0.8521 - val_accuracy: 0.5412 - val_loss: 1.4484\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7206 - loss: 0.8146 - val_accuracy: 0.5330 - val_loss: 1.4924\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.7286 - loss: 0.7862 - val_accuracy: 0.5372 - val_loss: 1.4882\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7391 - loss: 0.7615 - val_accuracy: 0.5358 - val_loss: 1.5276\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.7468 - loss: 0.7435 - val_accuracy: 0.5278 - val_loss: 1.5764\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.7565 - loss: 0.7171 - val_accuracy: 0.5278 - val_loss: 1.6121\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.1873 - loss: 20.2392 - val_accuracy: 0.1536 - val_loss: 2.2321\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.1764 - loss: 2.1483 - val_accuracy: 0.1888 - val_loss: 2.0553\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1984 - loss: 2.0604 - val_accuracy: 0.1892 - val_loss: 2.0697\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.2114 - loss: 2.0302 - val_accuracy: 0.2308 - val_loss: 1.9994\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.2370 - loss: 1.9639 - val_accuracy: 0.2358 - val_loss: 1.9086\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.2505 - loss: 4.8777 - val_accuracy: 0.0976 - val_loss: 13.7267\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.0987 - loss: 2.8913 - val_accuracy: 0.1026 - val_loss: 2.3309\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.0972 - loss: 2.3164 - val_accuracy: 0.0976 - val_loss: 2.3483\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.0982 - loss: 2.3221 - val_accuracy: 0.0994 - val_loss: 2.3214\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.0986 - loss: 2.3218 - val_accuracy: 0.1014 - val_loss: 2.3255\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.1012 - loss: 2.3202 - val_accuracy: 0.1026 - val_loss: 2.3153\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.1015 - loss: 2.3211 - val_accuracy: 0.0990 - val_loss: 2.3117\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.0988 - loss: 2.3207 - val_accuracy: 0.1010 - val_loss: 2.3191\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.1006 - loss: 2.3211 - val_accuracy: 0.0976 - val_loss: 2.3281\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.1034 - loss: 2.3202 - val_accuracy: 0.1014 - val_loss: 2.3274\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.0994 - loss: 2.3212 - val_accuracy: 0.1008 - val_loss: 2.3214\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0989 - loss: 2.3217 - val_accuracy: 0.1026 - val_loss: 2.3288\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.1017 - loss: 2.3201 - val_accuracy: 0.0994 - val_loss: 2.3292\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.0985 - loss: 2.3199 - val_accuracy: 0.1014 - val_loss: 2.3086\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.0992 - loss: 2.3216 - val_accuracy: 0.1014 - val_loss: 2.3192\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.0970 - loss: 2.4054 - val_accuracy: 0.0990 - val_loss: 2.5117\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.0985 - loss: 2.3990 - val_accuracy: 0.0994 - val_loss: 2.4658\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.1005 - loss: 2.3946 - val_accuracy: 0.1014 - val_loss: 2.4329\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.1014 - loss: 2.3961 - val_accuracy: 0.0994 - val_loss: 2.3573\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.1022 - loss: 2.3945 - val_accuracy: 0.1010 - val_loss: 2.3721\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0995 - loss: 2.3942 - val_accuracy: 0.1008 - val_loss: 2.4069\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.1036 - loss: 2.3971 - val_accuracy: 0.0976 - val_loss: 2.5838\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.1017 - loss: 2.3982 - val_accuracy: 0.0982 - val_loss: 2.3843\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.0967 - loss: 2.3964 - val_accuracy: 0.1008 - val_loss: 2.4447\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.1009 - loss: 2.3941 - val_accuracy: 0.0990 - val_loss: 2.4002\n",
      "Epoch 1/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1001 - loss: 2.3958 - val_accuracy: 0.0976 - val_loss: 2.6191\n",
      "Epoch 2/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0991 - loss: 2.3979 - val_accuracy: 0.0982 - val_loss: 2.4331\n",
      "Epoch 3/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.0973 - loss: 2.3973 - val_accuracy: 0.1010 - val_loss: 2.5148\n",
      "Epoch 4/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.0999 - loss: 2.3978 - val_accuracy: 0.1008 - val_loss: 2.3717\n",
      "Epoch 5/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1024 - loss: 2.3921 - val_accuracy: 0.0976 - val_loss: 2.3859\n",
      "Epoch 6/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.0993 - loss: 2.3979 - val_accuracy: 0.0982 - val_loss: 2.4256\n",
      "Epoch 7/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.0980 - loss: 2.3962 - val_accuracy: 0.0976 - val_loss: 2.3837\n",
      "Epoch 8/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1002 - loss: 2.3956 - val_accuracy: 0.1024 - val_loss: 2.3666\n",
      "Epoch 9/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.0972 - loss: 2.3971 - val_accuracy: 0.1024 - val_loss: 2.4008\n",
      "Epoch 10/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.0971 - loss: 2.3950 - val_accuracy: 0.1008 - val_loss: 2.4214\n",
      "Epoch 11/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1002 - loss: 2.3973 - val_accuracy: 0.0990 - val_loss: 2.4945\n",
      "Epoch 12/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1011 - loss: 2.3948 - val_accuracy: 0.1026 - val_loss: 2.5040\n",
      "Epoch 1/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.1019 - loss: 2.4015 - val_accuracy: 0.0976 - val_loss: 2.4254\n",
      "Epoch 2/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0964 - loss: 2.3933 - val_accuracy: 0.1024 - val_loss: 2.4162\n",
      "Epoch 3/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1029 - loss: 2.3964 - val_accuracy: 0.1026 - val_loss: 2.4326\n",
      "Epoch 4/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0998 - loss: 2.3955 - val_accuracy: 0.0976 - val_loss: 2.3655\n",
      "Epoch 5/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1015 - loss: 2.3977 - val_accuracy: 0.0976 - val_loss: 2.4291\n",
      "Epoch 6/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1011 - loss: 2.3939 - val_accuracy: 0.1008 - val_loss: 2.6533\n",
      "Epoch 7/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1032 - loss: 2.4018 - val_accuracy: 0.0976 - val_loss: 2.3810\n",
      "Epoch 8/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1004 - loss: 2.3971 - val_accuracy: 0.1008 - val_loss: 2.3968\n",
      "Epoch 9/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1015 - loss: 2.3938 - val_accuracy: 0.1008 - val_loss: 2.4168\n",
      "Epoch 10/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1010 - loss: 2.3996 - val_accuracy: 0.1026 - val_loss: 2.3988\n",
      "Epoch 11/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1016 - loss: 2.3913 - val_accuracy: 0.0976 - val_loss: 2.4071\n",
      "Epoch 12/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0969 - loss: 2.3991 - val_accuracy: 0.1026 - val_loss: 2.3989\n",
      "Epoch 13/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0982 - loss: 2.3970 - val_accuracy: 0.0976 - val_loss: 2.3837\n",
      "Epoch 14/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0987 - loss: 2.3936 - val_accuracy: 0.1014 - val_loss: 2.3445\n",
      "Epoch 15/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1006 - loss: 2.3941 - val_accuracy: 0.1024 - val_loss: 2.5245\n",
      "Epoch 16/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0992 - loss: 2.4006 - val_accuracy: 0.0982 - val_loss: 2.3828\n",
      "Epoch 17/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1048 - loss: 2.3902 - val_accuracy: 0.1008 - val_loss: 2.3672\n",
      "Epoch 18/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1017 - loss: 2.3931 - val_accuracy: 0.0976 - val_loss: 2.4154\n",
      "Epoch 19/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1025 - loss: 2.3956 - val_accuracy: 0.0990 - val_loss: 2.4814\n",
      "Epoch 20/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1004 - loss: 2.3983 - val_accuracy: 0.1014 - val_loss: 2.4294\n",
      "Epoch 21/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1042 - loss: 2.3972 - val_accuracy: 0.1008 - val_loss: 2.5352\n",
      "Epoch 22/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1002 - loss: 2.4019 - val_accuracy: 0.1026 - val_loss: 2.4262\n",
      "Epoch 23/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1006 - loss: 2.3940 - val_accuracy: 0.0976 - val_loss: 2.4278\n",
      "Epoch 24/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0994 - loss: 2.3959 - val_accuracy: 0.1014 - val_loss: 2.3364\n",
      "Epoch 25/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0985 - loss: 2.3977 - val_accuracy: 0.0976 - val_loss: 2.3779\n",
      "Epoch 26/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1008 - loss: 2.3958 - val_accuracy: 0.1014 - val_loss: 2.4057\n",
      "Epoch 27/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1011 - loss: 2.3972 - val_accuracy: 0.1024 - val_loss: 2.4134\n",
      "Epoch 28/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0994 - loss: 2.3966 - val_accuracy: 0.1024 - val_loss: 2.5107\n",
      "Epoch 29/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1026 - loss: 2.3975 - val_accuracy: 0.0976 - val_loss: 2.3436\n",
      "Epoch 30/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0973 - loss: 2.3981 - val_accuracy: 0.1026 - val_loss: 2.4722\n",
      "Epoch 31/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1021 - loss: 2.3997 - val_accuracy: 0.0982 - val_loss: 2.3966\n",
      "Epoch 32/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1008 - loss: 2.3939 - val_accuracy: 0.1024 - val_loss: 2.3585\n",
      "Epoch 33/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1025 - loss: 2.3998 - val_accuracy: 0.1008 - val_loss: 2.3571\n",
      "Epoch 34/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1020 - loss: 2.3945 - val_accuracy: 0.0990 - val_loss: 2.4916\n",
      "Epoch 35/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0973 - loss: 2.3978 - val_accuracy: 0.1010 - val_loss: 2.4835\n",
      "Epoch 36/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0994 - loss: 2.3980 - val_accuracy: 0.1010 - val_loss: 2.4794\n",
      "Epoch 37/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1012 - loss: 2.3950 - val_accuracy: 0.1010 - val_loss: 2.4652\n",
      "Epoch 38/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1005 - loss: 2.3947 - val_accuracy: 0.1014 - val_loss: 2.3810\n",
      "Epoch 39/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1017 - loss: 2.3978 - val_accuracy: 0.0976 - val_loss: 2.4746\n",
      "Epoch 40/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1017 - loss: 2.3966 - val_accuracy: 0.0976 - val_loss: 2.4370\n",
      "Epoch 41/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0998 - loss: 2.3960 - val_accuracy: 0.1010 - val_loss: 2.5148\n",
      "Epoch 42/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0981 - loss: 2.3938 - val_accuracy: 0.0976 - val_loss: 2.3626\n",
      "Epoch 43/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1002 - loss: 2.3941 - val_accuracy: 0.0976 - val_loss: 2.3868\n",
      "Epoch 44/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1006 - loss: 2.3981 - val_accuracy: 0.1008 - val_loss: 2.3866\n",
      "Epoch 45/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0977 - loss: 2.3950 - val_accuracy: 0.0994 - val_loss: 2.4202\n",
      "Epoch 46/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1000 - loss: 2.3947 - val_accuracy: 0.0982 - val_loss: 2.4656\n",
      "Epoch 47/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0995 - loss: 2.4002 - val_accuracy: 0.0982 - val_loss: 2.4454\n",
      "Epoch 48/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1004 - loss: 2.3943 - val_accuracy: 0.1008 - val_loss: 2.6351\n",
      "Epoch 49/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1000 - loss: 2.3944 - val_accuracy: 0.0976 - val_loss: 2.4746\n",
      "Epoch 50/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0991 - loss: 2.3935 - val_accuracy: 0.0976 - val_loss: 2.3932\n",
      "Epoch 51/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1006 - loss: 2.3980 - val_accuracy: 0.1024 - val_loss: 2.3729\n",
      "Epoch 52/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0991 - loss: 2.3977 - val_accuracy: 0.1014 - val_loss: 2.3626\n",
      "Epoch 53/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1040 - loss: 2.3910 - val_accuracy: 0.1014 - val_loss: 2.3984\n",
      "Epoch 54/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0997 - loss: 2.3929 - val_accuracy: 0.0990 - val_loss: 2.3765\n",
      "Epoch 55/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1002 - loss: 2.3957 - val_accuracy: 0.0982 - val_loss: 2.5551\n",
      "Epoch 56/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1018 - loss: 2.3984 - val_accuracy: 0.0976 - val_loss: 2.4081\n",
      "Epoch 57/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1033 - loss: 2.3964 - val_accuracy: 0.0976 - val_loss: 2.4451\n",
      "Epoch 58/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1015 - loss: 2.3962 - val_accuracy: 0.0994 - val_loss: 2.3469\n",
      "Epoch 59/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0974 - loss: 2.3956 - val_accuracy: 0.1024 - val_loss: 2.4618\n",
      "Epoch 60/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0985 - loss: 2.3959 - val_accuracy: 0.1026 - val_loss: 2.4137\n"
     ]
    }
   ],
   "source": [
    "# Limpiamos memoria\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# estandarizar\n",
    "media = np.mean(x_train, axis=(0, 1, 2))\n",
    "desviacion = np.std(x_train, axis=(0, 1, 2))\n",
    "x_train = (x_train - media) / desviacion\n",
    "x_val = (x_val - media) / desviacion\n",
    "x_test = (x_test - media) / desviacion\n",
    "\n",
    "\n",
    "# crear red\n",
    "model = tf.keras.Sequential()      # creacion del modelo\n",
    "model.add(tf.keras.layers.Input(shape=(32,32,3)))    # capa entrada,   shape= imagen de 32x32 a color 3\n",
    "model.add(tf.keras.layers.Flatten())      # capa flatten\n",
    "for i in range(20):        \n",
    "    model.add(tf.keras.layers.Dense(100, activation='selu', kernel_initializer=tf.keras.initializers.LecunNormal))    # las 20 capas ocultas de 100 neuronas activacion swish\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))     # capa salida \n",
    "\n",
    "historial['F'] = ej_CyD(model,'F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G\n",
    "Prueba ahora a regularizar el modelo anterior añadiendo una capa dropout antes de la última capa (estandariza manualmente como en el punto anterior).\n",
    "\n",
    "Repite C y D con esta nueva red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.1778 - loss: 2.5219 - val_accuracy: 0.2986 - val_loss: 1.9859\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.2756 - loss: 2.0810 - val_accuracy: 0.3358 - val_loss: 1.8717\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3098 - loss: 1.9548 - val_accuracy: 0.3588 - val_loss: 1.8131\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3373 - loss: 1.8801 - val_accuracy: 0.3712 - val_loss: 1.7617\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3517 - loss: 1.8337 - val_accuracy: 0.3864 - val_loss: 1.7291\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3674 - loss: 1.7794 - val_accuracy: 0.3918 - val_loss: 1.7053\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3835 - loss: 1.7409 - val_accuracy: 0.4026 - val_loss: 1.6828\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3897 - loss: 1.7109 - val_accuracy: 0.4110 - val_loss: 1.6607\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4054 - loss: 1.6838 - val_accuracy: 0.4152 - val_loss: 1.6490\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4158 - loss: 1.6500 - val_accuracy: 0.4164 - val_loss: 1.6348\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.4261 - loss: 1.6202 - val_accuracy: 0.4230 - val_loss: 1.6260\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4267 - loss: 1.6065 - val_accuracy: 0.4214 - val_loss: 1.6241\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4295 - loss: 1.6064 - val_accuracy: 0.4240 - val_loss: 1.6215\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4324 - loss: 1.5955 - val_accuracy: 0.4228 - val_loss: 1.6199\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4316 - loss: 1.6025 - val_accuracy: 0.4240 - val_loss: 1.6180\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4372 - loss: 1.5953 - val_accuracy: 0.4264 - val_loss: 1.6152\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4309 - loss: 1.5894 - val_accuracy: 0.4266 - val_loss: 1.6134\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4427 - loss: 1.5777 - val_accuracy: 0.4274 - val_loss: 1.6130\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4331 - loss: 1.5864 - val_accuracy: 0.4280 - val_loss: 1.6114\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4403 - loss: 1.5780 - val_accuracy: 0.4272 - val_loss: 1.6095\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.4078 - loss: 1.6753 - val_accuracy: 0.4316 - val_loss: 1.5913\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.4383 - loss: 1.5869 - val_accuracy: 0.4566 - val_loss: 1.5256\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4637 - loss: 1.5100 - val_accuracy: 0.4588 - val_loss: 1.5200\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4798 - loss: 1.4606 - val_accuracy: 0.4742 - val_loss: 1.4959\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5012 - loss: 1.4066 - val_accuracy: 0.4768 - val_loss: 1.4708\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5182 - loss: 1.3627 - val_accuracy: 0.4900 - val_loss: 1.4581\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5298 - loss: 1.3231 - val_accuracy: 0.4870 - val_loss: 1.4576\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5421 - loss: 1.2877 - val_accuracy: 0.4876 - val_loss: 1.4461\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5592 - loss: 1.2456 - val_accuracy: 0.4938 - val_loss: 1.4441\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5695 - loss: 1.2091 - val_accuracy: 0.4914 - val_loss: 1.4674\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.6035 - loss: 1.1220 - val_accuracy: 0.5082 - val_loss: 1.4232\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6210 - loss: 1.0774 - val_accuracy: 0.5126 - val_loss: 1.4257\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6300 - loss: 1.0550 - val_accuracy: 0.5130 - val_loss: 1.4403\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6343 - loss: 1.0384 - val_accuracy: 0.5084 - val_loss: 1.4476\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6397 - loss: 1.0208 - val_accuracy: 0.5180 - val_loss: 1.4453\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6438 - loss: 1.0146 - val_accuracy: 0.5106 - val_loss: 1.4574\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6473 - loss: 1.0019 - val_accuracy: 0.5072 - val_loss: 1.4689\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6530 - loss: 0.9974 - val_accuracy: 0.5070 - val_loss: 1.4771\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6561 - loss: 0.9825 - val_accuracy: 0.5078 - val_loss: 1.4812\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6635 - loss: 0.9591 - val_accuracy: 0.5044 - val_loss: 1.4825\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.3874 - loss: 1.7690 - val_accuracy: 0.4448 - val_loss: 1.5930\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4331 - loss: 1.6173 - val_accuracy: 0.4660 - val_loss: 1.5506\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4701 - loss: 1.5220 - val_accuracy: 0.4490 - val_loss: 1.5731\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4943 - loss: 1.4518 - val_accuracy: 0.4878 - val_loss: 1.4843\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5149 - loss: 1.3919 - val_accuracy: 0.4944 - val_loss: 1.4882\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5322 - loss: 1.3619 - val_accuracy: 0.5002 - val_loss: 1.4603\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5506 - loss: 1.3056 - val_accuracy: 0.4916 - val_loss: 1.4954\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5611 - loss: 1.2794 - val_accuracy: 0.5114 - val_loss: 1.4529\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5742 - loss: 1.2373 - val_accuracy: 0.4996 - val_loss: 1.4503\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5826 - loss: 1.2207 - val_accuracy: 0.5074 - val_loss: 1.4361\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.6431 - loss: 1.0317 - val_accuracy: 0.5442 - val_loss: 1.3946\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6755 - loss: 0.9454 - val_accuracy: 0.5434 - val_loss: 1.3950\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6844 - loss: 0.9119 - val_accuracy: 0.5446 - val_loss: 1.4190\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6971 - loss: 0.8760 - val_accuracy: 0.5424 - val_loss: 1.4093\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7069 - loss: 0.8452 - val_accuracy: 0.5358 - val_loss: 1.4473\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7203 - loss: 0.8127 - val_accuracy: 0.5366 - val_loss: 1.4968\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7278 - loss: 0.7898 - val_accuracy: 0.5394 - val_loss: 1.5198\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7399 - loss: 0.7715 - val_accuracy: 0.5350 - val_loss: 1.5286\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7454 - loss: 0.7467 - val_accuracy: 0.5406 - val_loss: 1.5977\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.7566 - loss: 0.7197 - val_accuracy: 0.5324 - val_loss: 1.6219\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.1797 - loss: 2.5569 - val_accuracy: 0.0982 - val_loss: 2.4046\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0993 - loss: 2.4417 - val_accuracy: 0.1024 - val_loss: 2.3886\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0991 - loss: 2.3955 - val_accuracy: 0.1024 - val_loss: 2.3501\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1002 - loss: 2.3825 - val_accuracy: 0.0976 - val_loss: 2.4012\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1000 - loss: 2.3805 - val_accuracy: 0.1026 - val_loss: 2.3520\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1015 - loss: 2.3785 - val_accuracy: 0.0994 - val_loss: 2.3345\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0987 - loss: 2.3824 - val_accuracy: 0.0982 - val_loss: 2.3666\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0994 - loss: 2.3827 - val_accuracy: 0.0976 - val_loss: 2.4717\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1020 - loss: 2.3825 - val_accuracy: 0.0976 - val_loss: 2.4318\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0971 - loss: 2.3858 - val_accuracy: 0.1014 - val_loss: 2.3388\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.1037 - loss: 2.3333 - val_accuracy: 0.1008 - val_loss: 2.3095\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1008 - loss: 2.3260 - val_accuracy: 0.1026 - val_loss: 2.3380\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1007 - loss: 2.3256 - val_accuracy: 0.0990 - val_loss: 2.3170\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0992 - loss: 2.3225 - val_accuracy: 0.0976 - val_loss: 2.3382\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1022 - loss: 2.3256 - val_accuracy: 0.1010 - val_loss: 2.3164\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0968 - loss: 2.3258 - val_accuracy: 0.1026 - val_loss: 2.3248\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0972 - loss: 2.3245 - val_accuracy: 0.1024 - val_loss: 2.3167\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.0998 - loss: 2.3239 - val_accuracy: 0.0982 - val_loss: 2.3224\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1015 - loss: 2.3242 - val_accuracy: 0.0976 - val_loss: 2.3250\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1029 - loss: 2.3243 - val_accuracy: 0.0994 - val_loss: 2.3316\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.0980 - loss: 2.4340 - val_accuracy: 0.1014 - val_loss: 2.4437\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1034 - loss: 2.4354 - val_accuracy: 0.1010 - val_loss: 2.4709\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1004 - loss: 2.4364 - val_accuracy: 0.1010 - val_loss: 2.3866\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1021 - loss: 2.4346 - val_accuracy: 0.1024 - val_loss: 2.3939\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0986 - loss: 2.4360 - val_accuracy: 0.0994 - val_loss: 2.4055\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0994 - loss: 2.4412 - val_accuracy: 0.1026 - val_loss: 2.3887\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0988 - loss: 2.4378 - val_accuracy: 0.1024 - val_loss: 2.4289\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0977 - loss: 2.4358 - val_accuracy: 0.1010 - val_loss: 2.3724\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1021 - loss: 2.4396 - val_accuracy: 0.1008 - val_loss: 2.4151\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0975 - loss: 2.4359 - val_accuracy: 0.1008 - val_loss: 2.5978\n",
      "Epoch 1/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0975 - loss: 2.4418 - val_accuracy: 0.0990 - val_loss: 2.3937\n",
      "Epoch 2/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1037 - loss: 2.4341 - val_accuracy: 0.1014 - val_loss: 2.4513\n",
      "Epoch 3/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0982 - loss: 2.4417 - val_accuracy: 0.1010 - val_loss: 2.4016\n",
      "Epoch 4/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.0966 - loss: 2.4411 - val_accuracy: 0.1024 - val_loss: 2.5208\n",
      "Epoch 5/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0990 - loss: 2.4402 - val_accuracy: 0.0994 - val_loss: 2.4119\n",
      "Epoch 1/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.0981 - loss: 2.4454 - val_accuracy: 0.0976 - val_loss: 2.3604\n",
      "Epoch 2/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0992 - loss: 2.4388 - val_accuracy: 0.0990 - val_loss: 2.4449\n",
      "Epoch 3/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1047 - loss: 2.4310 - val_accuracy: 0.1010 - val_loss: 2.5555\n",
      "Epoch 4/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.0975 - loss: 2.4404 - val_accuracy: 0.1024 - val_loss: 2.4632\n",
      "Epoch 5/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0970 - loss: 2.4419 - val_accuracy: 0.1010 - val_loss: 2.4073\n",
      "Epoch 6/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0999 - loss: 2.4392 - val_accuracy: 0.0994 - val_loss: 2.4193\n",
      "Epoch 7/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1036 - loss: 2.4372 - val_accuracy: 0.1026 - val_loss: 2.3302\n",
      "Epoch 8/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0962 - loss: 2.4424 - val_accuracy: 0.0976 - val_loss: 2.4280\n",
      "Epoch 9/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0990 - loss: 2.4389 - val_accuracy: 0.1024 - val_loss: 2.4157\n",
      "Epoch 10/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0994 - loss: 2.4371 - val_accuracy: 0.0994 - val_loss: 2.4049\n",
      "Epoch 11/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0992 - loss: 2.4352 - val_accuracy: 0.1014 - val_loss: 2.4505\n",
      "Epoch 12/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0979 - loss: 2.4386 - val_accuracy: 0.0990 - val_loss: 2.6814\n",
      "Epoch 13/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1028 - loss: 2.4357 - val_accuracy: 0.0982 - val_loss: 2.4233\n",
      "Epoch 14/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1015 - loss: 2.4333 - val_accuracy: 0.1014 - val_loss: 2.4693\n",
      "Epoch 15/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.0989 - loss: 2.4385 - val_accuracy: 0.0990 - val_loss: 2.3949\n",
      "Epoch 16/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1018 - loss: 2.4385 - val_accuracy: 0.0994 - val_loss: 2.4033\n",
      "Epoch 17/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0972 - loss: 2.4325 - val_accuracy: 0.0982 - val_loss: 2.4040\n",
      "Epoch 18/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0998 - loss: 2.4391 - val_accuracy: 0.1010 - val_loss: 2.3855\n",
      "Epoch 19/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1011 - loss: 2.4365 - val_accuracy: 0.1008 - val_loss: 2.4137\n",
      "Epoch 20/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1003 - loss: 2.4418 - val_accuracy: 0.1024 - val_loss: 2.4460\n",
      "Epoch 21/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1003 - loss: 2.4400 - val_accuracy: 0.0990 - val_loss: 2.4508\n",
      "Epoch 22/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1004 - loss: 2.4296 - val_accuracy: 0.1010 - val_loss: 2.4716\n",
      "Epoch 23/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1030 - loss: 2.4378 - val_accuracy: 0.0982 - val_loss: 2.3608\n",
      "Epoch 24/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1001 - loss: 2.4351 - val_accuracy: 0.0982 - val_loss: 2.3799\n",
      "Epoch 25/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1006 - loss: 2.4346 - val_accuracy: 0.1026 - val_loss: 2.3510\n",
      "Epoch 26/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1008 - loss: 2.4347 - val_accuracy: 0.1024 - val_loss: 2.3789\n",
      "Epoch 27/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1021 - loss: 2.4405 - val_accuracy: 0.0982 - val_loss: 2.4884\n",
      "Epoch 28/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1020 - loss: 2.4354 - val_accuracy: 0.1010 - val_loss: 2.4137\n",
      "Epoch 29/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1006 - loss: 2.4279 - val_accuracy: 0.1026 - val_loss: 2.3791\n",
      "Epoch 30/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1013 - loss: 2.4323 - val_accuracy: 0.0990 - val_loss: 2.4126\n",
      "Epoch 31/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0989 - loss: 2.4393 - val_accuracy: 0.1014 - val_loss: 2.4275\n",
      "Epoch 32/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0979 - loss: 2.4401 - val_accuracy: 0.0976 - val_loss: 2.4089\n",
      "Epoch 33/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.0978 - loss: 2.4330 - val_accuracy: 0.0990 - val_loss: 2.3902\n",
      "Epoch 34/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.0982 - loss: 2.4405 - val_accuracy: 0.0976 - val_loss: 2.3863\n",
      "Epoch 35/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1017 - loss: 2.4337 - val_accuracy: 0.1014 - val_loss: 2.3734\n",
      "Epoch 36/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0976 - loss: 2.4331 - val_accuracy: 0.0994 - val_loss: 2.3929\n",
      "Epoch 37/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.0988 - loss: 2.4398 - val_accuracy: 0.0976 - val_loss: 2.4112\n",
      "Epoch 38/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0974 - loss: 2.4407 - val_accuracy: 0.1008 - val_loss: 2.4237\n",
      "Epoch 39/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0990 - loss: 2.4372 - val_accuracy: 0.1008 - val_loss: 2.3707\n",
      "Epoch 40/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.0998 - loss: 2.4351 - val_accuracy: 0.1010 - val_loss: 2.3660\n",
      "Epoch 41/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0989 - loss: 2.4358 - val_accuracy: 0.1008 - val_loss: 2.4073\n",
      "Epoch 42/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0997 - loss: 2.4344 - val_accuracy: 0.1026 - val_loss: 2.4430\n",
      "Epoch 43/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.0965 - loss: 2.4366 - val_accuracy: 0.0990 - val_loss: 2.3915\n",
      "Epoch 44/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0986 - loss: 2.4383 - val_accuracy: 0.1024 - val_loss: 2.4061\n",
      "Epoch 45/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1011 - loss: 2.4389 - val_accuracy: 0.0976 - val_loss: 2.3653\n",
      "Epoch 46/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1007 - loss: 2.4370 - val_accuracy: 0.1014 - val_loss: 2.4845\n",
      "Epoch 47/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1004 - loss: 2.4373 - val_accuracy: 0.0976 - val_loss: 2.4960\n",
      "Epoch 48/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.0982 - loss: 2.4403 - val_accuracy: 0.0982 - val_loss: 2.4717\n",
      "Epoch 49/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1011 - loss: 2.4362 - val_accuracy: 0.0990 - val_loss: 2.4131\n",
      "Epoch 50/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0968 - loss: 2.4386 - val_accuracy: 0.1014 - val_loss: 2.3740\n",
      "Epoch 51/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1036 - loss: 2.4376 - val_accuracy: 0.1014 - val_loss: 2.4793\n",
      "Epoch 52/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0989 - loss: 2.4397 - val_accuracy: 0.0976 - val_loss: 2.3865\n",
      "Epoch 53/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0960 - loss: 2.4382 - val_accuracy: 0.0976 - val_loss: 2.4013\n",
      "Epoch 54/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.0990 - loss: 2.4406 - val_accuracy: 0.1008 - val_loss: 2.3868\n",
      "Epoch 55/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0990 - loss: 2.4402 - val_accuracy: 0.0994 - val_loss: 2.3540\n",
      "Epoch 56/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1018 - loss: 2.4349 - val_accuracy: 0.1008 - val_loss: 2.3828\n",
      "Epoch 57/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1007 - loss: 2.4358 - val_accuracy: 0.0976 - val_loss: 2.5048\n",
      "Epoch 58/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0973 - loss: 2.4411 - val_accuracy: 0.0982 - val_loss: 2.4750\n",
      "Epoch 59/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.0999 - loss: 2.4328 - val_accuracy: 0.1008 - val_loss: 2.4383\n",
      "Epoch 60/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.0985 - loss: 2.4376 - val_accuracy: 0.1008 - val_loss: 2.5045\n"
     ]
    }
   ],
   "source": [
    "# con la estandarizacion de F es suficiente, no es necesario estandarizar de nuevo\n",
    "\n",
    "# Limpiamos memoria\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# crear red\n",
    "model = tf.keras.Sequential()      # creacion del modelo\n",
    "model.add(tf.keras.layers.Input(shape=(32,32,3)))    # capa entrada,   shape= imagen de 32x32 a color 3\n",
    "model.add(tf.keras.layers.Flatten())      # capa flatten\n",
    "for i in range(20):        \n",
    "    model.add(tf.keras.layers.Dense(100, activation='selu', kernel_initializer=tf.keras.initializers.LecunNormal))    # las 20 capas ocultas de 100 neuronas activacion swish\n",
    "model.add(tf.keras.layers.Dropout(0.2))     # capa dropout ('apaga' un porcentaje de neuronas al azar)\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))     # capa salida \n",
    "\n",
    "historial['G'] = ej_CyD(model,'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####   RESULTADOS   #######\n",
      "C :  {'Tasa aprendizaje': 1e-05, 'Entrenamiento accuracy': np.float64(0.5007799863815308), 'Validacion accuracy': np.float64(0.47699999809265137), 'Tiempo': 92.61396408081055}\n",
      "D :  {'Tasa aprendizaje': 1e-05, 'Entrenamiento accuracy': 0.10000000149011612, 'Validacion accuracy': 0.0982000008225441, 'Tiempo': np.float64(491.0), 'Mejor epoca': 0}\n",
      "E :  {'Tasa aprendizaje': 0.01, 'Entrenamiento accuracy': 0.4629400074481964, 'Validacion accuracy': 0.4392000138759613, 'Tiempo': np.float64(834.0), 'Mejor epoca': 55}\n",
      "F :  {'Tasa aprendizaje': 0.01, 'Entrenamiento accuracy': 0.10288000106811523, 'Validacion accuracy': 0.10260000079870224, 'Tiempo': np.float64(668.0), 'Mejor epoca': 2}\n",
      "G :  {'Tasa aprendizaje': 0.01, 'Entrenamiento accuracy': 0.10198000073432922, 'Validacion accuracy': 0.10260000079870224, 'Tiempo': np.float64(705.0), 'Mejor epoca': 6}\n"
     ]
    }
   ],
   "source": [
    "print('#####   RESULTADOS   #######')\n",
    "for key,value in historial.items():\n",
    "    print(key,': ',value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
