{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 20:00:26.573032: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-20 20:00:26.580152: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-20 20:00:26.588566: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-20 20:00:26.591216: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-20 20:00:26.598666: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.activations import swish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practica cómo entrenar una red neuronal profunda con el conjunto de datos de imágenes CIFAR10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A\n",
    "El conjunto de datos está compuesto por 60.000 imágenes en color de 32 x 32 píxe­les (50.000 para el entrenamiento, 5.000 para la validación y 5.000 para las pruebas) con 10 clases. Puedes cargarlo con tf.keras.datasets.cifar10.load_data(). Muestra una de la imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos las tuplas en x e y\n",
    "(x_train_full, y_train_full), (x_test_full, y_test_full) = datos\n",
    "\n",
    "# 50,000 entrenamiento\n",
    "x_train = x_train_full[:50000]\n",
    "y_train = y_train_full[:50000]\n",
    "\n",
    "# 5,000 validación\n",
    "x_val = x_test_full[:5000]\n",
    "y_val = y_test_full[:5000]\n",
    "\n",
    "# 5,000 prueba\n",
    "x_test = x_test_full[5000:10000]\n",
    "y_test = y_test_full[5000:10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# muestra una imagen\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(x_train[8])\n",
    "plt.axis('off')   # quita los ejes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B\n",
    "Crea una RNP con 20 capas ocultas de 100 neuronas cada una (son demasiadas,\n",
    "pero esa es la gracia del ejercicio). \n",
    "\n",
    "Utiliza la inicialización He y la función de activa­ción Swish. \n",
    "\n",
    "Antes de las 20 capas tendras que añadir una capa Input y una capa Flatten y despúes una capa de de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 20:00:30.696179: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-01-20 20:00:30.696210: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:135] retrieving CUDA diagnostic information for host: iadb-17\n",
      "2025-01-20 20:00:30.696213: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:142] hostname: iadb-17\n",
      "2025-01-20 20:00:30.696414: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:166] libcuda reported version is: 550.120.0\n",
      "2025-01-20 20:00:30.696423: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] kernel reported version is: 550.120.0\n",
      "2025-01-20 20:00:30.696426: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:249] kernel version seems to match DSO: 550.120.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">307,300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m307,300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,210</span> (1.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m500,210\u001b[0m (1.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,210</span> (1.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m500,210\u001b[0m (1.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()      # creacion del modelo\n",
    "model.add(tf.keras.layers.Input(shape=(32,32,3)))    # capa entrada,   shape= imagen de 32x32 a color 3\n",
    "model.add(tf.keras.layers.Flatten())      # capa flatten\n",
    "for i in range(20):        \n",
    "    model.add(tf.keras.layers.Dense(100, activation=swish, kernel_initializer='he_normal'))    # las 20 capas ocultas de 100 neuronas activacion swish\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))     # capa salida \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C\n",
    "Elige una tasa de aprendizaje adecuada para la optimización Nadam.\n",
    "\n",
    "Para probar los diferentes modelos haz un bucle (después de cada entrenamiento evalua X_train y X_valid y guarda en un diccionario para \"Red neuronal normal\")\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "\n",
    "[{\n",
    "\n",
    "    'Red neuronal normal': {\n",
    "\n",
    "        'Tasa de aprendizaje': X,\n",
    "\n",
    "        'Entrenamiento sparse categorical accuracy': X,\n",
    "\n",
    "        'Validación sparse categorical accuracy': X,\n",
    "\n",
    "        'Tiempo total (s)': X\n",
    "\n",
    "    }\n",
    "    \n",
    "}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1033 - loss: 54.0051 - val_accuracy: 0.1234 - val_loss: 5.1058\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1123 - loss: 4.3764 - val_accuracy: 0.1208 - val_loss: 3.0300\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1271 - loss: 2.8923 - val_accuracy: 0.1398 - val_loss: 2.5821\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1461 - loss: 2.5011 - val_accuracy: 0.1668 - val_loss: 2.3529\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1764 - loss: 2.2996 - val_accuracy: 0.1776 - val_loss: 2.2378\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1973 - loss: 2.1879 - val_accuracy: 0.2230 - val_loss: 2.1480\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.2189 - loss: 2.1092 - val_accuracy: 0.2244 - val_loss: 2.0934\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.2394 - loss: 2.0606 - val_accuracy: 0.2472 - val_loss: 2.0506\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.2514 - loss: 2.0169 - val_accuracy: 0.2560 - val_loss: 2.0012\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.2718 - loss: 1.9773 - val_accuracy: 0.2766 - val_loss: 1.9698\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.2871 - loss: 1.9346 - val_accuracy: 0.2846 - val_loss: 1.9551\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.2943 - loss: 1.9298 - val_accuracy: 0.2832 - val_loss: 1.9466\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.3021 - loss: 1.9103 - val_accuracy: 0.2930 - val_loss: 1.9398\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3029 - loss: 1.9084 - val_accuracy: 0.2942 - val_loss: 1.9371\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3045 - loss: 1.9053 - val_accuracy: 0.3020 - val_loss: 1.9293\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3054 - loss: 1.8988 - val_accuracy: 0.2988 - val_loss: 1.9278\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3087 - loss: 1.8875 - val_accuracy: 0.3038 - val_loss: 1.9202\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3078 - loss: 1.8868 - val_accuracy: 0.3048 - val_loss: 1.9176\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.3149 - loss: 1.8794 - val_accuracy: 0.3118 - val_loss: 1.9141\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.3162 - loss: 1.8729 - val_accuracy: 0.3050 - val_loss: 1.9090\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.2667 - loss: 1.9950 - val_accuracy: 0.2902 - val_loss: 1.9084\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.3110 - loss: 1.8747 - val_accuracy: 0.3392 - val_loss: 1.8390\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.3438 - loss: 1.8051 - val_accuracy: 0.3504 - val_loss: 1.7949\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.3654 - loss: 1.7556 - val_accuracy: 0.3826 - val_loss: 1.7147\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.3843 - loss: 1.7097 - val_accuracy: 0.4028 - val_loss: 1.6735\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4020 - loss: 1.6606 - val_accuracy: 0.4106 - val_loss: 1.6474\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4076 - loss: 1.6379 - val_accuracy: 0.4170 - val_loss: 1.6331\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4221 - loss: 1.6071 - val_accuracy: 0.4048 - val_loss: 1.6436\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4296 - loss: 1.5862 - val_accuracy: 0.4332 - val_loss: 1.5964\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4373 - loss: 1.5666 - val_accuracy: 0.4234 - val_loss: 1.5877\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.4557 - loss: 1.5068 - val_accuracy: 0.4516 - val_loss: 1.5346\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4625 - loss: 1.4877 - val_accuracy: 0.4562 - val_loss: 1.5327\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4697 - loss: 1.4773 - val_accuracy: 0.4542 - val_loss: 1.5323\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4761 - loss: 1.4690 - val_accuracy: 0.4534 - val_loss: 1.5345\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4756 - loss: 1.4581 - val_accuracy: 0.4516 - val_loss: 1.5382\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.4772 - loss: 1.4572 - val_accuracy: 0.4526 - val_loss: 1.5281\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4798 - loss: 1.4509 - val_accuracy: 0.4526 - val_loss: 1.5390\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4781 - loss: 1.4471 - val_accuracy: 0.4542 - val_loss: 1.5227\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4868 - loss: 1.4401 - val_accuracy: 0.4548 - val_loss: 1.5275\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4915 - loss: 1.4265 - val_accuracy: 0.4598 - val_loss: 1.5136\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.2243 - loss: 2.1293 - val_accuracy: 0.3024 - val_loss: 1.8914\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.3175 - loss: 1.8458 - val_accuracy: 0.3424 - val_loss: 1.7984\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3491 - loss: 1.7784 - val_accuracy: 0.3720 - val_loss: 1.7362\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.3644 - loss: 1.7387 - val_accuracy: 0.3764 - val_loss: 1.7217\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3770 - loss: 1.7115 - val_accuracy: 0.3968 - val_loss: 1.6844\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.3861 - loss: 1.6908 - val_accuracy: 0.3696 - val_loss: 1.7011\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.3982 - loss: 1.6660 - val_accuracy: 0.3792 - val_loss: 1.7108\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4021 - loss: 1.6528 - val_accuracy: 0.4238 - val_loss: 1.6082\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.4068 - loss: 1.6399 - val_accuracy: 0.4116 - val_loss: 1.6386\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4134 - loss: 1.6279 - val_accuracy: 0.3998 - val_loss: 1.6559\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.4432 - loss: 1.5467 - val_accuracy: 0.4448 - val_loss: 1.5386\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4529 - loss: 1.5186 - val_accuracy: 0.4516 - val_loss: 1.5389\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4561 - loss: 1.5111 - val_accuracy: 0.4596 - val_loss: 1.5368\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4580 - loss: 1.5012 - val_accuracy: 0.4506 - val_loss: 1.5412\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4596 - loss: 1.4998 - val_accuracy: 0.4494 - val_loss: 1.5415\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4615 - loss: 1.4902 - val_accuracy: 0.4542 - val_loss: 1.5200\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4695 - loss: 1.4727 - val_accuracy: 0.4556 - val_loss: 1.5222\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4739 - loss: 1.4659 - val_accuracy: 0.4540 - val_loss: 1.5226\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4743 - loss: 1.4615 - val_accuracy: 0.4452 - val_loss: 1.5401\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4726 - loss: 1.4594 - val_accuracy: 0.4554 - val_loss: 1.5197\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.1127 - loss: 3.6172 - val_accuracy: 0.1008 - val_loss: 2.3028\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0979 - loss: 2.3033 - val_accuracy: 0.1008 - val_loss: 2.3035\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1035 - loss: 2.3031 - val_accuracy: 0.1024 - val_loss: 2.3035\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1001 - loss: 2.3034 - val_accuracy: 0.0976 - val_loss: 2.3033\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0995 - loss: 2.3034 - val_accuracy: 0.1026 - val_loss: 2.3036\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0969 - loss: 2.3034 - val_accuracy: 0.1024 - val_loss: 2.3031\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1029 - loss: 2.3032 - val_accuracy: 0.1010 - val_loss: 2.3030\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0985 - loss: 2.3036 - val_accuracy: 0.1024 - val_loss: 2.3028\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0979 - loss: 2.3032 - val_accuracy: 0.0982 - val_loss: 2.3031\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0989 - loss: 2.3032 - val_accuracy: 0.1008 - val_loss: 2.3032\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.0978 - loss: 2.3031 - val_accuracy: 0.0994 - val_loss: 2.3026\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0985 - loss: 2.3027 - val_accuracy: 0.0990 - val_loss: 2.3027\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0977 - loss: 2.3028 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1011 - loss: 2.3027 - val_accuracy: 0.1026 - val_loss: 2.3025\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 2.3027 - val_accuracy: 0.0982 - val_loss: 2.3026\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0980 - loss: 2.3028 - val_accuracy: 0.0982 - val_loss: 2.3027\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0986 - loss: 2.3028 - val_accuracy: 0.0976 - val_loss: 2.3027\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1002 - loss: 2.3027 - val_accuracy: 0.0990 - val_loss: 2.3026\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0974 - loss: 2.3028 - val_accuracy: 0.0990 - val_loss: 2.3027\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1000 - loss: 2.3027 - val_accuracy: 0.0976 - val_loss: 2.3026\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.1006 - loss: 2.3036 - val_accuracy: 0.1024 - val_loss: 2.3040\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1003 - loss: 2.3041 - val_accuracy: 0.1010 - val_loss: 2.3034\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0976 - loss: 2.3040 - val_accuracy: 0.0990 - val_loss: 2.3039\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0988 - loss: 2.3041 - val_accuracy: 0.1026 - val_loss: 2.3032\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1008 - loss: 2.3041 - val_accuracy: 0.0982 - val_loss: 2.3031\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0995 - loss: 2.3042 - val_accuracy: 0.0990 - val_loss: 2.3032\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1009 - loss: 2.3038 - val_accuracy: 0.1014 - val_loss: 2.3036\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0966 - loss: 2.3042 - val_accuracy: 0.0982 - val_loss: 2.3039\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 2.3040 - val_accuracy: 0.1010 - val_loss: 2.3041\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 2.3040 - val_accuracy: 0.1024 - val_loss: 2.3028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': {'Tasa aprendizaje': 1e-05,\n",
       "  'Entrenamiento accuracy': 0.48664000630378723,\n",
       "  'Validacion accuracy': 0.45980000495910645,\n",
       "  'Tiempo': 76.21988201141357}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historial = {'C':{'Tasa aprendizaje': None, 'Entrenamiento accuracy': 0, \n",
    "                     'Validacion accuracy': 0, 'Tiempo': None}}\n",
    "rangos = [5e-6, 1e-6, 5e-5, 1e-5, 5e-4, 1e-4, 5e-3, 1e-3, 1e-2]\n",
    "\n",
    "for lr in rangos:\n",
    "    # compilar\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Nadam(learning_rate=lr),  \n",
    "              metrics=['accuracy'])\n",
    "    # entrenar\n",
    "    time_ini = time.time()\n",
    "    hist = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
    "    time_fin = time.time()\n",
    "    \n",
    "    # guardar datos si son mejores\n",
    "    val_acc = np.sort( hist.history['val_accuracy'])[-1]     # oredenado de menor a mayor cojo el ultimo\n",
    "    if val_acc > historial['C']['Validacion accuracy']:\n",
    "        t_acc = np.sort(hist.history['accuracy'])[-1]  \n",
    "        historial['C'] = {'Tasa aprendizaje': lr, 'Entrenamiento accuracy': t_acc, \n",
    "                     'Validacion accuracy': val_acc, 'Tiempo': time_fin-time_ini}\n",
    "historial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejor_lr = historial['C']['Tasa aprendizaje']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D\n",
    " Una vez elegida la tasa de aprendizaje entrena el modelo usando la detención temprana (ahora que tienes detención temprana aumenta el número de epochs).\n",
    "\n",
    " Añade los resultados al diccionario anterior, hay que añadir:\n",
    "\n",
    "[{\n",
    "\n",
    "    'Red neuronal normal con detención temprana': {\n",
    "\n",
    "        'Tasa de aprendizaje': X,\n",
    "\n",
    "        'Entrenamiento sparse categorical accuracy': X,\n",
    "\n",
    "        'Validación sparse categorical accuracy': X,\n",
    "\n",
    "        'Tiempo total (s)': X,\n",
    "\n",
    "        'Mejor época': X\n",
    "\n",
    "    }\n",
    "    \n",
    "}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1009 - loss: 2.3042 - val_accuracy: 0.0982 - val_loss: 2.3034\n",
      "Epoch 2/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0966 - loss: 2.3041 - val_accuracy: 0.0976 - val_loss: 2.3071\n",
      "Epoch 3/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1003 - loss: 2.3042 - val_accuracy: 0.1010 - val_loss: 2.3030\n",
      "Epoch 4/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0975 - loss: 2.3041 - val_accuracy: 0.0976 - val_loss: 2.3038\n",
      "Epoch 5/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0983 - loss: 2.3042 - val_accuracy: 0.1010 - val_loss: 2.3032\n",
      "Epoch 6/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1036 - loss: 2.3038 - val_accuracy: 0.1014 - val_loss: 2.3029\n",
      "Epoch 7/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0988 - loss: 2.3037 - val_accuracy: 0.0994 - val_loss: 2.3042\n",
      "Epoch 8/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0997 - loss: 2.3038 - val_accuracy: 0.0994 - val_loss: 2.3054\n",
      "Epoch 9/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0979 - loss: 2.3043 - val_accuracy: 0.1008 - val_loss: 2.3046\n",
      "Epoch 10/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0982 - loss: 2.3042 - val_accuracy: 0.1010 - val_loss: 2.3036\n",
      "Epoch 1/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.0986 - loss: 2.3031 - val_accuracy: 0.1014 - val_loss: 2.3029\n",
      "Epoch 2/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1010 - loss: 2.3030 - val_accuracy: 0.1014 - val_loss: 2.3029\n",
      "Epoch 3/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1000 - loss: 2.3031 - val_accuracy: 0.1014 - val_loss: 2.3029\n",
      "Epoch 4/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1006 - loss: 2.3030 - val_accuracy: 0.1014 - val_loss: 2.3028\n",
      "Epoch 5/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1000 - loss: 2.3030 - val_accuracy: 0.1014 - val_loss: 2.3028\n",
      "Epoch 6/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1001 - loss: 2.3031 - val_accuracy: 0.1014 - val_loss: 2.3028\n",
      "Epoch 7/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0990 - loss: 2.3031 - val_accuracy: 0.1014 - val_loss: 2.3028\n",
      "Epoch 8/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0993 - loss: 2.3031 - val_accuracy: 0.1014 - val_loss: 2.3028\n",
      "Epoch 9/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1007 - loss: 2.3029 - val_accuracy: 0.1014 - val_loss: 2.3028\n",
      "Epoch 10/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1028 - loss: 2.3028 - val_accuracy: 0.1014 - val_loss: 2.3027\n",
      "Epoch 11/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0996 - loss: 2.3028 - val_accuracy: 0.1014 - val_loss: 2.3027\n",
      "Epoch 12/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0990 - loss: 2.3028 - val_accuracy: 0.1014 - val_loss: 2.3027\n",
      "Epoch 13/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0997 - loss: 2.3028 - val_accuracy: 0.1014 - val_loss: 2.3027\n",
      "Epoch 14/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3027\n",
      "Epoch 15/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1000 - loss: 2.3028 - val_accuracy: 0.1014 - val_loss: 2.3027\n",
      "Epoch 16/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1008 - loss: 2.3028 - val_accuracy: 0.1014 - val_loss: 2.3027\n",
      "Epoch 17/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0997 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3027\n",
      "Epoch 18/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0988 - loss: 2.3029 - val_accuracy: 0.1014 - val_loss: 2.3027\n",
      "Epoch 19/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0994 - loss: 2.3028 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 20/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1003 - loss: 2.3028 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 21/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1008 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 22/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0979 - loss: 2.3028 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 23/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0994 - loss: 2.3028 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 24/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0979 - loss: 2.3029 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 25/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.1014 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 26/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.0995 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 27/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.0995 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 28/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0993 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 29/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0996 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 30/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1010 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 31/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1002 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 32/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1030 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 33/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1031 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 34/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0969 - loss: 2.3028 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 35/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1004 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 36/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 37/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 38/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1006 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 39/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0995 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 40/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0984 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 41/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1023 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 42/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1023 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 43/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1011 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 44/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0999 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 45/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0988 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 46/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0999 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 47/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.1003 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 48/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1016 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 49/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1026 - loss: 2.3025 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 50/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0981 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 51/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0983 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 52/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1007 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 53/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0994 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 54/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1006 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 55/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.0993 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 56/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0993 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 57/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1009 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 58/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.0990 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 59/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0997 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 60/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1014 - loss: 2.3026 - val_accuracy: 0.1014 - val_loss: 2.3026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Tasa aprendizaje': 1e-05,\n",
       " 'Entrenamiento accuracy': 0.10000000149011612,\n",
       " 'Validacion accuracy': 0.10140000283718109,\n",
       " 'Tiempo': 409.0,\n",
       " 'Mejor epoca': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"./recursos/checkpoint/4_6_D_checkpoints.weights.h5\", save_weights_only=True)\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=70, validation_data=(x_val, y_val), \n",
    "                     callbacks=[checkpoint_cb,early_stopping_cb])\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "            optimizer=tf.keras.optimizers.Nadam(learning_rate=mejor_lr),   # asignar tasa de aprendizaje\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "time_ini = time.time()\n",
    "hist = model.fit(x_train, y_train, epochs=60, validation_data=(x_val, y_val))\n",
    "time_fin = time.time()\n",
    "\n",
    "mejor_ep = 0\n",
    "mejor_ep_acc = 0\n",
    "val_acc_arr = hist.history['val_accuracy']\n",
    "for i in range(len(val_acc_arr)): \n",
    "    if val_acc_arr[i] > mejor_ep_acc: \n",
    "        mejor_ep = i\n",
    "        mejor_ep_acc = val_acc_arr[i]\n",
    "\n",
    "historial['D'] = {'Tasa aprendizaje': mejor_lr, 'Entrenamiento accuracy': hist.history['accuracy'][mejor_ep], \n",
    "                    'Validacion accuracy': mejor_ep_acc, 'Tiempo': np.round(time_fin-time_ini), 'Mejor epoca': mejor_ep}\n",
    "\n",
    "historial['D']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E\n",
    "Ahora, prueba a añadir normalización de lotes y repite C y D con esta nueva red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.1001 - loss: 3.0376 - val_accuracy: 0.1166 - val_loss: 4.0467\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1037 - loss: 2.8920 - val_accuracy: 0.1126 - val_loss: 3.9256\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1015 - loss: 2.8147 - val_accuracy: 0.1118 - val_loss: 4.0331\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1023 - loss: 2.7488 - val_accuracy: 0.1106 - val_loss: 3.5196\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1059 - loss: 2.6955 - val_accuracy: 0.1164 - val_loss: 3.5158\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1056 - loss: 2.6642 - val_accuracy: 0.1156 - val_loss: 3.4372\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1072 - loss: 2.6204 - val_accuracy: 0.1152 - val_loss: 3.2918\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1051 - loss: 2.6067 - val_accuracy: 0.1150 - val_loss: 3.3103\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1065 - loss: 2.5759 - val_accuracy: 0.1190 - val_loss: 3.1569\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.1063 - loss: 2.5594 - val_accuracy: 0.1256 - val_loss: 3.0174\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 7ms/step - accuracy: 0.1116 - loss: 2.5374 - val_accuracy: 0.1242 - val_loss: 3.1205\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1098 - loss: 2.5302 - val_accuracy: 0.1222 - val_loss: 3.1084\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.1065 - loss: 2.5299 - val_accuracy: 0.1206 - val_loss: 3.1710\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1122 - loss: 2.5315 - val_accuracy: 0.1218 - val_loss: 3.0839\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1097 - loss: 2.5282 - val_accuracy: 0.1286 - val_loss: 3.0585\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1105 - loss: 2.5280 - val_accuracy: 0.1272 - val_loss: 3.0181\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1132 - loss: 2.5176 - val_accuracy: 0.1230 - val_loss: 2.9978\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.1146 - loss: 2.5134 - val_accuracy: 0.1196 - val_loss: 3.0082\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1116 - loss: 2.5129 - val_accuracy: 0.1314 - val_loss: 3.1384\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1116 - loss: 2.5093 - val_accuracy: 0.1282 - val_loss: 3.0239\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.1123 - loss: 2.4831 - val_accuracy: 0.1256 - val_loss: 2.7708\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1212 - loss: 2.3960 - val_accuracy: 0.1314 - val_loss: 2.7191\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.1469 - loss: 2.2984 - val_accuracy: 0.1708 - val_loss: 2.5079\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1775 - loss: 2.2088 - val_accuracy: 0.1878 - val_loss: 2.3471\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.2069 - loss: 2.1201 - val_accuracy: 0.2496 - val_loss: 2.2284\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.2399 - loss: 2.0363 - val_accuracy: 0.2676 - val_loss: 2.1500\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.2726 - loss: 1.9776 - val_accuracy: 0.3194 - val_loss: 1.9310\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.2986 - loss: 1.9183 - val_accuracy: 0.3496 - val_loss: 1.9198\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3194 - loss: 1.8745 - val_accuracy: 0.3474 - val_loss: 1.9229\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3383 - loss: 1.8256 - val_accuracy: 0.3708 - val_loss: 1.8025\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.3459 - loss: 1.7990 - val_accuracy: 0.3858 - val_loss: 1.7531\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3582 - loss: 1.7694 - val_accuracy: 0.4020 - val_loss: 1.7114\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3611 - loss: 1.7675 - val_accuracy: 0.4018 - val_loss: 1.7186\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3703 - loss: 1.7503 - val_accuracy: 0.4074 - val_loss: 1.6825\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.3676 - loss: 1.7473 - val_accuracy: 0.4118 - val_loss: 1.6886\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3715 - loss: 1.7422 - val_accuracy: 0.4154 - val_loss: 1.6578\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.3730 - loss: 1.7223 - val_accuracy: 0.4236 - val_loss: 1.7123\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3821 - loss: 1.7251 - val_accuracy: 0.4242 - val_loss: 1.6642\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3838 - loss: 1.7069 - val_accuracy: 0.4264 - val_loss: 1.6630\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3850 - loss: 1.7003 - val_accuracy: 0.4354 - val_loss: 1.6549\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.3333 - loss: 1.8582 - val_accuracy: 0.3550 - val_loss: 1.7966\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3748 - loss: 1.7413 - val_accuracy: 0.4054 - val_loss: 1.6988\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4018 - loss: 1.6827 - val_accuracy: 0.3862 - val_loss: 1.7016\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4152 - loss: 1.6369 - val_accuracy: 0.4138 - val_loss: 1.6645\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4297 - loss: 1.6028 - val_accuracy: 0.3950 - val_loss: 1.6932\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4363 - loss: 1.5785 - val_accuracy: 0.4182 - val_loss: 1.6268\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4487 - loss: 1.5551 - val_accuracy: 0.4518 - val_loss: 1.5981\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4630 - loss: 1.5212 - val_accuracy: 0.4254 - val_loss: 1.6132\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4703 - loss: 1.4864 - val_accuracy: 0.4540 - val_loss: 1.5423\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4735 - loss: 1.4884 - val_accuracy: 0.4574 - val_loss: 1.5857\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.5051 - loss: 1.4027 - val_accuracy: 0.5176 - val_loss: 1.3901\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5125 - loss: 1.3778 - val_accuracy: 0.5128 - val_loss: 1.3737\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5144 - loss: 1.3688 - val_accuracy: 0.5230 - val_loss: 1.4251\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5137 - loss: 1.3714 - val_accuracy: 0.5124 - val_loss: 1.3883\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5187 - loss: 1.3579 - val_accuracy: 0.5202 - val_loss: 1.3677\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5258 - loss: 1.3364 - val_accuracy: 0.5210 - val_loss: 1.3607\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5274 - loss: 1.3363 - val_accuracy: 0.5208 - val_loss: 1.3684\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5258 - loss: 1.3381 - val_accuracy: 0.5272 - val_loss: 1.3738\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5351 - loss: 1.3080 - val_accuracy: 0.5230 - val_loss: 1.3662\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5307 - loss: 1.3272 - val_accuracy: 0.5262 - val_loss: 1.3696\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.2697 - loss: 1.9875 - val_accuracy: 0.3294 - val_loss: 1.8991\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3058 - loss: 1.8807 - val_accuracy: 0.2130 - val_loss: 2.9369\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3377 - loss: 1.8333 - val_accuracy: 0.3392 - val_loss: 1.9707\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3434 - loss: 1.7981 - val_accuracy: 0.3146 - val_loss: 2.1017\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3561 - loss: 1.7721 - val_accuracy: 0.3636 - val_loss: 1.7963\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3712 - loss: 1.7406 - val_accuracy: 0.3246 - val_loss: 1.8760\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.3929 - loss: 1.6834 - val_accuracy: 0.3970 - val_loss: 1.6858\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.4101 - loss: 1.6473 - val_accuracy: 0.4164 - val_loss: 1.6417\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4156 - loss: 1.6370 - val_accuracy: 0.4200 - val_loss: 1.7076\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4265 - loss: 1.6063 - val_accuracy: 0.2672 - val_loss: 2.3591\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 8ms/step - accuracy: 0.4051 - loss: 1.6553 - val_accuracy: 0.4584 - val_loss: 1.6047\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4268 - loss: 1.5999 - val_accuracy: 0.4550 - val_loss: 1.7965\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4327 - loss: 1.5794 - val_accuracy: 0.4506 - val_loss: 2.1296\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4308 - loss: 1.5810 - val_accuracy: 0.4492 - val_loss: 9.1986\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4293 - loss: 1.5739 - val_accuracy: 0.4546 - val_loss: 3.7799\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4306 - loss: 1.5862 - val_accuracy: 0.4502 - val_loss: 2.0602\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4346 - loss: 1.5739 - val_accuracy: 0.4654 - val_loss: 6.3666\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.4422 - loss: 1.5542 - val_accuracy: 0.4600 - val_loss: 27.1956\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4447 - loss: 1.5518 - val_accuracy: 0.4616 - val_loss: 68.6737\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4467 - loss: 1.5461 - val_accuracy: 0.4646 - val_loss: 145.5873\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.4080 - loss: 1.6582 - val_accuracy: 0.3220 - val_loss: 6159695.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.3766 - loss: 1.7249 - val_accuracy: 0.3350 - val_loss: 4317445588572950233088.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3608 - loss: 1.7613 - val_accuracy: 0.3226 - val_loss: 240526099852918863205236736.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.3828 - loss: 1.7121 - val_accuracy: 0.3492 - val_loss: 176591194574976549693884989440.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3482 - loss: 1.7933 - val_accuracy: 0.3410 - val_loss: 179758372438241631867225767936.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3635 - loss: 1.7715 - val_accuracy: 0.3926 - val_loss: nan\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.3869 - loss: 1.7021 - val_accuracy: 0.3676 - val_loss: nan\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4044 - loss: 1.6564 - val_accuracy: 0.3468 - val_loss: nan\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4139 - loss: 1.6333 - val_accuracy: 0.3920 - val_loss: nan\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4236 - loss: 1.6081 - val_accuracy: 0.3782 - val_loss: nan\n",
      "Epoch 1/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4342 - loss: 1.5822 - val_accuracy: 0.3482 - val_loss: nan\n",
      "Epoch 2/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4407 - loss: 1.5585 - val_accuracy: 0.3810 - val_loss: nan\n",
      "Epoch 3/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4449 - loss: 1.5472 - val_accuracy: 0.4348 - val_loss: nan\n",
      "Epoch 4/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4531 - loss: 1.5290 - val_accuracy: 0.4182 - val_loss: nan\n",
      "Epoch 1/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.4430 - loss: 1.5632 - val_accuracy: 0.3804 - val_loss: nan\n",
      "Epoch 2/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4466 - loss: 1.5484 - val_accuracy: 0.4268 - val_loss: nan\n",
      "Epoch 3/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4494 - loss: 1.5301 - val_accuracy: 0.4308 - val_loss: nan\n",
      "Epoch 4/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4590 - loss: 1.5104 - val_accuracy: 0.4100 - val_loss: nan\n",
      "Epoch 5/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4589 - loss: 1.5089 - val_accuracy: 0.3936 - val_loss: nan\n",
      "Epoch 6/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4642 - loss: 1.4995 - val_accuracy: 0.4550 - val_loss: nan\n",
      "Epoch 7/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4646 - loss: 1.4971 - val_accuracy: 0.4394 - val_loss: nan\n",
      "Epoch 8/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4717 - loss: 1.4790 - val_accuracy: 0.4132 - val_loss: nan\n",
      "Epoch 9/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.4757 - loss: 1.4680 - val_accuracy: 0.4246 - val_loss: nan\n",
      "Epoch 10/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4809 - loss: 1.4609 - val_accuracy: 0.3820 - val_loss: nan\n",
      "Epoch 11/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4804 - loss: 1.4591 - val_accuracy: 0.4328 - val_loss: nan\n",
      "Epoch 12/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4816 - loss: 1.4528 - val_accuracy: 0.4614 - val_loss: nan\n",
      "Epoch 13/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.4857 - loss: 1.4408 - val_accuracy: 0.4670 - val_loss: nan\n",
      "Epoch 14/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4846 - loss: 1.4420 - val_accuracy: 0.3876 - val_loss: nan\n",
      "Epoch 15/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4818 - loss: 1.4380 - val_accuracy: 0.4582 - val_loss: nan\n",
      "Epoch 16/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4897 - loss: 1.4342 - val_accuracy: 0.4744 - val_loss: nan\n",
      "Epoch 17/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.4913 - loss: 1.4187 - val_accuracy: 0.4554 - val_loss: nan\n",
      "Epoch 18/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4840 - loss: 1.4319 - val_accuracy: 0.4590 - val_loss: nan\n",
      "Epoch 19/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4936 - loss: 1.4194 - val_accuracy: 0.4534 - val_loss: nan\n",
      "Epoch 20/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4931 - loss: 1.4222 - val_accuracy: 0.4410 - val_loss: nan\n",
      "Epoch 21/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.4992 - loss: 1.4035 - val_accuracy: 0.4614 - val_loss: nan\n",
      "Epoch 22/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.4972 - loss: 1.4188 - val_accuracy: 0.4586 - val_loss: nan\n",
      "Epoch 23/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.4998 - loss: 1.4012 - val_accuracy: 0.4424 - val_loss: nan\n",
      "Epoch 24/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5011 - loss: 1.3980 - val_accuracy: 0.4596 - val_loss: nan\n",
      "Epoch 25/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5007 - loss: 1.3941 - val_accuracy: 0.4602 - val_loss: nan\n",
      "Epoch 26/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.5052 - loss: 1.3870 - val_accuracy: 0.4726 - val_loss: nan\n",
      "Epoch 27/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5015 - loss: 1.3939 - val_accuracy: 0.4418 - val_loss: nan\n",
      "Epoch 28/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5118 - loss: 1.3781 - val_accuracy: 0.4594 - val_loss: nan\n",
      "Epoch 29/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.5056 - loss: 1.3845 - val_accuracy: 0.4668 - val_loss: nan\n",
      "Epoch 30/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5087 - loss: 1.3777 - val_accuracy: 0.4760 - val_loss: nan\n",
      "Epoch 31/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.5067 - loss: 1.3806 - val_accuracy: 0.4624 - val_loss: nan\n",
      "Epoch 32/60\n",
      "\u001b[1m1520/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5111 - loss: 1.3694"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 62\u001b[0m\n\u001b[1;32m     57\u001b[0m             mejor_ep_acc \u001b[38;5;241m=\u001b[39m val_acc_arr[i]\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTasa aprendizaje\u001b[39m\u001b[38;5;124m'\u001b[39m: mejor_lr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntrenamiento accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: hist\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][mejor_ep], \n\u001b[1;32m     60\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidacion accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: mejor_ep_acc, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTiempo\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mround(time_fin\u001b[38;5;241m-\u001b[39mtime_ini), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMejor epoca\u001b[39m\u001b[38;5;124m'\u001b[39m: mejor_ep}\n\u001b[0;32m---> 62\u001b[0m historial[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mej_CyD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 48\u001b[0m, in \u001b[0;36mej_CyD\u001b[0;34m(model, letra)\u001b[0m\n\u001b[1;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39msparse_categorical_crossentropy,\n\u001b[1;32m     44\u001b[0m             optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mNadam(learning_rate\u001b[38;5;241m=\u001b[39mmejor_lr),   \u001b[38;5;66;03m# asignar tasa de aprendizaje\u001b[39;00m\n\u001b[1;32m     45\u001b[0m             metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     47\u001b[0m time_ini \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 48\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m time_fin \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     51\u001b[0m mejor_ep \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/iabd_3_9/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/iabd_3_9/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/anaconda3/envs/iabd_3_9/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/iabd_3_9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/iabd_3_9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/iabd_3_9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/iabd_3_9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/iabd_3_9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/iabd_3_9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/iabd_3_9/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/iabd_3_9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Limpiamos memoria\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# crear red\n",
    "model = tf.keras.Sequential()      # creacion del modelo\n",
    "model.add(tf.keras.layers.Input(shape=(32,32,3)))    # capa entrada,   shape= imagen de 32x32 a color 3\n",
    "model.add(tf.keras.layers.Flatten())      # capa flatten\n",
    "for i in range(20):        \n",
    "    model.add(tf.keras.layers.Dense(100, activation=swish, kernel_initializer='he_normal'))    # las 20 capas ocultas de 100 neuronas activacion swish\n",
    "    model.add(tf.keras.layers.BatchNormalization())      # normalizacion\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))     # capa salida \n",
    "\n",
    "\n",
    "def ej_CyD(model, letra):\n",
    "    mejor_acc = 0\n",
    "    mejor_lr = None\n",
    "    # C, hayar mejor lr\n",
    "    rangos = [5e-6, 1e-6, 5e-5, 1e-5, 5e-4, 1e-4, 5e-3, 1e-3, 1e-2]\n",
    "    for lr in rangos:\n",
    "        # compilar\n",
    "        model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                optimizer=tf.keras.optimizers.Nadam(learning_rate=lr),  \n",
    "                metrics=['accuracy'])\n",
    "        # entrenar\n",
    "        time_ini = time.time()\n",
    "        hist = model.fit(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
    "        time_fin = time.time()\n",
    "        \n",
    "        # guardar mejor lr\n",
    "        val_acc = np.sort( hist.history['val_accuracy'])[-1]     # oredenado de menor a mayor cojo el ultimo\n",
    "        if val_acc > mejor_acc:\n",
    "            mejor_lr = lr\n",
    "\n",
    "\n",
    "    # D, aplicar detencion temprana con el mejor lr\n",
    "    early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True)\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"./recursos/checkpoint/4_6_\"+letra+\"_checkpoints.weights.h5\", save_weights_only=True)\n",
    "\n",
    "    hist = model.fit(x_train, y_train, epochs=70, validation_data=(x_val, y_val), \n",
    "                        callbacks=[checkpoint_cb,early_stopping_cb])\n",
    "\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                optimizer=tf.keras.optimizers.Nadam(learning_rate=mejor_lr),   # asignar tasa de aprendizaje\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    time_ini = time.time()\n",
    "    hist = model.fit(x_train, y_train, epochs=60, validation_data=(x_val, y_val))\n",
    "    time_fin = time.time()\n",
    "\n",
    "    mejor_ep = 0\n",
    "    mejor_ep_acc = 0\n",
    "    val_acc_arr = hist.history['val_accuracy']\n",
    "    for i in range(len(val_acc_arr)): \n",
    "        if val_acc_arr[i] > mejor_ep_acc: \n",
    "            mejor_ep = i\n",
    "            mejor_ep_acc = val_acc_arr[i]\n",
    "\n",
    "    return {'Tasa aprendizaje': mejor_lr, 'Entrenamiento accuracy': hist.history['accuracy'][mejor_ep], \n",
    "        'Validacion accuracy': mejor_ep_acc, 'Tiempo': np.round(time_fin-time_ini), 'Mejor epoca': mejor_ep}\n",
    "\n",
    "historial['E'] = ej_CyD(model,'E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F\n",
    "Prueba a sustituir la normalización de lotes por la activación SELU y haz los ajustes necesarios para garantizar que la red se autonormaliza (es decir, tienes que estandarizar los datos antes de empezar).\n",
    "\n",
    "En este caso prueba a estandarizar manualmentes, es decir restando la media y dividiendo por la desviación standard.\n",
    "\n",
    "Usa la inicialización LeCun normal.\n",
    "\n",
    "Repite C y D con esta nueva red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.2256 - loss: 2.2520 - val_accuracy: 0.3362 - val_loss: 1.8619\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3513 - loss: 1.8172 - val_accuracy: 0.3750 - val_loss: 1.7478\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3903 - loss: 1.7106 - val_accuracy: 0.4022 - val_loss: 1.6895\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4137 - loss: 1.6425 - val_accuracy: 0.4160 - val_loss: 1.6477\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4392 - loss: 1.5930 - val_accuracy: 0.4270 - val_loss: 1.6140\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4523 - loss: 1.5490 - val_accuracy: 0.4358 - val_loss: 1.5977\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4682 - loss: 1.5119 - val_accuracy: 0.4312 - val_loss: 1.5849\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4741 - loss: 1.4831 - val_accuracy: 0.4416 - val_loss: 1.5603\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4882 - loss: 1.4571 - val_accuracy: 0.4456 - val_loss: 1.5607\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5017 - loss: 1.4154 - val_accuracy: 0.4506 - val_loss: 1.5471\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4940199851989746    Validacion accuracy: 0.4505999982357025    Tiempo: 26.782188653945923    \n",
      "Mejor lr:  1e-05 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.3313 - loss: 1.8899 - val_accuracy: 0.4200 - val_loss: 1.6347\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4222 - loss: 1.6439 - val_accuracy: 0.4426 - val_loss: 1.5732\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4515 - loss: 1.5554 - val_accuracy: 0.4624 - val_loss: 1.5638\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4760 - loss: 1.4870 - val_accuracy: 0.4592 - val_loss: 1.5232\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4992 - loss: 1.4270 - val_accuracy: 0.4916 - val_loss: 1.4621\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5198 - loss: 1.3685 - val_accuracy: 0.4976 - val_loss: 1.4935\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5392 - loss: 1.3290 - val_accuracy: 0.5054 - val_loss: 1.4226\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5571 - loss: 1.2827 - val_accuracy: 0.5062 - val_loss: 1.4314\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5674 - loss: 1.2383 - val_accuracy: 0.5210 - val_loss: 1.4339\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5818 - loss: 1.2023 - val_accuracy: 0.5100 - val_loss: 1.4442\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4940199851989746    Validacion accuracy: 0.4505999982357025    Tiempo: 26.782188653945923    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5768799781799316    Validacion accuracy: 0.5099999904632568    Tiempo: 26.618760585784912    \n",
      "Mejor lr:  0.0005 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6363 - loss: 1.0504 - val_accuracy: 0.5410 - val_loss: 1.3654\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6613 - loss: 0.9701 - val_accuracy: 0.5378 - val_loss: 1.4030\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6754 - loss: 0.9281 - val_accuracy: 0.5356 - val_loss: 1.4398\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6849 - loss: 0.9026 - val_accuracy: 0.5354 - val_loss: 1.4315\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6996 - loss: 0.8660 - val_accuracy: 0.5320 - val_loss: 1.4658\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7083 - loss: 0.8400 - val_accuracy: 0.5332 - val_loss: 1.4836\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7160 - loss: 0.8222 - val_accuracy: 0.5344 - val_loss: 1.5004\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7257 - loss: 0.7979 - val_accuracy: 0.5288 - val_loss: 1.5338\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7372 - loss: 0.7646 - val_accuracy: 0.5304 - val_loss: 1.5861\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7403 - loss: 0.7524 - val_accuracy: 0.5316 - val_loss: 1.5910\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4940199851989746    Validacion accuracy: 0.4505999982357025    Tiempo: 26.782188653945923    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5768799781799316    Validacion accuracy: 0.5099999904632568    Tiempo: 26.618760585784912    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7377399802207947    Validacion accuracy: 0.5315999984741211    Tiempo: 27.045398235321045    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1557 - loss: 2.6473 - val_accuracy: 0.0982 - val_loss: 2.3165\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0948 - loss: 2.3508 - val_accuracy: 0.1024 - val_loss: 2.3618\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1009 - loss: 2.3568 - val_accuracy: 0.1008 - val_loss: 2.3837\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0991 - loss: 2.3598 - val_accuracy: 0.0994 - val_loss: 2.3314\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1007 - loss: 2.3592 - val_accuracy: 0.0982 - val_loss: 2.3761\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1015 - loss: 2.3582 - val_accuracy: 0.0976 - val_loss: 2.3470\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1020 - loss: 2.3617 - val_accuracy: 0.1008 - val_loss: 2.3470\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1018 - loss: 2.3602 - val_accuracy: 0.0982 - val_loss: 2.3191\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1027 - loss: 2.3613 - val_accuracy: 0.0982 - val_loss: 2.3510\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1045 - loss: 2.3590 - val_accuracy: 0.1024 - val_loss: 2.3820\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4940199851989746    Validacion accuracy: 0.4505999982357025    Tiempo: 26.782188653945923    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5768799781799316    Validacion accuracy: 0.5099999904632568    Tiempo: 26.618760585784912    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7377399802207947    Validacion accuracy: 0.5315999984741211    Tiempo: 27.045398235321045    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.10344000160694122    Validacion accuracy: 0.10239999741315842    Tiempo: 26.419175624847412    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.0946 - loss: 2.3218 - val_accuracy: 0.1014 - val_loss: 2.3212\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0979 - loss: 2.3224 - val_accuracy: 0.1008 - val_loss: 2.3177\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1013 - loss: 2.3200 - val_accuracy: 0.1024 - val_loss: 2.3282\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1011 - loss: 2.3202 - val_accuracy: 0.0976 - val_loss: 2.3319\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1003 - loss: 2.3222 - val_accuracy: 0.1026 - val_loss: 2.3270\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3230 - val_accuracy: 0.0990 - val_loss: 2.3293\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1001 - loss: 2.3224 - val_accuracy: 0.1014 - val_loss: 2.3375\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3214 - val_accuracy: 0.1014 - val_loss: 2.3177\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1017 - loss: 2.3214 - val_accuracy: 0.1024 - val_loss: 2.3223\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0982 - loss: 2.3223 - val_accuracy: 0.0994 - val_loss: 2.3311\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4940199851989746    Validacion accuracy: 0.4505999982357025    Tiempo: 26.782188653945923    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5768799781799316    Validacion accuracy: 0.5099999904632568    Tiempo: 26.618760585784912    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7377399802207947    Validacion accuracy: 0.5315999984741211    Tiempo: 27.045398235321045    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.10344000160694122    Validacion accuracy: 0.10239999741315842    Tiempo: 26.419175624847412    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.09935999661684036    Validacion accuracy: 0.09939999878406525    Tiempo: 25.820282697677612    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1040 - loss: 3.1708 - val_accuracy: 0.0990 - val_loss: 3.1332\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0993 - loss: 3.0043 - val_accuracy: 0.1024 - val_loss: 3.3519\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0997 - loss: 2.9749 - val_accuracy: 0.0976 - val_loss: 3.9328\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1020 - loss: 2.9608 - val_accuracy: 0.1014 - val_loss: 3.0890\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0974 - loss: 2.9793 - val_accuracy: 0.0990 - val_loss: 3.1320\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1013 - loss: 3.0000 - val_accuracy: 0.0994 - val_loss: 2.7670\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 3.0254 - val_accuracy: 0.0994 - val_loss: 2.6800\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0994 - loss: 2.9610 - val_accuracy: 0.0976 - val_loss: 4.2185\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1014 - loss: 2.9456 - val_accuracy: 0.1014 - val_loss: 2.6791\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0988 - loss: 2.9732 - val_accuracy: 0.0976 - val_loss: 5.1184\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4940199851989746    Validacion accuracy: 0.4505999982357025    Tiempo: 26.782188653945923    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5768799781799316    Validacion accuracy: 0.5099999904632568    Tiempo: 26.618760585784912    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7377399802207947    Validacion accuracy: 0.5315999984741211    Tiempo: 27.045398235321045    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.10344000160694122    Validacion accuracy: 0.10239999741315842    Tiempo: 26.419175624847412    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.09935999661684036    Validacion accuracy: 0.09939999878406525    Tiempo: 25.820282697677612    \n",
      "Tasa aprendizaje: 0.05    Entrenamiento accuracy: 0.09922000020742416    Validacion accuracy: 0.09759999811649323    Tiempo: 26.915548086166382    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1022 - loss: 2.4247 - val_accuracy: 0.1008 - val_loss: 2.3751\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1023 - loss: 2.3939 - val_accuracy: 0.1010 - val_loss: 2.3707\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0976 - loss: 2.3957 - val_accuracy: 0.1024 - val_loss: 2.4755\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3990 - val_accuracy: 0.0976 - val_loss: 2.4120\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1002 - loss: 2.3957 - val_accuracy: 0.1026 - val_loss: 2.4381\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 2.3959 - val_accuracy: 0.0976 - val_loss: 2.4677\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0963 - loss: 2.3980 - val_accuracy: 0.0976 - val_loss: 2.3820\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0996 - loss: 2.4005 - val_accuracy: 0.1024 - val_loss: 2.4834\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1020 - loss: 2.3950 - val_accuracy: 0.0976 - val_loss: 2.4134\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0936 - loss: 2.3991 - val_accuracy: 0.1014 - val_loss: 2.4928\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4940199851989746    Validacion accuracy: 0.4505999982357025    Tiempo: 26.782188653945923    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5768799781799316    Validacion accuracy: 0.5099999904632568    Tiempo: 26.618760585784912    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7377399802207947    Validacion accuracy: 0.5315999984741211    Tiempo: 27.045398235321045    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.10344000160694122    Validacion accuracy: 0.10239999741315842    Tiempo: 26.419175624847412    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.09935999661684036    Validacion accuracy: 0.09939999878406525    Tiempo: 25.820282697677612    \n",
      "Tasa aprendizaje: 0.05    Entrenamiento accuracy: 0.09922000020742416    Validacion accuracy: 0.09759999811649323    Tiempo: 26.915548086166382    \n",
      "Tasa aprendizaje: 0.01    Entrenamiento accuracy: 0.09662000089883804    Validacion accuracy: 0.10140000283718109    Tiempo: 27.003178119659424    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1007 - loss: 2.3993 - val_accuracy: 0.0982 - val_loss: 2.6624\n",
      "Epoch 2/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1005 - loss: 2.3973 - val_accuracy: 0.1014 - val_loss: 2.4745\n",
      "Epoch 3/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1033 - loss: 2.3948 - val_accuracy: 0.1026 - val_loss: 2.3362\n",
      "Epoch 4/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0986 - loss: 2.3945 - val_accuracy: 0.1014 - val_loss: 2.3867\n",
      "Epoch 5/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0996 - loss: 2.3971 - val_accuracy: 0.0982 - val_loss: 2.4568\n",
      "Epoch 6/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1011 - loss: 2.3950 - val_accuracy: 0.0994 - val_loss: 2.3675\n",
      "Epoch 7/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 2.3979 - val_accuracy: 0.1010 - val_loss: 2.3897\n",
      "Epoch 1/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1015 - loss: 2.3072 - val_accuracy: 0.1014 - val_loss: 2.3036\n",
      "Epoch 2/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3047 - val_accuracy: 0.1008 - val_loss: 2.3048\n",
      "Epoch 3/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0952 - loss: 2.3055 - val_accuracy: 0.1010 - val_loss: 2.3038\n",
      "Epoch 4/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0990 - loss: 2.3049 - val_accuracy: 0.1008 - val_loss: 2.3049\n",
      "Epoch 5/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0973 - loss: 2.3054 - val_accuracy: 0.1014 - val_loss: 2.3048\n",
      "Epoch 6/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1009 - loss: 2.3051 - val_accuracy: 0.1024 - val_loss: 2.3048\n",
      "Epoch 7/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3050 - val_accuracy: 0.0982 - val_loss: 2.3050\n",
      "Epoch 8/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0992 - loss: 2.3048 - val_accuracy: 0.0990 - val_loss: 2.3054\n",
      "Epoch 9/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0993 - loss: 2.3049 - val_accuracy: 0.1014 - val_loss: 2.3057\n",
      "Epoch 10/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0972 - loss: 2.3051 - val_accuracy: 0.1008 - val_loss: 2.3052\n",
      "Epoch 11/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0982 - loss: 2.3048 - val_accuracy: 0.1026 - val_loss: 2.3048\n",
      "Epoch 12/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0972 - loss: 2.3052 - val_accuracy: 0.1026 - val_loss: 2.3042\n",
      "Epoch 13/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0933 - loss: 2.3053 - val_accuracy: 0.1014 - val_loss: 2.3034\n",
      "Epoch 14/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1001 - loss: 2.3049 - val_accuracy: 0.1010 - val_loss: 2.3047\n",
      "Epoch 15/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0930 - loss: 2.3055 - val_accuracy: 0.0994 - val_loss: 2.3038\n",
      "Epoch 16/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0979 - loss: 2.3051 - val_accuracy: 0.1008 - val_loss: 2.3037\n",
      "Epoch 17/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0978 - loss: 2.3046 - val_accuracy: 0.1024 - val_loss: 2.3030\n",
      "Epoch 18/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1001 - loss: 2.3046 - val_accuracy: 0.0990 - val_loss: 2.3053\n",
      "Epoch 19/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 2.3050 - val_accuracy: 0.1008 - val_loss: 2.3045\n",
      "Epoch 20/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1002 - loss: 2.3049 - val_accuracy: 0.1024 - val_loss: 2.3038\n",
      "Epoch 21/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1006 - loss: 2.3047 - val_accuracy: 0.1010 - val_loss: 2.3036\n",
      "Epoch 22/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0990 - loss: 2.3047 - val_accuracy: 0.0982 - val_loss: 2.3055\n",
      "Epoch 23/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0997 - loss: 2.3051 - val_accuracy: 0.0976 - val_loss: 2.3033\n",
      "Epoch 24/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1035 - loss: 2.3047 - val_accuracy: 0.1024 - val_loss: 2.3042\n",
      "Epoch 25/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0982 - loss: 2.3053 - val_accuracy: 0.0990 - val_loss: 2.3048\n",
      "Epoch 26/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0998 - loss: 2.3054 - val_accuracy: 0.0982 - val_loss: 2.3040\n",
      "Epoch 27/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1025 - loss: 2.3046 - val_accuracy: 0.0976 - val_loss: 2.3052\n",
      "Epoch 28/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0987 - loss: 2.3048 - val_accuracy: 0.1014 - val_loss: 2.3054\n",
      "Epoch 29/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0981 - loss: 2.3050 - val_accuracy: 0.0994 - val_loss: 2.3051\n",
      "Epoch 30/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3052 - val_accuracy: 0.1008 - val_loss: 2.3034\n",
      "Epoch 31/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0991 - loss: 2.3050 - val_accuracy: 0.1024 - val_loss: 2.3040\n",
      "Epoch 32/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3052 - val_accuracy: 0.1024 - val_loss: 2.3041\n",
      "Epoch 33/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0988 - loss: 2.3044 - val_accuracy: 0.1010 - val_loss: 2.3051\n",
      "Epoch 34/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0998 - loss: 2.3048 - val_accuracy: 0.0994 - val_loss: 2.3034\n",
      "Epoch 35/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0972 - loss: 2.3048 - val_accuracy: 0.0990 - val_loss: 2.3044\n",
      "Epoch 36/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 2.3047 - val_accuracy: 0.1024 - val_loss: 2.3037\n",
      "Epoch 37/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1001 - loss: 2.3052 - val_accuracy: 0.0976 - val_loss: 2.3052\n",
      "Epoch 38/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3053 - val_accuracy: 0.1026 - val_loss: 2.3028\n",
      "Epoch 39/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3048 - val_accuracy: 0.1008 - val_loss: 2.3049\n",
      "Epoch 40/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3050 - val_accuracy: 0.0982 - val_loss: 2.3048\n",
      "Epoch 41/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1003 - loss: 2.3053 - val_accuracy: 0.0976 - val_loss: 2.3046\n",
      "Epoch 42/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0997 - loss: 2.3046 - val_accuracy: 0.0994 - val_loss: 2.3047\n",
      "Epoch 43/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0998 - loss: 2.3050 - val_accuracy: 0.1014 - val_loss: 2.3063\n",
      "Epoch 44/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1018 - loss: 2.3053 - val_accuracy: 0.0994 - val_loss: 2.3065\n",
      "Epoch 45/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 2.3050 - val_accuracy: 0.1008 - val_loss: 2.3042\n",
      "Epoch 46/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1037 - loss: 2.3047 - val_accuracy: 0.1008 - val_loss: 2.3040\n",
      "Epoch 47/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3048 - val_accuracy: 0.1024 - val_loss: 2.3035\n",
      "Epoch 48/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0986 - loss: 2.3049 - val_accuracy: 0.1008 - val_loss: 2.3047\n",
      "Epoch 49/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1002 - loss: 2.3051 - val_accuracy: 0.1010 - val_loss: 2.3043\n",
      "Epoch 50/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1024 - loss: 2.3048 - val_accuracy: 0.1008 - val_loss: 2.3047\n",
      "Epoch 51/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0979 - loss: 2.3049 - val_accuracy: 0.1026 - val_loss: 2.3041\n",
      "Epoch 52/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0963 - loss: 2.3049 - val_accuracy: 0.0976 - val_loss: 2.3045\n",
      "Epoch 53/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1044 - loss: 2.3052 - val_accuracy: 0.0976 - val_loss: 2.3036\n",
      "Epoch 54/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1018 - loss: 2.3046 - val_accuracy: 0.1010 - val_loss: 2.3045\n",
      "Epoch 55/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1004 - loss: 2.3051 - val_accuracy: 0.1026 - val_loss: 2.3040\n",
      "Epoch 56/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0997 - loss: 2.3048 - val_accuracy: 0.0976 - val_loss: 2.3050\n",
      "Epoch 57/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1011 - loss: 2.3051 - val_accuracy: 0.1008 - val_loss: 2.3064\n",
      "Epoch 58/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3049 - val_accuracy: 0.0976 - val_loss: 2.3053\n",
      "Epoch 59/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3049 - val_accuracy: 0.1026 - val_loss: 2.3045\n",
      "Epoch 60/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1051 - loss: 2.3046 - val_accuracy: 0.1008 - val_loss: 2.3037\n",
      "\n",
      "Tasa aprendizaje: 0.0001\n",
      "Entrenamiento accuracy: 0.10335999727249146\n",
      "Validacion accuracy: 0.10080000013113022\n",
      "Tiempo: 140.0\n",
      "Mejor epoca: 59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Limpiamos memoria\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# estandarizar\n",
    "media = np.mean(x_train, axis=(0, 1, 2))\n",
    "desviacion = np.std(x_train, axis=(0, 1, 2))\n",
    "x_train = (x_train - media) / desviacion\n",
    "x_val = (x_val - media) / desviacion\n",
    "x_test = (x_test - media) / desviacion\n",
    "\n",
    "\n",
    "# crear red\n",
    "model = tf.keras.Sequential()      # creacion del modelo\n",
    "model.add(tf.keras.layers.Input(shape=(32,32,3)))    # capa entrada,   shape= imagen de 32x32 a color 3\n",
    "model.add(tf.keras.layers.Flatten())      # capa flatten\n",
    "for i in range(20):        \n",
    "    model.add(tf.keras.layers.Dense(100, activation='selu', kernel_initializer=tf.keras.initializers.LecunNormal))    # las 20 capas ocultas de 100 neuronas activacion swish\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))     # capa salida \n",
    "\n",
    "historial['F'] = ej_CyD(model,'F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G\n",
    "Prueba ahora a regularizar el modelo anterior añadiendo una capa dropout antes de la última capa (estandariza manualmente como en el punto anterior).\n",
    "\n",
    "Repite C y D con esta nueva red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1920 - loss: 2.4504 - val_accuracy: 0.3278 - val_loss: 1.9106\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3014 - loss: 1.9857 - val_accuracy: 0.3676 - val_loss: 1.7882\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3414 - loss: 1.8611 - val_accuracy: 0.3948 - val_loss: 1.7192\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3699 - loss: 1.7832 - val_accuracy: 0.4162 - val_loss: 1.6785\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3948 - loss: 1.7076 - val_accuracy: 0.4288 - val_loss: 1.6381\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4129 - loss: 1.6575 - val_accuracy: 0.4336 - val_loss: 1.6074\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4310 - loss: 1.6042 - val_accuracy: 0.4418 - val_loss: 1.6007\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4411 - loss: 1.5720 - val_accuracy: 0.4502 - val_loss: 1.5833\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4527 - loss: 1.5487 - val_accuracy: 0.4536 - val_loss: 1.5694\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4638 - loss: 1.5146 - val_accuracy: 0.4608 - val_loss: 1.5526\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4607999920845032    Validacion accuracy: 0.4607999920845032    Tiempo: 27.522173643112183    \n",
      "Mejor lr:  1e-05 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.3072 - loss: 1.9801 - val_accuracy: 0.4210 - val_loss: 1.6603\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4046 - loss: 1.6893 - val_accuracy: 0.4386 - val_loss: 1.6070\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4462 - loss: 1.5693 - val_accuracy: 0.4634 - val_loss: 1.5525\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4782 - loss: 1.4922 - val_accuracy: 0.4770 - val_loss: 1.5376\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4976 - loss: 1.4392 - val_accuracy: 0.4938 - val_loss: 1.4622\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5170 - loss: 1.3852 - val_accuracy: 0.4872 - val_loss: 1.4779\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5362 - loss: 1.3404 - val_accuracy: 0.5052 - val_loss: 1.4460\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5543 - loss: 1.3007 - val_accuracy: 0.4950 - val_loss: 1.4486\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5620 - loss: 1.2697 - val_accuracy: 0.5314 - val_loss: 1.3883\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5811 - loss: 1.2301 - val_accuracy: 0.5024 - val_loss: 1.4401\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4607999920845032    Validacion accuracy: 0.4607999920845032    Tiempo: 27.522173643112183    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5764200091362    Validacion accuracy: 0.5023999810218811    Tiempo: 27.608420848846436    \n",
      "Mejor lr:  0.0005 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.6295 - loss: 1.0744 - val_accuracy: 0.5432 - val_loss: 1.3795\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6605 - loss: 0.9821 - val_accuracy: 0.5426 - val_loss: 1.3829\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6774 - loss: 0.9433 - val_accuracy: 0.5360 - val_loss: 1.4061\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6857 - loss: 0.9171 - val_accuracy: 0.5370 - val_loss: 1.4154\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6967 - loss: 0.8934 - val_accuracy: 0.5322 - val_loss: 1.4483\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7060 - loss: 0.8599 - val_accuracy: 0.5348 - val_loss: 1.4600\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7134 - loss: 0.8392 - val_accuracy: 0.5302 - val_loss: 1.4890\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7241 - loss: 0.8177 - val_accuracy: 0.5344 - val_loss: 1.4962\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7383 - loss: 0.7852 - val_accuracy: 0.5252 - val_loss: 1.5298\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7422 - loss: 0.7632 - val_accuracy: 0.5276 - val_loss: 1.5441\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4607999920845032    Validacion accuracy: 0.4607999920845032    Tiempo: 27.522173643112183    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5764200091362    Validacion accuracy: 0.5023999810218811    Tiempo: 27.608420848846436    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7378000020980835    Validacion accuracy: 0.5275999903678894    Tiempo: 26.994523763656616    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1652 - loss: 2.5058 - val_accuracy: 0.1014 - val_loss: 2.3206\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1003 - loss: 2.4378 - val_accuracy: 0.0990 - val_loss: 2.3431\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1002 - loss: 2.3891 - val_accuracy: 0.1028 - val_loss: 2.3792\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3798 - val_accuracy: 0.1024 - val_loss: 2.3334\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0974 - loss: 2.3774 - val_accuracy: 0.1014 - val_loss: 2.4248\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1012 - loss: 2.3786 - val_accuracy: 0.1008 - val_loss: 2.3227\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3789 - val_accuracy: 0.1010 - val_loss: 2.3602\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3827 - val_accuracy: 0.0990 - val_loss: 2.3783\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1011 - loss: 2.3798 - val_accuracy: 0.0982 - val_loss: 2.3682\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0984 - loss: 2.3813 - val_accuracy: 0.0976 - val_loss: 2.3634\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4607999920845032    Validacion accuracy: 0.4607999920845032    Tiempo: 27.522173643112183    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5764200091362    Validacion accuracy: 0.5023999810218811    Tiempo: 27.608420848846436    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7378000020980835    Validacion accuracy: 0.5275999903678894    Tiempo: 26.994523763656616    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.09796000272035599    Validacion accuracy: 0.09759999811649323    Tiempo: 27.22620153427124    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1007 - loss: 2.3386 - val_accuracy: 0.1008 - val_loss: 2.3112\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1022 - loss: 2.3248 - val_accuracy: 0.0976 - val_loss: 2.3243\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1004 - loss: 2.3259 - val_accuracy: 0.1008 - val_loss: 2.3195\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1015 - loss: 2.3234 - val_accuracy: 0.1014 - val_loss: 2.3147\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3247 - val_accuracy: 0.1008 - val_loss: 2.3243\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1000 - loss: 2.3260 - val_accuracy: 0.1008 - val_loss: 2.3219\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1013 - loss: 2.3241 - val_accuracy: 0.1024 - val_loss: 2.3415\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1026 - loss: 2.3231 - val_accuracy: 0.1026 - val_loss: 2.3114\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0996 - loss: 2.3247 - val_accuracy: 0.0982 - val_loss: 2.3130\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1007 - loss: 2.3249 - val_accuracy: 0.0976 - val_loss: 2.3127\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4607999920845032    Validacion accuracy: 0.4607999920845032    Tiempo: 27.522173643112183    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5764200091362    Validacion accuracy: 0.5023999810218811    Tiempo: 27.608420848846436    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7378000020980835    Validacion accuracy: 0.5275999903678894    Tiempo: 26.994523763656616    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.09796000272035599    Validacion accuracy: 0.09759999811649323    Tiempo: 27.22620153427124    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.0993800014257431    Validacion accuracy: 0.09759999811649323    Tiempo: 27.51779866218567    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 3.2308 - val_accuracy: 0.1010 - val_loss: 3.2676\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0967 - loss: 3.0717 - val_accuracy: 0.1024 - val_loss: 3.6810\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0960 - loss: 3.1015 - val_accuracy: 0.1010 - val_loss: 3.1578\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 3.0452 - val_accuracy: 0.1008 - val_loss: 2.9680\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1001 - loss: 3.0630 - val_accuracy: 0.0976 - val_loss: 3.1445\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0987 - loss: 3.0480 - val_accuracy: 0.0990 - val_loss: 2.8231\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0998 - loss: 3.0634 - val_accuracy: 0.0994 - val_loss: 4.0752\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1036 - loss: 3.0653 - val_accuracy: 0.0990 - val_loss: 3.0843\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 3.0966 - val_accuracy: 0.1026 - val_loss: 4.1017\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1004 - loss: 3.1060 - val_accuracy: 0.1024 - val_loss: 2.8778\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4607999920845032    Validacion accuracy: 0.4607999920845032    Tiempo: 27.522173643112183    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5764200091362    Validacion accuracy: 0.5023999810218811    Tiempo: 27.608420848846436    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7378000020980835    Validacion accuracy: 0.5275999903678894    Tiempo: 26.994523763656616    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.09796000272035599    Validacion accuracy: 0.09759999811649323    Tiempo: 27.22620153427124    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.0993800014257431    Validacion accuracy: 0.09759999811649323    Tiempo: 27.51779866218567    \n",
      "Tasa aprendizaje: 0.05    Entrenamiento accuracy: 0.10044000297784805    Validacion accuracy: 0.10239999741315842    Tiempo: 27.561628341674805    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 2.4716 - val_accuracy: 0.0990 - val_loss: 2.4133\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1016 - loss: 2.4363 - val_accuracy: 0.1008 - val_loss: 2.4572\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1036 - loss: 2.4363 - val_accuracy: 0.0990 - val_loss: 2.5158\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0984 - loss: 2.4410 - val_accuracy: 0.1014 - val_loss: 2.4502\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0993 - loss: 2.4404 - val_accuracy: 0.1008 - val_loss: 2.4832\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0970 - loss: 2.4424 - val_accuracy: 0.0976 - val_loss: 2.3430\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1020 - loss: 2.4318 - val_accuracy: 0.1014 - val_loss: 2.3196\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1029 - loss: 2.4370 - val_accuracy: 0.1010 - val_loss: 2.3926\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0991 - loss: 2.4431 - val_accuracy: 0.0976 - val_loss: 2.4381\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0999 - loss: 2.4347 - val_accuracy: 0.0990 - val_loss: 2.4941\n",
      "Tasa aprendizaje: 1e-05    Entrenamiento accuracy: 0.4607999920845032    Validacion accuracy: 0.4607999920845032    Tiempo: 27.522173643112183    \n",
      "Tasa aprendizaje: 0.0005    Entrenamiento accuracy: 0.5764200091362    Validacion accuracy: 0.5023999810218811    Tiempo: 27.608420848846436    \n",
      "Tasa aprendizaje: 0.0001    Entrenamiento accuracy: 0.7378000020980835    Validacion accuracy: 0.5275999903678894    Tiempo: 26.994523763656616    \n",
      "Tasa aprendizaje: 0.005    Entrenamiento accuracy: 0.09796000272035599    Validacion accuracy: 0.09759999811649323    Tiempo: 27.22620153427124    \n",
      "Tasa aprendizaje: 0.001    Entrenamiento accuracy: 0.0993800014257431    Validacion accuracy: 0.09759999811649323    Tiempo: 27.51779866218567    \n",
      "Tasa aprendizaje: 0.05    Entrenamiento accuracy: 0.10044000297784805    Validacion accuracy: 0.10239999741315842    Tiempo: 27.561628341674805    \n",
      "Tasa aprendizaje: 0.01    Entrenamiento accuracy: 0.10000000149011612    Validacion accuracy: 0.0989999994635582    Tiempo: 27.657562017440796    \n",
      "Mejor lr:  0.0001 \n",
      "\n",
      "\n",
      "Epoch 1/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0974 - loss: 2.4378 - val_accuracy: 0.0976 - val_loss: 2.4094\n",
      "Epoch 2/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 2.4381 - val_accuracy: 0.0982 - val_loss: 2.3996\n",
      "Epoch 3/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0981 - loss: 2.4377 - val_accuracy: 0.0976 - val_loss: 2.3642\n",
      "Epoch 4/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0984 - loss: 2.4374 - val_accuracy: 0.0994 - val_loss: 2.5186\n",
      "Epoch 5/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1001 - loss: 2.4370 - val_accuracy: 0.1010 - val_loss: 2.3856\n",
      "Epoch 6/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1001 - loss: 2.4438 - val_accuracy: 0.1014 - val_loss: 2.4490\n",
      "Epoch 7/70\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 2.4372 - val_accuracy: 0.0982 - val_loss: 2.4386\n",
      "Epoch 1/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.1021 - loss: 2.3495 - val_accuracy: 0.1024 - val_loss: 2.3038\n",
      "Epoch 2/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0997 - loss: 2.3403 - val_accuracy: 0.1026 - val_loss: 2.3050\n",
      "Epoch 3/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1004 - loss: 2.3308 - val_accuracy: 0.1010 - val_loss: 2.3046\n",
      "Epoch 4/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1013 - loss: 2.3261 - val_accuracy: 0.0990 - val_loss: 2.3037\n",
      "Epoch 5/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3223 - val_accuracy: 0.0976 - val_loss: 2.3044\n",
      "Epoch 6/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3177 - val_accuracy: 0.1008 - val_loss: 2.3053\n",
      "Epoch 7/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1011 - loss: 2.3162 - val_accuracy: 0.1008 - val_loss: 2.3033\n",
      "Epoch 8/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0979 - loss: 2.3144 - val_accuracy: 0.0994 - val_loss: 2.3054\n",
      "Epoch 9/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0971 - loss: 2.3133 - val_accuracy: 0.0990 - val_loss: 2.3046\n",
      "Epoch 10/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1009 - loss: 2.3113 - val_accuracy: 0.1024 - val_loss: 2.3046\n",
      "Epoch 11/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 2.3093 - val_accuracy: 0.0976 - val_loss: 2.3044\n",
      "Epoch 12/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 2.3082 - val_accuracy: 0.0990 - val_loss: 2.3058\n",
      "Epoch 13/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0995 - loss: 2.3084 - val_accuracy: 0.1026 - val_loss: 2.3035\n",
      "Epoch 14/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3076 - val_accuracy: 0.0990 - val_loss: 2.3045\n",
      "Epoch 15/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1018 - loss: 2.3061 - val_accuracy: 0.1008 - val_loss: 2.3046\n",
      "Epoch 16/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1015 - loss: 2.3069 - val_accuracy: 0.1010 - val_loss: 2.3032\n",
      "Epoch 17/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.1001 - loss: 2.3067 - val_accuracy: 0.0976 - val_loss: 2.3048\n",
      "Epoch 18/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3063 - val_accuracy: 0.0990 - val_loss: 2.3053\n",
      "Epoch 19/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0975 - loss: 2.3060 - val_accuracy: 0.1008 - val_loss: 2.3035\n",
      "Epoch 20/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1024 - loss: 2.3053 - val_accuracy: 0.1010 - val_loss: 2.3043\n",
      "Epoch 21/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1009 - loss: 2.3057 - val_accuracy: 0.1008 - val_loss: 2.3068\n",
      "Epoch 22/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1003 - loss: 2.3058 - val_accuracy: 0.0976 - val_loss: 2.3050\n",
      "Epoch 23/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0961 - loss: 2.3056 - val_accuracy: 0.0976 - val_loss: 2.3039\n",
      "Epoch 24/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0992 - loss: 2.3060 - val_accuracy: 0.0976 - val_loss: 2.3046\n",
      "Epoch 25/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1005 - loss: 2.3053 - val_accuracy: 0.1008 - val_loss: 2.3043\n",
      "Epoch 26/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1004 - loss: 2.3056 - val_accuracy: 0.1014 - val_loss: 2.3032\n",
      "Epoch 27/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0993 - loss: 2.3052 - val_accuracy: 0.1014 - val_loss: 2.3042\n",
      "Epoch 28/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1019 - loss: 2.3052 - val_accuracy: 0.0990 - val_loss: 2.3038\n",
      "Epoch 29/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1025 - loss: 2.3051 - val_accuracy: 0.0990 - val_loss: 2.3044\n",
      "Epoch 30/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0981 - loss: 2.3053 - val_accuracy: 0.0994 - val_loss: 2.3036\n",
      "Epoch 31/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1001 - loss: 2.3055 - val_accuracy: 0.1010 - val_loss: 2.3042\n",
      "Epoch 32/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3055 - val_accuracy: 0.1010 - val_loss: 2.3058\n",
      "Epoch 33/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1008 - loss: 2.3052 - val_accuracy: 0.1014 - val_loss: 2.3034\n",
      "Epoch 34/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 2.3052 - val_accuracy: 0.0994 - val_loss: 2.3039\n",
      "Epoch 35/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0976 - loss: 2.3053 - val_accuracy: 0.0976 - val_loss: 2.3035\n",
      "Epoch 36/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 2.3050 - val_accuracy: 0.0994 - val_loss: 2.3059\n",
      "Epoch 37/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0987 - loss: 2.3056 - val_accuracy: 0.1014 - val_loss: 2.3051\n",
      "Epoch 38/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1018 - loss: 2.3054 - val_accuracy: 0.0994 - val_loss: 2.3036\n",
      "Epoch 39/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3052 - val_accuracy: 0.1024 - val_loss: 2.3058\n",
      "Epoch 40/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0976 - loss: 2.3059 - val_accuracy: 0.1014 - val_loss: 2.3041\n",
      "Epoch 41/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0977 - loss: 2.3052 - val_accuracy: 0.1024 - val_loss: 2.3038\n",
      "Epoch 42/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1003 - loss: 2.3048 - val_accuracy: 0.0976 - val_loss: 2.3061\n",
      "Epoch 43/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3053 - val_accuracy: 0.0990 - val_loss: 2.3041\n",
      "Epoch 44/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3053 - val_accuracy: 0.1010 - val_loss: 2.3028\n",
      "Epoch 45/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0998 - loss: 2.3052 - val_accuracy: 0.0976 - val_loss: 2.3057\n",
      "Epoch 46/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0985 - loss: 2.3056 - val_accuracy: 0.1010 - val_loss: 2.3035\n",
      "Epoch 47/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0996 - loss: 2.3051 - val_accuracy: 0.0990 - val_loss: 2.3038\n",
      "Epoch 48/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0976 - loss: 2.3056 - val_accuracy: 0.0990 - val_loss: 2.3062\n",
      "Epoch 49/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1016 - loss: 2.3055 - val_accuracy: 0.1024 - val_loss: 2.3039\n",
      "Epoch 50/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0959 - loss: 2.3053 - val_accuracy: 0.1008 - val_loss: 2.3043\n",
      "Epoch 51/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0986 - loss: 2.3053 - val_accuracy: 0.0982 - val_loss: 2.3040\n",
      "Epoch 52/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1017 - loss: 2.3047 - val_accuracy: 0.1014 - val_loss: 2.3050\n",
      "Epoch 53/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0962 - loss: 2.3054 - val_accuracy: 0.0994 - val_loss: 2.3049\n",
      "Epoch 54/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0999 - loss: 2.3052 - val_accuracy: 0.1010 - val_loss: 2.3050\n",
      "Epoch 55/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1002 - loss: 2.3051 - val_accuracy: 0.0990 - val_loss: 2.3044\n",
      "Epoch 56/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1028 - loss: 2.3050 - val_accuracy: 0.0990 - val_loss: 2.3058\n",
      "Epoch 57/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0996 - loss: 2.3056 - val_accuracy: 0.1008 - val_loss: 2.3048\n",
      "Epoch 58/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1000 - loss: 2.3053 - val_accuracy: 0.1014 - val_loss: 2.3057\n",
      "Epoch 59/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0947 - loss: 2.3051 - val_accuracy: 0.0976 - val_loss: 2.3040\n",
      "Epoch 60/60\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1029 - loss: 2.3051 - val_accuracy: 0.0994 - val_loss: 2.3043\n",
      "\n",
      "Tasa aprendizaje: 0.0001\n",
      "Entrenamiento accuracy: 0.10057999938726425\n",
      "Validacion accuracy: 0.09939999878406525\n",
      "Tiempo: 140.0\n",
      "Mejor epoca: 28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# con la estandarizacion de F es suficiente, no es necesario estandarizar de nuevo\n",
    "\n",
    "# Limpiamos memoria\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# crear red\n",
    "model = tf.keras.Sequential()      # creacion del modelo\n",
    "model.add(tf.keras.layers.Input(shape=(32,32,3)))    # capa entrada,   shape= imagen de 32x32 a color 3\n",
    "model.add(tf.keras.layers.Flatten())      # capa flatten\n",
    "for i in range(20):        \n",
    "    model.add(tf.keras.layers.Dense(100, activation='selu', kernel_initializer=tf.keras.initializers.LecunNormal))    # las 20 capas ocultas de 100 neuronas activacion swish\n",
    "model.add(tf.keras.layers.Dropout(0.2))     # capa dropout ('apaga' un porcentaje de neuronas al azar)\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))     # capa salida \n",
    "\n",
    "historial['G'] = ej_CyD(model,'G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#####   RESULTADOS   #######')\n",
    "for key,value in historial.items():\n",
    "    print(key,': ',value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iabd_3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
