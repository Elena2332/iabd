{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iabd/anaconda3/envs/iabd_3_10_SAM2/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from ultralytics.solutions.solutions import BaseSolution\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "import time \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.digitalocean.com/community/tutorials/what-is-new-with-yolo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 1 \n",
    "Vamos a usar el modleo YOLOv11 para detectar objetos en una imagen (en este caso vamos a aplicar el modelo directamente sin entrenarlo).\n",
    "Vamos a aplicarlo en las imagenes deteccion_objetos.jpg y bus.jpg\n",
    "\n",
    "Partiendo de la imagen deteccion_objetos.jpg y bus.jpg.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_imgs = 'recursos/5_5/'\n",
    "imgs_arr = [ruta_imgs+\"deteccion_objetos.jpg\",ruta_imgs+\"bus.jpg\"]\n",
    "# cargar modelo yolo11\n",
    "model = YOLO(\"recursos/5_5/yolo/yolo11n.pt\")   \n",
    "\n",
    "results = model(imgs_arr)\n",
    "for res in results:\n",
    "    res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a repetir el ejercicio pero ahora vamos a modificar la salida para que quede de la siguiente forma:\n",
    "\n",
    "![Imagen con la el resultado que se quiere obtener 1](recursos/5_5/deteccion_objetos_solucion.png)\n",
    "\n",
    "![Imagen con la el resultado que se quiere obtener 1](recursos/5_5/bus_solucion.png)\n",
    "\n",
    "Además sólo quiero que detecte los objetos cuya probabilidad sea mayor al 50%.\n",
    "\n",
    "Ten en cuenta que al aplicar el modelo a una imagen devuelve diferentes datos:\n",
    " * Cajas:\n",
    "    * Clase (cls)\n",
    "    * Probabilidad (score)\n",
    "    * Coordenadas de la caja xyxy\n",
    "\n",
    "Para representar la imagen y añadir rectángulos, texto... puedes usar Image, ImageDraw, ImageFont de PIL. Dibujas la imagen con .Draw de (ImageDraw) con .rectangle y .text puedes ir añadiendo texto y rectángulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clases = results[0].names\n",
    "colores = ['cyan','orange','pink','green','yellow','red','blue','white']\n",
    "guia = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,res in enumerate(results):    \n",
    "    boxes = res.boxes  # Boxes object for bounding box outputs\n",
    "    txt = ''\n",
    "    filtrados = []\n",
    "    for j,(cls,prob,coords) in enumerate(zip(boxes.cls,boxes.conf,boxes.xyxy)):\n",
    "        if prob > 0.5:      # probabilidad mayor del 50%            \n",
    "            # datos prediccion\n",
    "            filtrados.append([cls,prob,coords])\n",
    "            txt += 'Recuadro {}--> Clase: {},\\t Score: {},\\t Caja: {}\\n'.format(j, clases[int(cls)], prob, coords)\n",
    "            if int(cls) not in guia.keys(): \n",
    "                print(len(guia.keys()))\n",
    "                guia[int(cls)] = colores[len(guia.keys())]\n",
    "    # imagen\n",
    "    img = Image.open(imgs_arr[i])\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font = ImageFont.truetype(\"usr/share/fonts/truetype/ubuntu/Ubuntu-B.ttf\", size=30)\n",
    "\n",
    "    for i,caso in enumerate(filtrados):\n",
    "        coords = caso[2]\n",
    "        color = guia[int(caso[0])]\n",
    "        draw.rectangle([coords[0], coords[1], coords[2], coords[3]], outline=color, width=5)\n",
    "        draw.rectangle([coords[0], coords[1]-30, coords[0]+2 + 40, coords[1]],fill=\"black\")\n",
    "        draw.rectangle([coords[0]+2, coords[1]-28, coords[0] + 40, coords[1]-2],fill=color)\n",
    "        draw.text((coords[0]+8, coords[1]-32), str(i), fill=\"black\",font=font)\n",
    "\n",
    "    # mostrar resultados\n",
    "    plt.figure(figsize=(13,7))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chuleta atributos\n",
    "\"\"\" for res in results:    \n",
    "    boxes = res.boxes          # Boxes object for bounding box outputs\n",
    "    masks = res.masks          # Masks object for segmentation masks outputs\n",
    "    keypoints = res.keypoints          # Keypoints object for pose outputs\n",
    "    probs = res.probs          # Probs object for classification outputs\n",
    "    obb = res.obb            # Oriented boxes object for OBB outputs\n",
    "    res.show()              # display to screen\n",
    "    res.save(filename=\"result.jpg\")          # save to disk\n",
    "    print(boxes.cls)\n",
    "    print(boxes.conf) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 3\n",
    "YOLOv11 también sirve para segmentación, aplica segmentación a las dos imágenes con las que estamos trabajando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segmentation  \n",
    "model = YOLO('recursos/5_5/yolo/yolo11n-seg.pt')  \n",
    "results = model(imgs_arr)  \n",
    "for res in results:\n",
    "    res.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 4\n",
    "De manera similar, podemos hacer la estimación de pose. Hazlo con las imágenes con las que estamos trabajando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('recursos/5_5/yolo/yolo11n-pose.pt')  \n",
    "results = model(imgs_arr)  \n",
    "for res in results:\n",
    "    res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haz lo que se hace en el siguiente video:\n",
    "\n",
    "https://www.youtube.com/watch?v=_YbEna8UNcU\n",
    "\n",
    "Tienes parte del código en:\n",
    "\n",
    "https://www.albertcoronado.com/2024/11/12/tutorial-yolo-11/\n",
    "\n",
    "Para la parte fine tuning tienes que entrenar el modelo para que distina matrículas de coche, para entrenar el modelo utiliza el dataset que puedes descargar de:\n",
    "\n",
    "https://universe.roboflow.com/parag-parmar-3qpin/car_license_plate-ypwmk/dataset/1\n",
    "\n",
    "NOTA: HE CONSEGUIDO QUE FUNCIONE BIEN CV2 PERO ABRIENDO PRIMERO UNA IMAGEN:\n",
    "```\n",
    "img = cv2.imread('Datos/image3.jpg')\n",
    "cv2.imshow(\"SAPA\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camara\n",
    "model = YOLO(\"recursos/5_5/yolo/yolo11x.pt\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 0.7\n",
    "color = (0, 250, 0)\n",
    "thickness = 2\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model( img, stream=True )\n",
    "\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            confidence = math.ceil((box.conf[0]*100))\n",
    "            \n",
    "            cv2.rectangle(img, ( x1, y1 ), ( x2, y2 ), color, 1)\n",
    "            cv2.putText(img, r.names[ int( box.cls[0] ) ]+\" \"+str(confidence)+\"%\", [ x1+4, y1+25 ], font, fontScale, color, thickness)\n",
    "\n",
    "    cv2.imshow('Webcam', img)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train epochs=20 batch=10 model='yolo11s' data='/home/iabd/Escritorio/clase/iabd/ia/sapa/deep_learning/recursos/datasets/car_license_plate.v1i.yolov11/data.yaml' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predecir\n",
    "!yolo predict model='yolo11s' source='/home/iabd/Escritorio/clase/iabd/ia/sapa/deep_learning/recursos/5_5/matriculas.jpeg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 6\n",
    "Repite el fine tuning del apartado anterior pero ahora en vez de como un comando en la terminal con código de python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rutas\n",
    "model_matriculas = YOLO('yolo11s')\n",
    "data_yaml='/home/iabd/Escritorio/clase/iabd/ia/sapa/deep_learning/recursos/datasets/car_license_plate.v1i.yolov11/data.yaml' \n",
    "\n",
    "# entrenar\n",
    "model_matriculas.train(data = data_yaml,\n",
    "            epochs= 25, \n",
    "            batch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predecir\n",
    "results = model_matriculas.predict('./recursos/5_5/matriculas.jpeg', conf=0.25)\n",
    "for res in results:\n",
    "    res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_matriculas.save('./recursos/5_5/yolo/yolo_matriculas.pt')    # guardar modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 7\n",
    "Vamos a contar los pasajeros de un autobus.\n",
    "\n",
    "Sigue las instrucciones del siguiente video:\n",
    "\n",
    "https://www.youtube.com/watch?v=hTI0Aj__SLE\n",
    "\n",
    "ELIMINA LOS COMENTARIOS QUE HAY EN EL CÓDIGO Y COMENTA EL CÓDIGO CON TUS PROPIAS PALABRAS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.solutions.solutions import BaseSolution\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "class ObjectCounter(BaseSolution):\n",
    "    \"\"\"\n",
    "        Clase para contar los objetos en un video.\n",
    "\n",
    "        Extend: BaseSolution\n",
    "        Atributos:\n",
    "         - in_count (int): Contador de objetos que entran.\n",
    "         - out_count (int): Contador de objetos que salen.\n",
    "         - counted_ids (List[int]): Lista de IDs de objetos contados.\n",
    "         - saved_ids (List[int]): Lista de IDs guardados en un archivo CSV.\n",
    "         - classwise_counts (Dict[str, Dict[str, int]]): Diccionario de conteos, categorizados por clase de objeto.\n",
    "         - region_initialized (bool): Indica si se ha inicializado la región de conteo en la imagen.\n",
    "         - show_in (bool): Controla la visualización del conteo de entrada.\n",
    "         - show_out (bool): Controla la visualización del conteo de salida.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Constructor de la clase.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.in_count = 0    \n",
    "        self.out_count = 0    \n",
    "        self.counted_ids = []    \n",
    "        self.saved_ids = []    \n",
    "        self.classwise_counts = {}     \n",
    "        self.region_initialized = False    \n",
    "\n",
    "        self.show_in = self.CFG.get(\"show_in\", True)\n",
    "        self.show_out = self.CFG.get(\"show_out\", True)\n",
    "\n",
    "    def save_label_to_csv(self, track_id, label, action):\n",
    "        \"\"\" Guarda en un archivo CSV los datos ['track_id', 'label', 'action', 'date', 'time'] \"\"\"\n",
    "        if track_id in self.saved_ids:\n",
    "            return  # Si el ID ya está registrado, se omite\n",
    "\n",
    "        # Obtener la fecha y hora actual\n",
    "        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")  \n",
    "\n",
    "        # Crear el archivo CSV con la fecha en el nombre\n",
    "        filename = f'./recursos/5_5/tracked_objects_{current_date}.csv'\n",
    "\n",
    "        # Comprobar si el archivo ya existe\n",
    "        file_exists = os.path.isfile(filename)\n",
    "\n",
    "        with open(filename, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "            # Escribir la cabecera si el archivo es nuevo\n",
    "            if not file_exists:\n",
    "                writer.writerow(['track_id', 'label', 'action', 'date', 'time'])\n",
    "\n",
    "            # Escribir una nueva línea con los datos\n",
    "            writer.writerow([track_id, label, action, current_time.split()[0], current_time.split()[1]])\n",
    "            self.saved_ids.append(track_id)  # Guardar el ID en la lista de guardados\n",
    "\n",
    "    def count_objects(self, current_centroid, track_id, prev_position, cls):\n",
    "        \"\"\"\n",
    "        Cuenta objetos en función de un área o línea de referencia.\n",
    "\n",
    "        Parámetros:\n",
    "         - current_centroid (Tuple[float, float]): Coordenadas del centroide en el fotograma actual.\n",
    "         - track_id (int): Identificador único del objeto rastreado.\n",
    "         - prev_position (Tuple[float, float]): Coordenadas de la posición en el fotograma anterior (x, y).\n",
    "         - cls (int): Índice de clase del objeto, utilizado para actualizar el conteo por clase.\n",
    "        \"\"\"\n",
    "        if prev_position is None or track_id in self.counted_ids:\n",
    "            return\n",
    "\n",
    "        action = None  \n",
    "\n",
    "        if len(self.region) == 2:  # Región lineal (definida como un segmento de línea)\n",
    "            line = self.LineString(self.region)\n",
    "            if line.intersects(self.LineString([prev_position, current_centroid])):\n",
    "                if abs(self.region[0][0] - self.region[1][0]) < abs(self.region[0][1] - self.region[1][1]):\n",
    "                    if current_centroid[0] > prev_position[0]:  # Movimiento hacia la derecha\n",
    "                        self.in_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"IN\"] += 1\n",
    "                        action = \"IN\"\n",
    "                    else:  # Movimiento hacia la izquierda\n",
    "                        self.out_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"OUT\"] += 1\n",
    "                        action = \"OUT\"\n",
    "                else:\n",
    "                    if current_centroid[1] > prev_position[1]:  # Movimiento hacia abajo\n",
    "                        self.in_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"IN\"] += 1\n",
    "                        action = \"IN\"\n",
    "                    else:  # Movimiento hacia arriba\n",
    "                        self.out_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"OUT\"] += 1\n",
    "                        action = \"OUT\"\n",
    "                self.counted_ids.append(track_id)\n",
    "\n",
    "        elif len(self.region) > 2:  # Región poligonal\n",
    "            polygon = self.Polygon(self.region)\n",
    "            if polygon.contains(self.Point(current_centroid)):\n",
    "                region_width = max([p[0] for p in self.region]) - min([p[0] for p in self.region])\n",
    "                region_height = max([p[1] for p in self.region]) - min([p[1] for p in self.region])\n",
    "\n",
    "                if region_width < region_height:\n",
    "                    if current_centroid[0] > prev_position[0]:  # Movimiento hacia la derecha\n",
    "                        self.in_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"IN\"] += 1\n",
    "                        action = \"IN\"\n",
    "                    else:  # Movimiento hacia la izquierda\n",
    "                        self.out_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"OUT\"] += 1\n",
    "                        action = \"OUT\"\n",
    "                else:\n",
    "                    if current_centroid[1] > prev_position[1]:  # Movimiento hacia abajo\n",
    "                        self.in_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"IN\"] += 1\n",
    "                        action = \"IN\"\n",
    "                    else:  # Movimiento hacia arriba\n",
    "                        self.out_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"OUT\"] += 1\n",
    "                        action = \"OUT\"\n",
    "                self.counted_ids.append(track_id)\n",
    "\n",
    "        # Guardar la etiqueta con la acción realizada\n",
    "        if action:\n",
    "            label = f\"{self.names[cls]} ID: {track_id}\"\n",
    "            self.save_label_to_csv(track_id, label, action)\n",
    "\n",
    "    def store_classwise_counts(self, cls):\n",
    "        \"\"\"Inicializa los conteos por clase si aún no existen.\"\"\"\n",
    "        if self.names[cls] not in self.classwise_counts:\n",
    "            self.classwise_counts[self.names[cls]] = {\"IN\": 0, \"OUT\": 0}\n",
    "\n",
    "    def display_counts(self, im0):\n",
    "        \"\"\"Muestra los conteos de objetos en la imagen de entrada.\"\"\"\n",
    "        labels_dict = {\n",
    "            str.capitalize(key): f\"{'IN ' + str(value['IN']) if self.show_in else ''} \"\n",
    "            f\"{'OUT ' + str(value['OUT']) if self.show_out else ''}\".strip()\n",
    "            for key, value in self.classwise_counts.items()\n",
    "            if value[\"IN\"] != 0 or value[\"OUT\"] != 0\n",
    "        }\n",
    "\n",
    "        if labels_dict:\n",
    "            self.annotator.display_analytics(im0, labels_dict, (104, 31, 17), (255, 255, 255), 10)\n",
    "\n",
    "        for track_id in self.track_ids:\n",
    "            if track_id in self.counted_ids:\n",
    "                in_count = self.in_count\n",
    "                label = f\"ID:{track_id} count at number {in_count}\"\n",
    "                self.annotator.box_label(self.boxes[self.track_ids.index(track_id)], label=label, color=(255, 255, 0))\n",
    "\n",
    "    def count(self, im0):\n",
    "        \"\"\"Procesa los datos de entrada (fotogramas o rastros de objetos) y actualiza los conteos.\"\"\"\n",
    "        if not self.region_initialized:\n",
    "            self.initialize_region()\n",
    "            self.region_initialized = True\n",
    "\n",
    "        self.annotator = Annotator(im0, line_width=self.line_width)\n",
    "        self.extract_tracks(im0)\n",
    "        self.annotator.draw_region(reg_pts=self.region, color=(104, 0, 123), thickness=self.line_width * 2)\n",
    "\n",
    "        for box, track_id, cls in zip(self.boxes, self.track_ids, self.clss):\n",
    "            self.store_tracking_history(track_id, box)\n",
    "            self.store_classwise_counts(cls)\n",
    "\n",
    "            label = f\"{self.names[cls]} ID: {track_id}\"\n",
    "            self.annotator.box_label(box, label=label, color=colors(cls, True))\n",
    "\n",
    "            current_centroid = ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)\n",
    "            prev_position = self.track_history[track_id][-2] if len(self.track_history[track_id]) > 1 else None\n",
    "            self.count_objects(current_centroid, track_id, prev_position, cls)\n",
    "\n",
    "        self.display_counts(im0)\n",
    "        self.display_output(im0)\n",
    "\n",
    "        return im0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de callback del mouse\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE:  # Verificar el movimiento del mouse\n",
    "        point = [x, y]\n",
    "        print(f\"El mouse se movió a: {point}\") \n",
    "\n",
    "# Abrir el archivo de video\n",
    "cap = cv2.VideoCapture('/home/iabd/Escritorio/clase/iabd/ia/sapa/deep_learning/recursos/5_5/1.mp4')\n",
    "\n",
    "# Definir los puntos de la región para el conteo\n",
    "region_points = [(386,103), (458, 499)]\n",
    "\n",
    "# Inicializar el contador de objetos\n",
    "counter = ObjectCounter(\n",
    "    region = region_points,  # Pasar los puntos de la región\n",
    "    model = \"yolo11s.pt\",  \n",
    "    classes = [0],  # clase \"persona\"\n",
    "    show_in = True,  # conteo de entradas\n",
    "    show_out = True,  # conteo de salidas\n",
    "    line_width = 2,  #  grosor de la línea \n",
    ")\n",
    "\n",
    "# Crear ventana y establecer función callback del mouse\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB', RGB)\n",
    "\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    # Leer un fotograma del video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        # Si el video termina, reiniciar desde el principio\n",
    "#        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "#        continue\n",
    "    count += 1\n",
    "    if count % 2 != 0:  # Omitir fotogramas impares\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    # Procesar el fotograma con el contador de objetos\n",
    "    frame = counter.count(frame)\n",
    "\n",
    "    # Mostrar el fotograma\n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):  # Presionar 'q' para salir\n",
    "        break\n",
    "\n",
    "# Liberar el objeto de captura de video y cerrar la ventana de visualización\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 8\n",
    "Adapta el código anterior para que cuente vehículos en el video vehicle-counting.mp4 (tiene que contar por separado coches y camiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.solutions.solutions import BaseSolution\n",
    "from ultralytics.utils.plotting import Annotator, colors\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "class ObjectCounter(BaseSolution):\n",
    "    \"\"\"\n",
    "        Clase para contar los objetos en un video.\n",
    "\n",
    "        Extend: BaseSolution\n",
    "        Atributos:\n",
    "         - in_count (int): Contador de objetos que entran.\n",
    "         - out_count (int): Contador de objetos que salen.\n",
    "         - counted_ids (List[int]): Lista de IDs de objetos contados.\n",
    "         - saved_ids (List[int]): Lista de IDs guardados en un archivo CSV.\n",
    "         - classwise_counts (Dict[str, Dict[str, int]]): Diccionario de conteos, categorizados por clase de objeto.\n",
    "         - region_initialized (bool): Indica si se ha inicializado la región de conteo en la imagen.\n",
    "         - show_in (bool): Controla la visualización del conteo de entrada.\n",
    "         - show_out (bool): Controla la visualización del conteo de salida.\n",
    "         - csv_ruta (str): ruta del csv         ### CAMBIO\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ruta, **kwargs):         ### CAMBIO\n",
    "        \"\"\"Constructor de la clase.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.in_count = 0    \n",
    "        self.out_count = 0    \n",
    "        self.counted_ids = []    \n",
    "        self.saved_ids = []    \n",
    "        self.classwise_counts = {}     \n",
    "        self.region_initialized = False    \n",
    "        self.csv_ruta = ruta         ### CAMBIO\n",
    "\n",
    "        self.show_in = self.CFG.get(\"show_in\", True)\n",
    "        self.show_out = self.CFG.get(\"show_out\", True)\n",
    "\n",
    "    def save_label_to_csv(self, track_id, label, action):\n",
    "        \"\"\" Guarda en un archivo CSV los datos ['track_id', 'label', 'action', 'date', 'time'] \"\"\"\n",
    "        if track_id in self.saved_ids:\n",
    "            return  # Si el ID ya está registrado, se omite\n",
    "\n",
    "        # Obtener la fecha y hora actual\n",
    "        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")  \n",
    "\n",
    "        # Crear el archivo CSV con la fecha en el nombre\n",
    "        filename = self.csv_ruta+current_date+'.csv'    ### CAMBIO\n",
    "\n",
    "        # Comprobar si el archivo ya existe\n",
    "        file_exists = os.path.isfile(filename)\n",
    "\n",
    "        with open(filename, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "            # Escribir la cabecera si el archivo es nuevo\n",
    "            if not file_exists:\n",
    "                writer.writerow(['track_id', 'label', 'action', 'date', 'time'])\n",
    "\n",
    "            # Escribir una nueva línea con los datos\n",
    "            writer.writerow([track_id, label, action, current_time.split()[0], current_time.split()[1]])\n",
    "            self.saved_ids.append(track_id)  # Guardar el ID en la lista de guardados\n",
    "\n",
    "    def count_objects(self, current_centroid, track_id, prev_position, cls):\n",
    "        \"\"\"\n",
    "        Cuenta objetos en función de un área o línea de referencia.\n",
    "\n",
    "        Parámetros:\n",
    "         - current_centroid (Tuple[float, float]): Coordenadas del centroide en el fotograma actual.\n",
    "         - track_id (int): Identificador único del objeto rastreado.\n",
    "         - prev_position (Tuple[float, float]): Coordenadas de la posición en el fotograma anterior (x, y).\n",
    "         - cls (int): Índice de clase del objeto, utilizado para actualizar el conteo por clase.\n",
    "        \"\"\"\n",
    "        if prev_position is None or track_id in self.counted_ids:\n",
    "            return\n",
    "\n",
    "        action = None  \n",
    "\n",
    "        if len(self.region) == 2:  # Región lineal (definida como un segmento de línea)\n",
    "            line = self.LineString(self.region)\n",
    "            if line.intersects(self.LineString([prev_position, current_centroid])):\n",
    "                if abs(self.region[0][0] - self.region[1][0]) < abs(self.region[0][1] - self.region[1][1]):\n",
    "                    if current_centroid[0] > prev_position[0]:  # Movimiento hacia la derecha\n",
    "                        self.in_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"IN\"] += 1\n",
    "                        action = \"IN\"\n",
    "                    else:  # Movimiento hacia la izquierda\n",
    "                        self.out_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"OUT\"] += 1\n",
    "                        action = \"OUT\"\n",
    "                else:\n",
    "                    if current_centroid[1] > prev_position[1]:  # Movimiento hacia abajo\n",
    "                        self.in_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"IN\"] += 1\n",
    "                        action = \"IN\"\n",
    "                    else:  # Movimiento hacia arriba\n",
    "                        self.out_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"OUT\"] += 1\n",
    "                        action = \"OUT\"\n",
    "                self.counted_ids.append(track_id)\n",
    "\n",
    "        elif len(self.region) > 2:  # Región poligonal\n",
    "            polygon = self.Polygon(self.region)\n",
    "            if polygon.contains(self.Point(current_centroid)):\n",
    "                region_width = max([p[0] for p in self.region]) - min([p[0] for p in self.region])\n",
    "                region_height = max([p[1] for p in self.region]) - min([p[1] for p in self.region])\n",
    "\n",
    "                if region_width < region_height:\n",
    "                    if current_centroid[0] > prev_position[0]:  # Movimiento hacia la derecha\n",
    "                        self.in_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"IN\"] += 1\n",
    "                        action = \"IN\"\n",
    "                    else:  # Movimiento hacia la izquierda\n",
    "                        self.out_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"OUT\"] += 1\n",
    "                        action = \"OUT\"\n",
    "                else:\n",
    "                    if current_centroid[1] > prev_position[1]:  # Movimiento hacia abajo\n",
    "                        self.in_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"IN\"] += 1\n",
    "                        action = \"IN\"\n",
    "                    else:  # Movimiento hacia arriba\n",
    "                        self.out_count += 1\n",
    "                        self.classwise_counts[self.names[cls]][\"OUT\"] += 1\n",
    "                        action = \"OUT\"\n",
    "                self.counted_ids.append(track_id)\n",
    "\n",
    "        # Guardar la etiqueta con la acción realizada\n",
    "        if action:\n",
    "            label = f\"{self.names[cls]} ID: {track_id}\"\n",
    "            self.save_label_to_csv(track_id, label, action)\n",
    "\n",
    "    def store_classwise_counts(self, cls):\n",
    "        \"\"\"Inicializa los conteos por clase si aún no existen.\"\"\"\n",
    "        if self.names[cls] not in self.classwise_counts:\n",
    "            self.classwise_counts[self.names[cls]] = {\"IN\": 0, \"OUT\": 0}\n",
    "\n",
    "    def display_counts(self, im0):\n",
    "        \"\"\"Muestra los conteos de objetos en la imagen de entrada.\"\"\"\n",
    "        labels_dict = {\n",
    "            str.capitalize(key): f\"{'IN ' + str(value['IN']) if self.show_in else ''} \"\n",
    "            f\"{'OUT ' + str(value['OUT']) if self.show_out else ''}\".strip()\n",
    "            for key, value in self.classwise_counts.items()\n",
    "            if value[\"IN\"] != 0 or value[\"OUT\"] != 0\n",
    "        }\n",
    "\n",
    "        if labels_dict:\n",
    "            self.annotator.display_analytics(im0, labels_dict, (104, 31, 17), (255, 255, 255), 10)\n",
    "\n",
    "        for track_id in self.track_ids:\n",
    "            if track_id in self.counted_ids:\n",
    "                in_count = self.in_count\n",
    "                label = f\"ID:{track_id} count at number {in_count}\"\n",
    "                self.annotator.box_label(self.boxes[self.track_ids.index(track_id)], label=label, color=(255, 255, 0))\n",
    "\n",
    "    def count(self, im0):\n",
    "        \"\"\"Procesa los datos de entrada (fotogramas o rastros de objetos) y actualiza los conteos.\"\"\"\n",
    "        if not self.region_initialized:\n",
    "            self.initialize_region()\n",
    "            self.region_initialized = True\n",
    "\n",
    "        self.annotator = Annotator(im0, line_width=self.line_width)\n",
    "        self.extract_tracks(im0)\n",
    "        self.annotator.draw_region(reg_pts=self.region, color=(104, 0, 123), thickness=self.line_width * 2)\n",
    "\n",
    "        for box, track_id, cls in zip(self.boxes, self.track_ids, self.clss):\n",
    "            self.store_tracking_history(track_id, box)\n",
    "            self.store_classwise_counts(cls)\n",
    "\n",
    "            label = f\"{self.names[cls]} ID: {track_id}\"\n",
    "            self.annotator.box_label(box, label=label, color=colors(cls, True))\n",
    "\n",
    "            current_centroid = ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)\n",
    "            prev_position = self.track_history[track_id][-2] if len(self.track_history[track_id]) > 1 else None\n",
    "            self.count_objects(current_centroid, track_id, prev_position, cls)\n",
    "\n",
    "        self.display_counts(im0)\n",
    "        self.display_output(im0)\n",
    "\n",
    "        return im0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de callback del mouse\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE:  # Verificar el movimiento del mouse\n",
    "        point = [x, y]\n",
    "        print(f\"El mouse se movió a: {point}\") \n",
    "\n",
    "# Abrir el archivo de video\n",
    "cap = cv2.VideoCapture('./recursos/5_5/vehicle-counting.mp4')   ### CAMBIO\n",
    "\n",
    "# Definir los puntos de la región para el conteo\n",
    "region_points = [(20,280), (1000, 280)]\n",
    "\n",
    "# Inicializar el contador de objetos\n",
    "counter = ObjectCounter(\n",
    "    ruta = './recursos/5_5/tracked_objects_autopista_',\n",
    "    region=region_points,  # Pasar los puntos de la región\n",
    "    model=\"./recursos/5_5/yolo/yolo11s.pt\",  \n",
    "    classes=[2,7],  # Detectar clases 2 car, 7 truk       ### CAMBIO\n",
    "    show_in=True,  # conteo de entradas\n",
    "    show_out=True,  # conteo de salidas\n",
    "    line_width=2,  # grosor de la línea \n",
    ")\n",
    "\n",
    "# Crear ventana y establecer función callback del mouse\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB', RGB)\n",
    "\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    # Leer un fotograma del video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        # Si el video termina, reiniciar desde el principio\n",
    "#        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "#        continue\n",
    "    count += 1\n",
    "    if count % 2 != 0:  # Omitir fotogramas impares\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    # Procesar el fotograma con el contador de objetos\n",
    "    frame = counter.count(frame)\n",
    "\n",
    "    # Mostrar el fotograma\n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):  # Presionar 'q' para salir\n",
    "        break\n",
    "\n",
    "# Liberar el objeto de captura de video y cerrar la ventana de visualización\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 9\n",
    "Adapta el ejercicio anterior para que en vez de coches cuente matrículas usando el modelo que has creado en el ejercicio 6. \n",
    "\n",
    "Si el video del apartado anterior no te sirve porque no se ven bien las matrículas crea un video con la IA generativa (si el video creado es demasiado corto junta varios videos en uno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####  solo es necesario editar el segundo fichero\n",
    "\n",
    "# Definir la función de callback del mouse\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE:  # Verificar el movimiento del mouse\n",
    "        point = [x, y]\n",
    "        print(f\"El mouse se movió a: {point}\") \n",
    "\n",
    "# Abrir el archivo de video\n",
    "cap = cv2.VideoCapture('./recursos/5_5/prueba.mp4')   ### CAMBIO\n",
    "\n",
    "# Definir los puntos de la región para el conteo\n",
    "region_points = [(400,20), (800, 460)]\n",
    "\n",
    "# Inicializar el contador de objetos\n",
    "counter = ObjectCounter(\n",
    "    ruta = './recursos/5_5/tracked_objects_matriculas_',        ### CAMBIO\n",
    "    region=region_points,  # Pasar los puntos de la región\n",
    "    model='./recursos/5_5/yolo/yolo_matriculas.pt',  \n",
    "    classes=[0],  # Detectar clases \n",
    "    show_in=True,  # conteo de entradas\n",
    "    show_out=True,  # conteo de salidas\n",
    "    line_width=2,  # grosor de la línea \n",
    ")\n",
    "\n",
    "# Crear ventana y establecer función callback del mouse\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB', RGB)\n",
    "\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    # Leer un fotograma del video\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        # Si el video termina, reiniciar desde el principio\n",
    "#        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "#        continue\n",
    "    count += 1\n",
    "    if count % 2 != 0:  # Omitir fotogramas impares\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, (1020, 500))\n",
    "\n",
    "    # Procesar el fotograma con el contador de objetos\n",
    "    frame = counter.count(frame)\n",
    "\n",
    "    # Mostrar el fotograma\n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):  # Presionar 'q' para salir\n",
    "        break\n",
    "\n",
    "# Liberar el objeto de captura de video y cerrar la ventana de visualización\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 10\n",
    "Vamos a hacer fine tuning sobre el modelo para segmentación SAM-2.\n",
    "\n",
    "Puedes sacar información de la siguiente página:\n",
    "\n",
    "https://blog.roboflow.com/fine-tune-sam-2-1/\n",
    "\n",
    "A la hora de conseguir el dataset, descargalo para no tener problemas con la API-KEY de Roboflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   901  100   901    0     0   3090      0 --:--:-- --:--:-- --:--:--  3096\n",
      "100 4978k  100 4978k    0     0  2456k      0  0:00:02  0:00:02 --:--:-- 5458k\n",
      "Archive:  roboflow.zip\n",
      "replace README.dataset.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "# obtener dataset\n",
    "!curl -L \"https://universe.roboflow.com/ds/p1fYx5Kd9a?key=NAS33NVLPw\" > roboflow.zip; unzip roboflow.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key=\"W8Wh3vwPre13GJ9ArQue\")\n",
    "project = rf.workspace(\"brad-dwyer\").project(\"car-parts-pgo19\")\n",
    "version = project.version(6)\n",
    "dataset = version.download(\"sam2\")\n",
    "\n",
    "# rename dataset.location to \"data\"\n",
    "os.rename(dataset.location, \"/home/iabd/Escritorio/IABD/IA/SAPA/Redes Neuronales/ej10Sam/data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descargar sam2 (clonar repo)\n",
    "!git clone https://github.com/facebookresearch/sam2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenar sam2\n",
    "!wget -O ./sam2/sam2/configs/train.yaml 'https://drive.usercontent.google.com/download?id=11cmbxPPsYqFyWq87tmLgBAQ6OZgEhPG3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate to the sam2 directory and install the model as well as supervision\n",
    "%cd ./sam2/\n",
    "!pip install -e .[dev]\n",
    "!pip install supervision -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the checkpoints\n",
    "!cd ./checkpoints && ./download_ckpts.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparar dataset\n",
    "import re\n",
    "\n",
    "FOLDER = \"../train\"\n",
    "for filename in os.listdir(FOLDER):\n",
    "    # Replace all except last dot with underscore\n",
    "    new_filename = filename.replace(\".\", \"_\", filename.count(\".\") - 1)\n",
    "    if not re.search(r\"_\\d+\\.\\w+$\", new_filename):\n",
    "        # Add an int to the end of base name\n",
    "        new_filename = new_filename.replace(\".\", \"_1.\")\n",
    "    os.rename(os.path.join(FOLDER, filename), os.path.join(FOLDER, new_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/home/iabd/Escritorio/clase/iabd/ia/sapa/deep_learning/Ej_sam2/training/train.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# estamos en la carpeta Ej_sam2/sam2\n",
    "!python training/train.py -c '.sam2/sam2/configs/train.yaml' --use-cluster 0 --num-gpus 1\n",
    "\n",
    "# model weights saved in: /sam2/sam2_logs/configs/train.yaml/checkpoints/checkpoint.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_5Ejercicios.ipynb  README.roboflow.txt  sam2\ttrain\n",
      "README.dataset.txt   roboflow.zip\t  test\tvalid\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ya esta instalado mas arriba\n",
    "# !pip install supervision    \n",
    "\n",
    "import torch\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "import supervision as sv\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# use bfloat16 for inference\n",
    "# from Meta notebook\n",
    "torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "\ttorch.backends.cuda.matmul.allow_tf32 = True\n",
    "\ttorch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "checkpoint = \"/sam2_logs/configs/train.yaml/checkpoints/checkpoint.pt\"\n",
    "model_cfg = \"configs/sam2.1/sam2.1_hiera_b+.yaml\"\n",
    "sam2 = build_sam2(model_cfg, checkpoint, device=\"cuda\")\n",
    "mask_generator = SAM2AutomaticMaskGenerator(sam2)\n",
    "\n",
    "checkpoint_base = \"/sam2/sam2/checkpoints/sam2.1_hiera_base_plus.pt\"\n",
    "model_cfg_base = \"configs/sam2.1/sam2.1_hiera_b+.yaml\"\n",
    "sam2_base = build_sam2(model_cfg_base, checkpoint_base, device=\"cuda\")\n",
    "mask_generator_base = SAM2AutomaticMaskGenerator(sam2_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validation_set = os.listdir(\"/content/data/valid\")\n",
    "\n",
    "# choose random with .json extension\n",
    "image = random.choice([img for img in validation_set if img.endswith(\".jpg\")])\n",
    "image = os.path.join(\"/content/data/valid\", image)\n",
    "opened_image = np.array(Image.open(image).convert(\"RGB\"))\n",
    "result = mask_generator.generate(opened_image)\n",
    "\n",
    "detections = sv.Detections.from_sam(sam_result=result)\n",
    "\n",
    "mask_annotator = sv.MaskAnnotator(color_lookup = sv.ColorLookup.INDEX)\n",
    "annotated_image = opened_image.copy()\n",
    "annotated_image = mask_annotator.annotate(annotated_image, detections=detections)\n",
    "\n",
    "base_annotator = sv.MaskAnnotator(color_lookup = sv.ColorLookup.INDEX)\n",
    "\n",
    "base_result = mask_generator_base.generate(opened_image)\n",
    "base_detections = sv.Detections.from_sam(sam_result=base_result)\n",
    "base_annotated_image = opened_image.copy()\n",
    "base_annotated_image = base_annotator.annotate(base_annotated_image, detections=base_detections)\n",
    "\n",
    "sv.plot_images_grid(images=[annotated_image, base_annotated_image], grid_size=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 11 (OPCIONAL)\n",
    "Haz fine tuning con sam2 o yolo11 para segmentación con otro dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 12 (OPCIONAL)\n",
    "En el siguiente enlace encontraras diferentes modelos y trabajos sobre la visión por computación, prueba alguno de ellos (algunos que no funcionan porque las librerías se han actualizado y tienes que adaptarlos, otros son recientes y no deberías tener problemas).\n",
    "\n",
    "https://github.com/roboflow/notebooks\n",
    "\n",
    "ELIMINA LOS COMENTARIOS QUE HAY EN EL CÓDIGO Y COMENTA EL CÓDIGO CON TUS PROPIAS PALABRAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "14_deep_computer_vision_with_cnns.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "iabd_3_10_SAM2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0401482a18a94f22b95d5321bfa6f414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c08c78c0d484eed9638ad2b757ab584": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2839afc6cb6d4a50b0bdad1fcb7f39d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eefd1a01ef1c46e09ffbd97ad25377cf",
       "IPY_MODEL_d142189db76a4681a22f38ae252e4ebc",
       "IPY_MODEL_d441368305704ab9a3bdbe762ab340a4"
      ],
      "layout": "IPY_MODEL_1c08c78c0d484eed9638ad2b757ab584"
     }
    },
    "54a90429726b4d848358cafae87ad893": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57cbb645792f45adbfab9b29aa708809": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f0660be3bf44dd48fd42cd52a507e32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b681dc2200ad4ee397a46602e8f4f654": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d142189db76a4681a22f38ae252e4ebc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54a90429726b4d848358cafae87ad893",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0401482a18a94f22b95d5321bfa6f414",
      "value": 5
     }
    },
    "d441368305704ab9a3bdbe762ab340a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8ef3c06db574e3f88dc9a8c0bcd22ab",
      "placeholder": "​",
      "style": "IPY_MODEL_8f0660be3bf44dd48fd42cd52a507e32",
      "value": " 5/5 [00:10&lt;00:00,  2.12s/ file]"
     }
    },
    "eefd1a01ef1c46e09ffbd97ad25377cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b681dc2200ad4ee397a46602e8f4f654",
      "placeholder": "​",
      "style": "IPY_MODEL_57cbb645792f45adbfab9b29aa708809",
      "value": "Dl Completed...: 100%"
     }
    },
    "f8ef3c06db574e3f88dc9a8c0bcd22ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
