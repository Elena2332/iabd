{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# import tensorflow_hub as hub\n",
    "# from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea tu propia CNN desde el principio e intenta conseguir la mayor exactitud posible con MNIST (por ejemplo 99% en el conjunto de prueba).\n",
    "\n",
    "En vez de crear un conjunto de validación en el fit indica que porcentaje (10%) vas a usar para el conjunto de validación (validation_split)\n",
    "\n",
    "Por ejemplo:\n",
    "* 2 capas convolucionales (32 filtros)\n",
    "* 1 capa maxpool\n",
    "* 2 capas convolucionales (64 filtros)\n",
    "* 1 capa maxpool\n",
    "* 1 capa flatten\n",
    "* 1 capa dropout\n",
    "* 1 capa densa oculta\n",
    "* 1 capa dropout\n",
    "* 1 capa densa de salida\n",
    "\n",
    "Usá como función de pérdida categorical_crossentropy.\n",
    "\n",
    "Ten en cuenta que:\n",
    "* sparse_categorical_crossentropy: se usa cuando las etiquetas de las clases están representadas como enteros (codificación entera), por ejemplo: 0, 1, 2, 3, ... para n clasess\n",
    "* categorical_crossentropy: se usa cuando las etiquetas están representadas en formato one-hot encoded.\n",
    "\n",
    "Tal y com tenemos los datos podemos usar directamente sparse_categorical_crossentropy, para poder aplicar categorical_crossentropy hay que hacer una transformación en y (to_categorical).\n",
    "\n",
    "Haz una predicción y muestra la imagen con la etiqueta real y la predicha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tdKYb9PpK0B",
    "outputId": "37baf840-d76d-4d94-f692-524eef47a041"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtener datos\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# print(x_train.shape)\n",
    "# normalizar\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)  # (batch_size, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# ver imagenes\n",
    "fig,ax = plt.subplots(1,5, figsize=(10,6))\n",
    "ax = ax.flatten()\n",
    "for i in range(5):\n",
    "    ax[i].set_title(y_train[i])\n",
    "    ax[i].imshow(x_train[i])\n",
    "    ax[i].axis(\"off\") \n",
    "plt.subplots_adjust(wspace=0.25, hspace=0.15)   # ajusta los margenes para separar las imágenes \n",
    "plt.show()\n",
    "len(x_train) , len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear capas\n",
    "tf.random.set_seed(42)\n",
    "DefaultConv2D = partial(tf.keras.layers.Conv2D, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "    DefaultConv2D(filters=32),\n",
    "    DefaultConv2D(filters=32),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    DefaultConv2D(filters=64),\n",
    "    DefaultConv2D(filters=64),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8382 - loss: 0.5082 - val_accuracy: 0.9848 - val_loss: 0.0509\n",
      "Epoch 2/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9689 - loss: 0.1063 - val_accuracy: 0.9877 - val_loss: 0.0433\n",
      "Epoch 3/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9771 - loss: 0.0769 - val_accuracy: 0.9898 - val_loss: 0.0318\n",
      "Epoch 4/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9821 - loss: 0.0628 - val_accuracy: 0.9908 - val_loss: 0.0361\n",
      "Epoch 5/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9842 - loss: 0.0571 - val_accuracy: 0.9905 - val_loss: 0.0340\n",
      "Epoch 6/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9855 - loss: 0.0507 - val_accuracy: 0.9932 - val_loss: 0.0313\n",
      "Epoch 7/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9868 - loss: 0.0460 - val_accuracy: 0.9922 - val_loss: 0.0302\n",
      "Epoch 8/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9879 - loss: 0.0417 - val_accuracy: 0.9922 - val_loss: 0.0305\n",
      "Epoch 9/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9890 - loss: 0.0398 - val_accuracy: 0.9917 - val_loss: 0.0360\n",
      "Epoch 10/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9898 - loss: 0.0345 - val_accuracy: 0.9922 - val_loss: 0.0306\n",
      "Epoch 11/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9900 - loss: 0.0341 - val_accuracy: 0.9920 - val_loss: 0.0315\n",
      "Epoch 12/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9895 - loss: 0.0328 - val_accuracy: 0.9935 - val_loss: 0.0287\n",
      "Epoch 13/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 998us/step - accuracy: 0.9912 - loss: 0.0304 - val_accuracy: 0.9937 - val_loss: 0.0290\n",
      "Epoch 14/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 989us/step - accuracy: 0.9913 - loss: 0.0287 - val_accuracy: 0.9942 - val_loss: 0.0232\n",
      "Epoch 15/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9908 - loss: 0.0326 - val_accuracy: 0.9945 - val_loss: 0.0263\n",
      "Epoch 16/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9921 - loss: 0.0264 - val_accuracy: 0.9935 - val_loss: 0.0302\n",
      "Epoch 17/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9920 - loss: 0.0262 - val_accuracy: 0.9925 - val_loss: 0.0359\n",
      "Epoch 18/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9916 - loss: 0.0264 - val_accuracy: 0.9937 - val_loss: 0.0273\n",
      "Epoch 19/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9925 - loss: 0.0269 - val_accuracy: 0.9940 - val_loss: 0.0286\n",
      "Epoch 20/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9932 - loss: 0.0233 - val_accuracy: 0.9945 - val_loss: 0.0298\n",
      "Epoch 21/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9928 - loss: 0.0219 - val_accuracy: 0.9935 - val_loss: 0.0371\n",
      "Epoch 22/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 979us/step - accuracy: 0.9933 - loss: 0.0228 - val_accuracy: 0.9928 - val_loss: 0.0382\n",
      "Epoch 23/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9924 - loss: 0.0248 - val_accuracy: 0.9935 - val_loss: 0.0352\n",
      "Epoch 24/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 990us/step - accuracy: 0.9929 - loss: 0.0239 - val_accuracy: 0.9928 - val_loss: 0.0306\n",
      "Epoch 25/25\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9925 - loss: 0.0233 - val_accuracy: 0.9932 - val_loss: 0.0362\n"
     ]
    }
   ],
   "source": [
    "# compilar\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
    "\n",
    "# entrenar\n",
    "hist = model.fit(x_train, y_train, epochs=25, validation_split=0.1)   # 10% validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predecir\n",
    "y_pred = model.predict(x_test[3].reshape(1, 28, 28, 1))\n",
    "plt.imshow(x_test[3])\n",
    "plt.title('Prediccion: '+str(np.argmax(y_pred))+'      Sol: '+str(y_test[3]))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haz unas fotos con tu movil (a objetos) y usando alguno de los modelos que existen (por ejemplo ResNet101V2). Tendrás de adecuar el tamaño de las fotos antes de intentar predecir que es lo que has fotografiado.\n",
    "\n",
    "Tendrás que investigar como añadir cargar tus images, un buen sitio por donde empezar es por la documentación de Keras para ResNEt101V2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset food101 es un conjunto de datos consta de 101 categorías de alimentos, con 101000 imágenes. Para cada clase, se proporcionan 250 imágenes de prueba revisadas manualmente, así como 750 imágenes de entrenamiento. A propósito, las imágenes de entrenamiento no se limpiaron y, por lo tanto, aún contienen cierta cantidad de ruido. Esto viene principalmente en forma de colores intensos y, a veces, etiquetas incorrectas. Todas las imágenes se redimensionaron para tener una longitud lateral máxima de 512 píxeles.\n",
    "* Carga el conjunto de imagenes: entrenamiento, validación (coge la mitad de los datos de prueba) y prueba (coge la otra mitad de los datos de prueba)\n",
    "* Explora los datos: dimensiones, número de elementos, dibuja algunas imagenes con sus etiquetas...\n",
    "* Prepara los datos: añade más elementos al conjunto de entrenamiento (rotando, trasladando... las imagenes acutales), cambia el tamaño para que sea adecuado para el modelo, normaliza...\n",
    "* Entrena un modelo para estos datos usando algunas de las redes ya existentes (por ejemplo: MobileNetV2): coge todo menos la última capa y añade una capa globalaveragepooling y la capa dense de salida. En este caso utiliza como función de pérdida sparse_categorical_crossentropy\n",
    "* Busca una imagen de comida en Internet y haz una predicción\n",
    "\n",
    "Por defecto tensorflow busca y descarga los dato en:\n",
    "* Linux/Mac: ~/tensorflow_datasets/\n",
    "* Windows: C:\\Users\\<usuario>\\tensorflow_datasets\\\n",
    "\n",
    "Los datos puedes copiarlo de mi disco duro o descarlos, pero son 5.12GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repite el ejercicio pero para otros datos (tienes conjuntos de datos en https://www.tensorflow.org/datasets/catalog/overview?hl=es-419 en el apartado image classificación, por ejemplo puedes usar stanford_dogs) y utilizando otra de las redes conocidas que no se haya utilizado todavía.\n",
    "Para cargar los datos en este caso vas a descargar las imagnes a tu ordenador y cargarlos desde ahi (descargar la carpeta al ordenador y luego cargarlo desde la carpeta con python (mage_dataset_from_director)):\n",
    "\n",
    "* Carga el conjunto de imagenes (entrenamiento, validación y pruebas)\n",
    "* Explora los datos: dimensiones, número de elementos, dibuja algunas imagenes con sus etiquetas...\n",
    "* Prepara los datos: añadir más elementos al conjunto de entrenamiento (rotando, trasladando... las imagenes acutales), cambiar el tamaño para que sea adecuado para el modelo, normalizar...\n",
    "* Entrena un modelo para estos datos usando algunas de las redes ya existentes (por ejemplo: MobileNetV2)\n",
    "* Busa una imagen en Internet y haz una predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigue el tutorial de TensorFlow Style Transfer (https://homl.info/styletuto) hasta definir representaciones de contenido y estilo (hay que hacer sólo los primeros puntos, hasta el punto  Transferencia de estilo rápido usando TF-Hub (incluido)).\n",
    "\n",
    "Haz algo parecido no igual (por lo menos cambia de imagenes).\n",
    "\n",
    "Además tienes que poner comentarios para explicar con tus palabras lo que estas haciendo.\n",
    "\n",
    "Realmente lo que esta haciendo es aplicar una capas convolucionales a una imagen, donde los filtros se han sacado de otra imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un modelo sencillo que aplique un filtro personalizado a una imagen de contenido mediante una capa convolucional es un buen ejercicio para entender cómo funcionan las convoluciones en el procesamiento de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga una imagen desde archivo preparala para se procesada por la red:\n",
    "* Cargar la imagen (tf.keras.preprocessing.image.load_im)\n",
    "* Convertir la imagen a un tensor de NumPy y redimensionarla:\n",
    "    * tf.keras.preprocessing.image.img_to_array\n",
    "    * tf.image.resize\n",
    "* Añadir una dimensión de batch al tensor de la imagen (np.expand_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define un filtro personalizado para aplicar a la imagen. Los filtros son matrices pequeñas que modifican los píxeles de la imagen al aplicar la convolución.\n",
    "\n",
    "Por ejemplo aquí tienes un filtro de bordes:\n",
    "\n",
    "```python\n",
    "filtro = np.array([\n",
    "    [[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]],\n",
    "    [[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]],\n",
    "    [[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]\n",
    "], dtype=np.float32)\n",
    "```\n",
    "El filtro debe tener forma (altura, anchura, canales_entrada, canales_salida) (usa reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un modelo secuencial en Keras con una única capa convolucional que utilice tu filtro personalizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiza el resultado (muestra la imagen original y la imagen con el filtro y pon un título a cada imagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 7\n",
    "Repite el ejercicio anterior con diferentes modelos y filtros:\n",
    "* Prueba otro filtro (mostrar imagen original e imagen con filtro)\n",
    "* Prueba con tres filtros a la vez (mostrar la imagen resultante de cada filtro)\n",
    "* Prueba con tres filtros y dos capas convolucionales (mostrar imagen original e imagne con filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "14_deep_computer_vision_with_cnns.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "iabd_3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0401482a18a94f22b95d5321bfa6f414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c08c78c0d484eed9638ad2b757ab584": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2839afc6cb6d4a50b0bdad1fcb7f39d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eefd1a01ef1c46e09ffbd97ad25377cf",
       "IPY_MODEL_d142189db76a4681a22f38ae252e4ebc",
       "IPY_MODEL_d441368305704ab9a3bdbe762ab340a4"
      ],
      "layout": "IPY_MODEL_1c08c78c0d484eed9638ad2b757ab584"
     }
    },
    "54a90429726b4d848358cafae87ad893": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57cbb645792f45adbfab9b29aa708809": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f0660be3bf44dd48fd42cd52a507e32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b681dc2200ad4ee397a46602e8f4f654": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d142189db76a4681a22f38ae252e4ebc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54a90429726b4d848358cafae87ad893",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0401482a18a94f22b95d5321bfa6f414",
      "value": 5
     }
    },
    "d441368305704ab9a3bdbe762ab340a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8ef3c06db574e3f88dc9a8c0bcd22ab",
      "placeholder": "​",
      "style": "IPY_MODEL_8f0660be3bf44dd48fd42cd52a507e32",
      "value": " 5/5 [00:10&lt;00:00,  2.12s/ file]"
     }
    },
    "eefd1a01ef1c46e09ffbd97ad25377cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b681dc2200ad4ee397a46602e8f4f654",
      "placeholder": "​",
      "style": "IPY_MODEL_57cbb645792f45adbfab9b29aa708809",
      "value": "Dl Completed...: 100%"
     }
    },
    "f8ef3c06db574e3f88dc9a8c0bcd22ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
