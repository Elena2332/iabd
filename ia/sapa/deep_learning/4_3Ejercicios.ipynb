{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuántas neuronas hacen falta en la capa de salida para clasificar emails entre correo no deseado y correo deseado? \n",
    " - 1\n",
    "\n",
    "¿Qué función de activación deberías usar en la capa de salida? \n",
    " - Sigmoide\n",
    "\n",
    "Si, en cambio, quieres enfrentarte a MNIST, ¿cuántas neuronas necesitas en la capa de salida y qué función de activación deberías usar? \n",
    " - 10 neuronas (1 neurona por clase), funcion de activacion: Softmax\n",
    "\n",
    "¿Y si quieres que la red prediga los precios de la vivienda en California?\n",
    " - 1 neurona, funcion de activacion: Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrena un red neuronal profunda con el conjunto de datos MNIST (puedes cargarlo con tf. keras. datasets.minst.load_data()). Intenta conseguir la mejor pruebas en el conjunto de validación  ajustando los hiperparámetros de modo manual. Prueba a buscar una buena tasa de aprendizaje y utiliza la detención temprana (mínimo hay que conseguir un 97%).\n",
    "\n",
    "Pasos a seguir: \n",
    "+ Entrena varios modelos con distintas tasas de aprendizaje\n",
    "+ Guarda cada modelo en un fichero\n",
    "+ Carga cada modelo y evalúalo en el conjunto de cargas y quedate con programación con el mejor (bucle que se quede con el mejor), mostrando la tasa de aprendizaje y la exactitud del mejor modelo.\n",
    "\n",
    "Si no obtienes más de un 97% vuelve a empezar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtener, separar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
    "\n",
    "#Dividimos los datos completos de entrenamiento en datos de entrenamiento y validación\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenar varios modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 15:01:47.777066: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# todos los modelos tendran 1 entrada, 2 ocultas y 10 salidas(1 salida por clase)\n",
    "modelos = []\n",
    "for i in range(3):\n",
    "    # Se crea el modelo con la capa de normalización y 4 capas densas (fully connected) con 50 neuronas cada una y función de activación ReLU (Rectified Linear Unit) y una capa de salida con una neurona y sin función de activación\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=X_train.shape[1:]),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(124, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    modelos.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8.9780 - sparse_categorical_accuracy: 0.1254 - val_loss: 6.6824 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 2/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.8600 - sparse_categorical_accuracy: 0.0955 - val_loss: 6.5732 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 3/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.5716 - sparse_categorical_accuracy: 0.0962 - val_loss: 3.8081 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 4/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.9263 - sparse_categorical_accuracy: 0.0985 - val_loss: 3.9243 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 5/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.9274 - sparse_categorical_accuracy: 0.0973 - val_loss: 3.7734 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 6/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.7796 - sparse_categorical_accuracy: 0.0999 - val_loss: 3.7733 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 7/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.7832 - sparse_categorical_accuracy: 0.0976 - val_loss: 3.7733 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 8/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.7693 - sparse_categorical_accuracy: 0.0983 - val_loss: 3.7732 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 9/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.8035 - sparse_categorical_accuracy: 0.0958 - val_loss: 3.7731 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 10/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.8279 - sparse_categorical_accuracy: 0.0994 - val_loss: 3.7724 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 11/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3.8024 - sparse_categorical_accuracy: 0.0981 - val_loss: 3.7708 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 12/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3.7855 - sparse_categorical_accuracy: 0.0963 - val_loss: 3.7757 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 13/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 3.8166 - sparse_categorical_accuracy: 0.0977 - val_loss: 3.8013 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 14/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.9078 - sparse_categorical_accuracy: 0.0959 - val_loss: 3.7593 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 15/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.8156 - sparse_categorical_accuracy: 0.0984 - val_loss: 3.7494 - val_sparse_categorical_accuracy: 0.0988\n",
      "Epoch 16/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.8392 - sparse_categorical_accuracy: 0.1003 - val_loss: 3.7450 - val_sparse_categorical_accuracy: 0.0980\n",
      "Epoch 17/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.8349 - sparse_categorical_accuracy: 0.0979 - val_loss: 3.7081 - val_sparse_categorical_accuracy: 0.0980\n",
      "Epoch 18/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.7215 - sparse_categorical_accuracy: 0.1006 - val_loss: 3.7035 - val_sparse_categorical_accuracy: 0.0980\n",
      "Epoch 19/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.7822 - sparse_categorical_accuracy: 0.0989 - val_loss: 3.7250 - val_sparse_categorical_accuracy: 0.0980\n",
      "Epoch 20/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 3.7655 - sparse_categorical_accuracy: 0.0979 - val_loss: 3.7482 - val_sparse_categorical_accuracy: 0.0980\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7.3679 - sparse_categorical_accuracy: 0.1337 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 2/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2651 - sparse_categorical_accuracy: 0.1142 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 3/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2026 - sparse_categorical_accuracy: 0.1136 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 4/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2521 - sparse_categorical_accuracy: 0.1131 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 5/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2727 - sparse_categorical_accuracy: 0.1129 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 6/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2583 - sparse_categorical_accuracy: 0.1116 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 7/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2914 - sparse_categorical_accuracy: 0.1112 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 8/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2522 - sparse_categorical_accuracy: 0.1140 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 9/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3135 - sparse_categorical_accuracy: 0.1123 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 10/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2647 - sparse_categorical_accuracy: 0.1127 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 11/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2894 - sparse_categorical_accuracy: 0.1148 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 12/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2620 - sparse_categorical_accuracy: 0.1130 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 13/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2647 - sparse_categorical_accuracy: 0.1127 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 14/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2885 - sparse_categorical_accuracy: 0.1131 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 15/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3107 - sparse_categorical_accuracy: 0.1145 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 16/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2774 - sparse_categorical_accuracy: 0.1133 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 17/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3261 - sparse_categorical_accuracy: 0.1135 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 18/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2682 - sparse_categorical_accuracy: 0.1118 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 19/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2796 - sparse_categorical_accuracy: 0.1128 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "Epoch 20/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3201 - sparse_categorical_accuracy: 0.1125 - val_loss: 5.1902 - val_sparse_categorical_accuracy: 0.1060\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.8528 - sparse_categorical_accuracy: 0.1255 - val_loss: 8.2226 - val_sparse_categorical_accuracy: 0.1628\n",
      "Epoch 2/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8.1872 - sparse_categorical_accuracy: 0.1456 - val_loss: 9.5985 - val_sparse_categorical_accuracy: 0.1296\n",
      "Epoch 3/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.5922 - sparse_categorical_accuracy: 0.1204 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 4/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.5753 - sparse_categorical_accuracy: 0.1194 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 5/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.6091 - sparse_categorical_accuracy: 0.1164 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 6/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.5802 - sparse_categorical_accuracy: 0.1161 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 7/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.6214 - sparse_categorical_accuracy: 0.1156 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 8/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.5477 - sparse_categorical_accuracy: 0.1127 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 9/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.5817 - sparse_categorical_accuracy: 0.1148 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 10/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.6103 - sparse_categorical_accuracy: 0.1139 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 11/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.5877 - sparse_categorical_accuracy: 0.1175 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 12/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.5704 - sparse_categorical_accuracy: 0.1164 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 13/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.6110 - sparse_categorical_accuracy: 0.1150 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 14/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.5964 - sparse_categorical_accuracy: 0.1182 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 15/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.6169 - sparse_categorical_accuracy: 0.1150 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 16/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.5584 - sparse_categorical_accuracy: 0.1163 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 17/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.6112 - sparse_categorical_accuracy: 0.1157 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 18/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.6112 - sparse_categorical_accuracy: 0.1164 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 19/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.6097 - sparse_categorical_accuracy: 0.1152 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "Epoch 20/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 9.6043 - sparse_categorical_accuracy: 0.1192 - val_loss: 9.5976 - val_sparse_categorical_accuracy: 0.1258\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "historys = []\n",
    "lr = 0.0001\n",
    "for mod in modelos:\n",
    "    # Se compila el modelo con el optimizador SGD  \n",
    "    mod.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=lr),   # asignar tasa de aprendizaje tasa entre 0.001 y 0.0001\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy])\n",
    "    lr += 0.0004\n",
    "    # entrenar\n",
    "    hist = mod.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "    historys.append(hist)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Modelo_0: {'verbose': 'auto', 'epochs': 20, 'steps': 1719}\n",
      " Modelo_1: {'verbose': 'auto', 'epochs': 20, 'steps': 1719}\n",
      " Modelo_2: {'verbose': 'auto', 'epochs': 20, 'steps': 1719}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(historys)):\n",
    "    # mostramos el historial de entrenamiento \n",
    "    print(' Modelo_{}: {}'.format(i,historys[i].params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar en diferentes ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SparseCategoricalAccuracy.get_config() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./recursos/modelos\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(modelos)):\n\u001b[0;32m----> 6\u001b[0m     modelos[i]\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./recursos/modelos/my_keras_model_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:372\u001b[0m, in \u001b[0;36m_get_class_or_fn_config\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# All classes:\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_config\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 372\u001b[0m     config \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mget_config()\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    375\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `get_config()` method of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should return \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    376\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma dict. It returned: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: SparseCategoricalAccuracy.get_config() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./recursos/modelos'):\n",
    "    if not os.path.exists('./recursos'):\n",
    "        os.mkdir('./recursos')\n",
    "    os.mkdir('./recursos/modelos')\n",
    "for i in range(len(modelos)):\n",
    "    modelos[i].save(\"./recursos/modelos/my_keras_model_{}.keras\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar y evaluar con bucle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# evaluar\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificación de Imágenes de Dígitos Escritos a Mano:\n",
    "\n",
    "* Objetivo: Entrenar una red neuronal para clasificar imágenes de dígitos escritos a mano utilizando el conjunto de datos SVHN (Street View House Numbers).\n",
    "\n",
    "* Tareas: \n",
    "    * Cargar el conjunto de datos, dividir los datos (train, valid y test), explorar los datos representando alguna imagen con su etiqueta y muestra los valores (únicos) de y (en el entrenamiento, en validación y en pruebas), preparar los datos (d normalizar dividiendo entre 255.0 e igual hay que hacer algo más), construir, compilar y entrenar una red neuronal. \n",
    "\n",
    "    * Utilizar detección temprana\n",
    "\n",
    "    * Hacer una gráfica de como evoluciona accuracy y val_accuracy durante el entrenamiento\n",
    "\n",
    "    * Si es necesario ajustar el modelo para lograr una mayor precisión.\n",
    "\n",
    "    * Evalúar el modelo en el conjunto de test y hacer alguna predicción (representa alguna imagen con su etiqueta real y la predicha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_svhn_data(url):\n",
    "    path = tf.keras.utils.get_file(\"svhn.mat\", url)\n",
    "    data = loadmat(path)\n",
    "    return np.transpose(data[\"X\"], (3, 0, 1, 2)), data[\"y\"].flatten()\n",
    "\n",
    "# Cargar datos\n",
    "train_url = \"http://ufldl.stanford.edu/housenumbers/train_32x32.mat\"\n",
    "test_url = \"http://ufldl.stanford.edu/housenumbers/test_32x32.mat\"\n",
    "X_train_full, y_train_full = load_svhn_data(train_url)\n",
    "X_test, y_test = load_svhn_data(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicción del consumo de energía:\n",
    "\n",
    "* Objetivo: Construir una red neuronal para predecir el consumo de energía de edificios a partir de características como la temperatura, humedad, y tiempo del conjunto de datos Energy Efficiency de UCI Machine Learning Repository\n",
    "\n",
    "* Tareas: \n",
    "    * Cargar el conjunto de datos, dividir los datos (train, valid y test), explorar los datos, preparar los datos (normalizar con una capa de normalización), construir un modelo de regresión, compilar y entrenar una red neuronal. \n",
    "    \n",
    "    * Usa X1-X8 para la X e Y1-Y2 para la y\n",
    "\n",
    "    * Ajusta el modelo hasta encontrar un error absoluto medio aceptable\n",
    "\n",
    "    * Haz una gráfica de como evoluciona el error absoluto medio y error absoluto medio del conjunto de validación durante el entrenamiento\n",
    "\n",
    "    * Evalúa el modelo en el conjunto de test y haz alguna predicción (muestra el valor predicho y el real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar el conjunto de datos de eficiencia energética de UCI\n",
    "url = (\"https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\")\n",
    "data = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
