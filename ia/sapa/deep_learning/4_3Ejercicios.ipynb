{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuántas neuronas hacen falta en la capa de salida para clasificar emails entre correo no deseado y correo deseado? \n",
    " - 1\n",
    "\n",
    "¿Qué función de activación deberías usar en la capa de salida? \n",
    " - Sigmoide\n",
    "\n",
    "Si, en cambio, quieres enfrentarte a MNIST, ¿cuántas neuronas necesitas en la capa de salida y qué función de activación deberías usar? \n",
    " - 10 neuronas (1 neurona por clase), funcion de activacion: Softmax\n",
    "\n",
    "¿Y si quieres que la red prediga los precios de la vivienda en California?\n",
    " - 1 neurona, funcion de activacion: Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrena un red neuronal profunda con el conjunto de datos MNIST (puedes cargarlo con tf. keras. datasets.minst.load_data()). Intenta conseguir la mejor pruebas en el conjunto de validación  ajustando los hiperparámetros de modo manual. Prueba a buscar una buena tasa de aprendizaje y utiliza la detención temprana (mínimo hay que conseguir un 97%).\n",
    "\n",
    "Pasos a seguir: \n",
    "+ Entrena varios modelos con distintas tasas de aprendizaje\n",
    "+ Guarda cada modelo en un fichero\n",
    "+ Carga cada modelo y evalúalo en el conjunto de cargas y quedate con programación con el mejor (bucle que se quede con el mejor), mostrando la tasa de aprendizaje y la exactitud del mejor modelo.\n",
    "\n",
    "Si no obtienes más de un 97% vuelve a empezar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtener, separar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
    "\n",
    "#Dividimos los datos completos de entrenamiento en datos de entrenamiento y validación\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenar varios modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todos los modelos tendran 1 entrada, 2 ocultas y 10 salidas(1 salida por clase)\n",
    "modelos = []\n",
    "for i in range(3):\n",
    "    # Se crea el modelo con la capa de normalización y 4 capas densas (fully connected) con 50 neuronas cada una y función de activación ReLU (Rectified Linear Unit) y una capa de salida con una neurona y sin función de activación\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=X_train.shape[1:]),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(124, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    modelos.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8.2920 - sparse_categorical_accuracy: 0.0897 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 2/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8.2434 - sparse_categorical_accuracy: 0.0892 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 3/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8.2970 - sparse_categorical_accuracy: 0.0923 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 4/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8.3026 - sparse_categorical_accuracy: 0.0896 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 5/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8.2377 - sparse_categorical_accuracy: 0.0916 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 6/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8.3164 - sparse_categorical_accuracy: 0.0879 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 7/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8.2974 - sparse_categorical_accuracy: 0.0891 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 8/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8.2471 - sparse_categorical_accuracy: 0.0912 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 9/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8.3040 - sparse_categorical_accuracy: 0.0905 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 10/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8.2859 - sparse_categorical_accuracy: 0.0896 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 11/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8.2689 - sparse_categorical_accuracy: 0.0904 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 12/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8.3069 - sparse_categorical_accuracy: 0.0890 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 13/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8.3045 - sparse_categorical_accuracy: 0.0914 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 14/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8.2717 - sparse_categorical_accuracy: 0.0898 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 15/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8.3086 - sparse_categorical_accuracy: 0.0900 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 16/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8.2374 - sparse_categorical_accuracy: 0.0913 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 17/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8.2096 - sparse_categorical_accuracy: 0.0909 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 18/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 8.2358 - sparse_categorical_accuracy: 0.0899 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 19/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8.2945 - sparse_categorical_accuracy: 0.0898 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "Epoch 20/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 8.2316 - sparse_categorical_accuracy: 0.0901 - val_loss: 8.4292 - val_sparse_categorical_accuracy: 0.0916\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5.3180 - sparse_categorical_accuracy: 0.0966 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 2/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3588 - sparse_categorical_accuracy: 0.1005 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 3/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5.3178 - sparse_categorical_accuracy: 0.1002 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 4/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3292 - sparse_categorical_accuracy: 0.1020 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 5/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3480 - sparse_categorical_accuracy: 0.0996 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 6/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3270 - sparse_categorical_accuracy: 0.0989 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 7/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3792 - sparse_categorical_accuracy: 0.1003 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 8/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3728 - sparse_categorical_accuracy: 0.0994 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 9/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5.3336 - sparse_categorical_accuracy: 0.1017 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 10/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3062 - sparse_categorical_accuracy: 0.1001 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 11/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 5.4037 - sparse_categorical_accuracy: 0.0984 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 12/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3814 - sparse_categorical_accuracy: 0.0997 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 13/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3720 - sparse_categorical_accuracy: 0.0985 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 14/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3271 - sparse_categorical_accuracy: 0.1029 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 15/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3272 - sparse_categorical_accuracy: 0.0986 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 16/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3494 - sparse_categorical_accuracy: 0.1019 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 17/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5.3566 - sparse_categorical_accuracy: 0.1004 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 18/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5.3233 - sparse_categorical_accuracy: 0.1011 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 19/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5.3283 - sparse_categorical_accuracy: 0.1021 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 20/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 5.3564 - sparse_categorical_accuracy: 0.0987 - val_loss: 5.4707 - val_sparse_categorical_accuracy: 0.0986\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 11.0128 - sparse_categorical_accuracy: 0.0994 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 2/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 11.0044 - sparse_categorical_accuracy: 0.1004 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 3/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 10.9780 - sparse_categorical_accuracy: 0.1006 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 4/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 11.0170 - sparse_categorical_accuracy: 0.0968 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 5/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 11.0238 - sparse_categorical_accuracy: 0.0998 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 6/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 11.0270 - sparse_categorical_accuracy: 0.0997 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 7/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 11.0206 - sparse_categorical_accuracy: 0.0977 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 8/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 11.0342 - sparse_categorical_accuracy: 0.1017 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 9/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 11.0677 - sparse_categorical_accuracy: 0.0981 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 10/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 11.0159 - sparse_categorical_accuracy: 0.1022 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 11/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 11.0445 - sparse_categorical_accuracy: 0.1006 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 12/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 11.0298 - sparse_categorical_accuracy: 0.0976 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 13/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 11.0493 - sparse_categorical_accuracy: 0.0994 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 14/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 11.0101 - sparse_categorical_accuracy: 0.1003 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 15/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 11.0649 - sparse_categorical_accuracy: 0.1007 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 16/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 10.9889 - sparse_categorical_accuracy: 0.1000 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 17/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 11.0377 - sparse_categorical_accuracy: 0.1003 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 18/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 11.0776 - sparse_categorical_accuracy: 0.0990 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 19/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 11.0887 - sparse_categorical_accuracy: 0.0989 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "Epoch 20/20\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 10.9984 - sparse_categorical_accuracy: 0.0991 - val_loss: 11.1539 - val_sparse_categorical_accuracy: 0.0986\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "historys = []\n",
    "lr = 0.0001\n",
    "for mod in modelos:\n",
    "    # Se compila el modelo con el optimizador SGD  \n",
    "    mod.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=lr),   # asignar tasa de aprendizaje tasa entre 0.001 y 0.0001\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy])\n",
    "    lr += 0.0004\n",
    "    # entrenar\n",
    "    hist = mod.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "    historys.append(hist)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Modelo_0: {'verbose': 'auto', 'epochs': 20, 'steps': 1719}\n",
      " Modelo_1: {'verbose': 'auto', 'epochs': 20, 'steps': 1719}\n",
      " Modelo_2: {'verbose': 'auto', 'epochs': 20, 'steps': 1719}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(historys)):\n",
    "    # mostramos el historial de entrenamiento \n",
    "    print(' Modelo_{}: {}'.format(i,historys[i].params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardar en diferentes ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(modelos)):\n",
    "    modelos[i].save(\"Resultados/my_keras_model_{}.keras\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar y evaluar con bucle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificación de Imágenes de Dígitos Escritos a Mano:\n",
    "\n",
    "* Objetivo: Entrenar una red neuronal para clasificar imágenes de dígitos escritos a mano utilizando el conjunto de datos SVHN (Street View House Numbers).\n",
    "\n",
    "* Tareas: \n",
    "    * Cargar el conjunto de datos, dividir los datos (train, valid y test), explorar los datos representando alguna imagen con su etiqueta y muestra los valores (únicos) de y (en el entrenamiento, en validación y en pruebas), preparar los datos (d normalizar dividiendo entre 255.0 e igual hay que hacer algo más), construir, compilar y entrenar una red neuronal. \n",
    "\n",
    "    * Utilizar detección temprana\n",
    "\n",
    "    * Hacer una gráfica de como evoluciona accuracy y val_accuracy durante el entrenamiento\n",
    "\n",
    "    * Si es necesario ajustar el modelo para lograr una mayor precisión.\n",
    "\n",
    "    * Evalúar el modelo en el conjunto de test y hacer alguna predicción (representa alguna imagen con su etiqueta real y la predicha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_svhn_data(url):\n",
    "    path = tf.keras.utils.get_file(\"svhn.mat\", url)\n",
    "    data = loadmat(path)\n",
    "    return np.transpose(data[\"X\"], (3, 0, 1, 2)), data[\"y\"].flatten()\n",
    "\n",
    "# Cargar datos\n",
    "train_url = \"http://ufldl.stanford.edu/housenumbers/train_32x32.mat\"\n",
    "test_url = \"http://ufldl.stanford.edu/housenumbers/test_32x32.mat\"\n",
    "X_train_full, y_train_full = load_svhn_data(train_url)\n",
    "X_test, y_test = load_svhn_data(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIO 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicción del consumo de energía:\n",
    "\n",
    "* Objetivo: Construir una red neuronal para predecir el consumo de energía de edificios a partir de características como la temperatura, humedad, y tiempo del conjunto de datos Energy Efficiency de UCI Machine Learning Repository\n",
    "\n",
    "* Tareas: \n",
    "    * Cargar el conjunto de datos, dividir los datos (train, valid y test), explorar los datos, preparar los datos (normalizar con una capa de normalización), construir un modelo de regresión, compilar y entrenar una red neuronal. \n",
    "    \n",
    "    * Usa X1-X8 para la X e Y1-Y2 para la y\n",
    "\n",
    "    * Ajusta el modelo hasta encontrar un error absoluto medio aceptable\n",
    "\n",
    "    * Haz una gráfica de como evoluciona el error absoluto medio y error absoluto medio del conjunto de validación durante el entrenamiento\n",
    "\n",
    "    * Evalúa el modelo en el conjunto de test y haz alguna predicción (muestra el valor predicho y el real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar el conjunto de datos de eficiencia energética de UCI\n",
    "url = (\"https://archive.ics.uci.edu/ml/machine-learning-databases/00242/ENB2012_data.xlsx\")\n",
    "data = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
